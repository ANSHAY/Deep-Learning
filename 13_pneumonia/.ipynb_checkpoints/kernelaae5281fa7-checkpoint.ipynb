{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chest_xray', '__MACOSX']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/chest_xray\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORMAL', 'PNEUMONIA', '.DS_Store']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input/chest_xray/chest_xray/train\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining metadata\n",
      "\n",
      "Metadata defined\n"
     ]
    }
   ],
   "source": [
    "## define parameters\n",
    "print(\"\\nDefining metadata\")\n",
    "Nrows = 150\n",
    "Ncols = 150\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 15\n",
    "FILTER_SIZE = (3,3)\n",
    "model_path = \"../model\"+\"_R\"+str(Nrows)+\"_C\"+str(Ncols)+\"_fs\"+str(FILTER_SIZE[0])+\"_ep\"+str(NUM_EPOCHS)+\".h5\"\n",
    "print(\"\\nMetadata defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    # Retrieve a list of list results on training and val data\n",
    "    # sets for each training epoch\n",
    "    acc=history.history['acc']\n",
    "    val_acc=history.history['val_acc']\n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "    \n",
    "    # Get number of epochs\n",
    "    epochs=range(len(acc)) \n",
    "    \n",
    "    # Plot training and validation accuracy per epoch\n",
    "    plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "    plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.figure()\n",
    "    \n",
    "    # Plot training and validation loss per epoch\n",
    "    plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "    \n",
    "    plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epochs, logs={}):\n",
    "        if (logs.get('acc') > 0.99):\n",
    "            self.model.stop_training = True\n",
    "            print (\"\\nStopping training as accuracy is above 99%\")\n",
    "callback = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data using ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "\n",
      "Data Generators defined\n"
     ]
    }
   ],
   "source": [
    "## load data - change directories to the location of data\n",
    "\n",
    "print(\"\\nLoading data...\")\n",
    "train_dir = \"../input/chest_xray/chest_xray/train\"\n",
    "val_dir = \"../input/chest_xray/chest_xray/val\"\n",
    "test_dir = \"../input/chest_xray/chest_xray/test\"\n",
    "\n",
    "train_data_gen = ImageDataGenerator(rescale=1/255.0,\n",
    "                                      rotation_range=40,\n",
    "                                      shear_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      width_shift_range=0.2,\n",
    "                                      height_shift_range=0.2,\n",
    "                                      zoom_range=0.3)\n",
    "val_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_data_gen.flow_from_directory( train_dir,\n",
    "                                                target_size=((Nrows, Ncols)),\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                class_mode='binary')\n",
    "val_gen = val_data_gen.flow_from_directory(val_dir,\n",
    "                                            target_size=((Nrows, Ncols)),\n",
    "                                            class_mode='binary')\n",
    "test_gen = test_data_gen.flow_from_directory(test_dir,\n",
    "                                            target_size=((Nrows, Ncols)),\n",
    "                                            class_mode='binary')\n",
    "print(\"\\nData Generators defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "print(\"\\nTraining model...\")\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(256, FILTER_SIZE, activation='relu', input_shape=(Nrows, Ncols, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "model.add(tf.keras.layers.Conv2D(128, FILTER_SIZE, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "model.add(tf.keras.layers.Conv2D(32, FILTER_SIZE, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 148, 148, 256)     7168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 72, 72, 128)       295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 34, 34, 32)        36896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9248)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              9470976   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 9,875,745\n",
      "Trainable params: 9,875,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## compile model\n",
    "model.compile(optimizer=RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit model to data - training\n",
    "history = model.fit_generator(train_gen,\n",
    "                              epochs=NUM_EPOCHS,\n",
    "                              steps_per_epoch=100,\n",
    "                              validation_steps=50,\n",
    "                              validation_data=val_gen,\n",
    "                              verbose=1,\n",
    "                              callbacks=[callback])\n",
    "print(\"\\nNew model trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model to file\n",
    "print(\"\\nSaving model for later use...\")\n",
    "model.save(model_path)\n",
    "print(\"\\nModel Successfully saved\")\n",
    "## plot results\n",
    "print(\"\\nPlotting results...\")\n",
    "plot_results(history)\n",
    "print(\"\\n........................\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "model.evaluate_generator(test_gen, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
