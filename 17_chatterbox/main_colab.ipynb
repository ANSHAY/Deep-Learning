{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of main_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANSHAY/deeplearning/blob/master/17_chatterbox/main_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8R1fQ0bJzbO",
        "colab_type": "text"
      },
      "source": [
        "# Chatty the chatterbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN3VHIEVJzbT",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf8hPVbTJzbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS78ddwAJzbf",
        "colab_type": "text"
      },
      "source": [
        "## Define Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVnovUgZJzbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_type = 'conversation'\n",
        "\n",
        "files = [dataset_type + '_train.txt']\n",
        "save_file_path = dataset_type + '_predicted.txt'\n",
        "PADDING = 'pre'\n",
        "TRUNC = 'pre'\n",
        "MAXLEN = 7\n",
        "\n",
        "VOCAB_SIZE = 10000\n",
        "EMB_DIM = 128\n",
        "\n",
        "OPTIMIZER = 'adam'\n",
        "LOSS = 'categorical_crossentropy'\n",
        "METRICS = ['acc']\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = 128\n",
        "VAL_SPLIT = 0.1\n",
        "\n",
        "SEEDER = 'Hi, Whats up'    ## Seeder word to start prediction of poetry\n",
        "\n",
        "model_name = dataset_type + \"_model_colab.h5\"\n",
        "\n",
        "data = \"This is some random statement \\n being used as placeholder for the actual data that is to be \\n imported later from a file.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWv2zYlJJzbo",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEARnDkOJzbq",
        "colab_type": "code",
        "outputId": "f668670b-a7e2-4fb1-8905-ed9f400c362f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "corpus = ''\n",
        "for file in files:\n",
        "    with open(file) as f:\n",
        "        data = f.read()\n",
        "        corpus += data + '\\n'\n",
        "        f.close()\n",
        "#data = data.replace('\\n', ' \\n<>')\n",
        "sentences = corpus.lower().split('\\n')\n",
        "print(len(sentences))\n",
        "print(sentences[0])\n",
        "print(len(sentences[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-89874eba437d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcorpus\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmp/conversation_train.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICnYMUreJzby",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kc4UjLNJzbz",
        "colab_type": "code",
        "outputId": "c552d263-7951-4404-aba0-17831020a850",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()          #filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t')\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "total_words = len(word_index) + 1\n",
        "print(total_words)\n",
        "print(word_index['a'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2256\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBRlj6zEJzb6",
        "colab_type": "code",
        "outputId": "3490b661-1342-4f32-d7a7-bc152a8e15ab",
        "colab": {}
      },
      "source": [
        "## create reverse_word_index\n",
        "reverse_word_index = {}\n",
        "for word, i in word_index.items():\n",
        "    reverse_word_index[i] = word\n",
        "print(reverse_word_index[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYq_DARiJzcA",
        "colab_type": "text"
      },
      "source": [
        "## Change Sentences to Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1yR0RobJzcC",
        "colab_type": "code",
        "outputId": "d5df7f1c-0962-4c52-cb5e-c4a300d4236d",
        "colab": {}
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded_seq = pad_sequences(sequences, padding=PADDING, truncating=TRUNC, maxlen=MAXLEN)\n",
        "print(padded_seq[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IceZraoJzcR",
        "colab_type": "text"
      },
      "source": [
        "## Extract trainX and trainY from sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLzUBvpIJzcU",
        "colab_type": "code",
        "outputId": "ce7e38ce-b883-4a61-843a-3ae77b48eba7",
        "colab": {}
      },
      "source": [
        "trainX = padded_seq[:-1,:]\n",
        "trainY = padded_seq[1:,:]\n",
        "\n",
        "INP_LEN = trainX.shape[1]\n",
        "OUT_LEN = trainY.shape[1]\n",
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=total_words)\n",
        "\n",
        "print(trainX.shape)\n",
        "print(trainY.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2309, 7)\n",
            "(2309, 7, 2256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnOvE61TJzcb",
        "colab_type": "code",
        "outputId": "a34ab3b0-c892-4cfc-9c17-687e27a98270",
        "colab": {}
      },
      "source": [
        "print(padded_seq[1])\n",
        "print(trainY[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   7   6 418]\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwEXiXg8Jzch",
        "colab_type": "text"
      },
      "source": [
        "## Define Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XENWJ2F4Jzci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epochs, log={}):\n",
        "        if (log.get('acc')>0.90):\n",
        "            self.model.stop_training = True\n",
        "            print(\"\\n Stopped training since model reached accuracy of 90%\")\n",
        "callback = myCallback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R98s4WNaJzcl",
        "colab_type": "text"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKoqVEocJzco",
        "colab_type": "code",
        "outputId": "f37c89d3-6a4c-43bb-9bef-c91893a60705",
        "colab": {}
      },
      "source": [
        "LOAD_MODEL = False\n",
        "\n",
        "if LOAD_MODEL == True:\n",
        "    try:\n",
        "        model = tf.keras.models.load_model(model_name)\n",
        "        print(\"\\nModel loaded successfully\")\n",
        "    except:\n",
        "        print(\"\\nModel not loaded. Building new...\")\n",
        "        LOAD_MODEL = False\n",
        "if LOAD_MODEL == False:\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Embedding(total_words, EMB_DIM, input_length=INP_LEN),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "        tf.keras.layers.Dense(total_words, activation='softmax')\n",
        "    ])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model not loaded. Building new...\n",
            "WARNING:tensorflow:From C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwLnIsxoJzct",
        "colab_type": "code",
        "outputId": "9148a081-da66-4852-9e78-dc06e995f7c4",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 7, 128)            288768    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 7, 256)            263168    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 7, 128)            164352    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 7, 2256)           291024    \n",
            "=================================================================\n",
            "Total params: 1,007,312\n",
            "Trainable params: 1,007,312\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyM8TzeWJzcz",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "vluiwIr5Jzc1",
        "colab_type": "code",
        "outputId": "1a471450-6b96-451e-8702-718d98c055fb",
        "colab": {}
      },
      "source": [
        "history = model.fit(trainX, trainY, validation_split=VAL_SPLIT, verbose=1, epochs = EPOCHS, shuffle=False, batch_size=BATCH_SIZE, callbacks=[callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2078 samples, validate on 231 samples\n",
            "WARNING:tensorflow:From C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Epoch 1/1000\n",
            "2078/2078 [==============================] - 10s 5ms/sample - loss: 7.6453 - acc: 0.2573 - val_loss: 7.2569 - val_acc: 0.1979\n",
            "Epoch 2/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 5.8147 - acc: 0.2784 - val_loss: 5.6399 - val_acc: 0.1979\n",
            "Epoch 3/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.8447 - acc: 0.2784 - val_loss: 5.5874 - val_acc: 0.1979\n",
            "Epoch 4/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.7432 - acc: 0.2784 - val_loss: 5.5843 - val_acc: 0.1979\n",
            "Epoch 5/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.6983 - acc: 0.2787 - val_loss: 5.6058 - val_acc: 0.2010\n",
            "Epoch 6/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.6626 - acc: 0.2817 - val_loss: 5.6251 - val_acc: 0.2004\n",
            "Epoch 7/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.6300 - acc: 0.2825 - val_loss: 5.6447 - val_acc: 0.2022\n",
            "Epoch 8/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.5955 - acc: 0.2835 - val_loss: 5.6655 - val_acc: 0.2028\n",
            "Epoch 9/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.5618 - acc: 0.2851 - val_loss: 5.6805 - val_acc: 0.2028\n",
            "Epoch 10/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.5311 - acc: 0.2868 - val_loss: 5.7159 - val_acc: 0.2010\n",
            "Epoch 11/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.5043 - acc: 0.2876 - val_loss: 5.7241 - val_acc: 0.2016\n",
            "Epoch 12/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.4821 - acc: 0.2894 - val_loss: 5.7649 - val_acc: 0.2028\n",
            "Epoch 13/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.4613 - acc: 0.2897 - val_loss: 5.7752 - val_acc: 0.2010\n",
            "Epoch 14/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.4382 - acc: 0.2905 - val_loss: 5.8000 - val_acc: 0.1991\n",
            "Epoch 15/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.4219 - acc: 0.2903 - val_loss: 5.8152 - val_acc: 0.1998\n",
            "Epoch 16/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.4083 - acc: 0.2910 - val_loss: 5.8626 - val_acc: 0.1998\n",
            "Epoch 17/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.3889 - acc: 0.2918 - val_loss: 5.8668 - val_acc: 0.1991\n",
            "Epoch 18/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.3679 - acc: 0.2940 - val_loss: 5.8818 - val_acc: 0.1911\n",
            "Epoch 19/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.3555 - acc: 0.2921 - val_loss: 5.8949 - val_acc: 0.1861\n",
            "Epoch 20/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.3506 - acc: 0.2931 - val_loss: 5.9201 - val_acc: 0.1886\n",
            "Epoch 21/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.3518 - acc: 0.2927 - val_loss: 6.0077 - val_acc: 0.1979\n",
            "Epoch 22/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.3744 - acc: 0.2907 - val_loss: 5.9640 - val_acc: 0.1899\n",
            "Epoch 23/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.3404 - acc: 0.2925 - val_loss: 5.9182 - val_acc: 0.1824\n",
            "Epoch 24/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.3361 - acc: 0.2880 - val_loss: 5.9812 - val_acc: 0.1911\n",
            "Epoch 25/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.2851 - acc: 0.2938 - val_loss: 6.0147 - val_acc: 0.1892\n",
            "Epoch 26/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.2561 - acc: 0.2951 - val_loss: 5.9923 - val_acc: 0.1831\n",
            "Epoch 27/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.2421 - acc: 0.2938 - val_loss: 6.0033 - val_acc: 0.1855\n",
            "Epoch 28/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.2304 - acc: 0.2969 - val_loss: 6.0605 - val_acc: 0.1911\n",
            "Epoch 29/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.2206 - acc: 0.2967 - val_loss: 6.0750 - val_acc: 0.1899\n",
            "Epoch 30/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1973 - acc: 0.2972 - val_loss: 6.0484 - val_acc: 0.1800\n",
            "Epoch 31/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1961 - acc: 0.2975 - val_loss: 6.0502 - val_acc: 0.1843\n",
            "Epoch 32/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1944 - acc: 0.2982 - val_loss: 6.1330 - val_acc: 0.1899\n",
            "Epoch 33/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1866 - acc: 0.2999 - val_loss: 6.1250 - val_acc: 0.1837\n",
            "Epoch 34/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1631 - acc: 0.2998 - val_loss: 6.0725 - val_acc: 0.1744\n",
            "Epoch 35/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1561 - acc: 0.2993 - val_loss: 6.1044 - val_acc: 0.1812\n",
            "Epoch 36/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1461 - acc: 0.2992 - val_loss: 6.1858 - val_acc: 0.1868\n",
            "Epoch 37/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1381 - acc: 0.3000 - val_loss: 6.1647 - val_acc: 0.1824\n",
            "Epoch 38/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1142 - acc: 0.3017 - val_loss: 6.1349 - val_acc: 0.1694\n",
            "Epoch 39/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1140 - acc: 0.3000 - val_loss: 6.1599 - val_acc: 0.1732\n",
            "Epoch 40/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1108 - acc: 0.3019 - val_loss: 6.2379 - val_acc: 0.1886\n",
            "Epoch 41/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1143 - acc: 0.2996 - val_loss: 6.2140 - val_acc: 0.1775\n",
            "Epoch 42/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1053 - acc: 0.3008 - val_loss: 6.1239 - val_acc: 0.1707\n",
            "Epoch 43/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.1008 - acc: 0.3002 - val_loss: 6.2003 - val_acc: 0.1707\n",
            "Epoch 44/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.0842 - acc: 0.3015 - val_loss: 6.2762 - val_acc: 0.1824\n",
            "Epoch 45/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.0780 - acc: 0.3021 - val_loss: 6.2466 - val_acc: 0.1775\n",
            "Epoch 46/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.0447 - acc: 0.3006 - val_loss: 6.1920 - val_acc: 0.1651\n",
            "Epoch 47/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.0443 - acc: 0.3019 - val_loss: 6.2366 - val_acc: 0.1694\n",
            "Epoch 48/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.0328 - acc: 0.3036 - val_loss: 6.3119 - val_acc: 0.1837\n",
            "Epoch 49/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.0252 - acc: 0.3032 - val_loss: 6.2909 - val_acc: 0.1707\n",
            "Epoch 50/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.0118 - acc: 0.3019 - val_loss: 6.2420 - val_acc: 0.1664\n",
            "Epoch 51/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 4.0019 - acc: 0.3032 - val_loss: 6.2748 - val_acc: 0.1688\n",
            "Epoch 52/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9924 - acc: 0.3044 - val_loss: 6.3436 - val_acc: 0.1806\n",
            "Epoch 53/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9853 - acc: 0.3057 - val_loss: 6.3314 - val_acc: 0.1744\n",
            "Epoch 54/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9716 - acc: 0.3038 - val_loss: 6.2745 - val_acc: 0.1651\n",
            "Epoch 55/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9679 - acc: 0.3043 - val_loss: 6.3146 - val_acc: 0.1626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 56/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9656 - acc: 0.3050 - val_loss: 6.3973 - val_acc: 0.1763\n",
            "Epoch 57/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9586 - acc: 0.3070 - val_loss: 6.3672 - val_acc: 0.1769\n",
            "Epoch 58/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9417 - acc: 0.3064 - val_loss: 6.3168 - val_acc: 0.1633\n",
            "Epoch 59/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9351 - acc: 0.3063 - val_loss: 6.3277 - val_acc: 0.1626\n",
            "Epoch 60/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9452 - acc: 0.3052 - val_loss: 6.3989 - val_acc: 0.1744\n",
            "Epoch 61/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9488 - acc: 0.3090 - val_loss: 6.4110 - val_acc: 0.1793\n",
            "Epoch 62/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9393 - acc: 0.3032 - val_loss: 6.3480 - val_acc: 0.1645\n",
            "Epoch 63/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9493 - acc: 0.3036 - val_loss: 6.3092 - val_acc: 0.1657\n",
            "Epoch 64/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9353 - acc: 0.3072 - val_loss: 6.4111 - val_acc: 0.1763\n",
            "Epoch 65/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9218 - acc: 0.3113 - val_loss: 6.4233 - val_acc: 0.1738\n",
            "Epoch 66/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.9004 - acc: 0.3083 - val_loss: 6.3326 - val_acc: 0.1657\n",
            "Epoch 67/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.8805 - acc: 0.3097 - val_loss: 6.3524 - val_acc: 0.1676\n",
            "Epoch 68/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.8656 - acc: 0.3120 - val_loss: 6.4324 - val_acc: 0.1775\n",
            "Epoch 69/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.8607 - acc: 0.3143 - val_loss: 6.4351 - val_acc: 0.1763\n",
            "Epoch 70/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.8485 - acc: 0.3125 - val_loss: 6.3675 - val_acc: 0.1676\n",
            "Epoch 71/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.8391 - acc: 0.3124 - val_loss: 6.3902 - val_acc: 0.1645\n",
            "Epoch 72/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.8319 - acc: 0.3131 - val_loss: 6.4851 - val_acc: 0.1756\n",
            "Epoch 73/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.8288 - acc: 0.3160 - val_loss: 6.4585 - val_acc: 0.1750\n",
            "Epoch 74/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.8115 - acc: 0.3140 - val_loss: 6.3809 - val_acc: 0.1651\n",
            "Epoch 75/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.8109 - acc: 0.3136 - val_loss: 6.4109 - val_acc: 0.1645\n",
            "Epoch 76/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.8109 - acc: 0.3133 - val_loss: 6.5229 - val_acc: 0.1763\n",
            "Epoch 77/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.8092 - acc: 0.3173 - val_loss: 6.4867 - val_acc: 0.1756\n",
            "Epoch 78/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.7865 - acc: 0.3156 - val_loss: 6.3947 - val_acc: 0.1626\n",
            "Epoch 79/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.7923 - acc: 0.3144 - val_loss: 6.4529 - val_acc: 0.1639\n",
            "Epoch 80/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.7812 - acc: 0.3159 - val_loss: 6.5385 - val_acc: 0.1787\n",
            "Epoch 81/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.8016 - acc: 0.3180 - val_loss: 6.4687 - val_acc: 0.1694\n",
            "Epoch 82/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.7758 - acc: 0.3153 - val_loss: 6.4131 - val_acc: 0.1626\n",
            "Epoch 83/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.7958 - acc: 0.3126 - val_loss: 6.5028 - val_acc: 0.1682\n",
            "Epoch 84/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.7524 - acc: 0.3173 - val_loss: 6.5428 - val_acc: 0.1694\n",
            "Epoch 85/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.7377 - acc: 0.3211 - val_loss: 6.4593 - val_acc: 0.1657\n",
            "Epoch 86/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.7131 - acc: 0.3181 - val_loss: 6.4534 - val_acc: 0.1651\n",
            "Epoch 87/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.7027 - acc: 0.3196 - val_loss: 6.5201 - val_acc: 0.1645\n",
            "Epoch 88/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.6850 - acc: 0.3227 - val_loss: 6.5652 - val_acc: 0.1682\n",
            "Epoch 89/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.6752 - acc: 0.3230 - val_loss: 6.5477 - val_acc: 0.1701\n",
            "Epoch 90/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.6628 - acc: 0.3222 - val_loss: 6.5040 - val_acc: 0.1664\n",
            "Epoch 91/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.6576 - acc: 0.3224 - val_loss: 6.4888 - val_acc: 0.1552\n",
            "Epoch 92/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.6735 - acc: 0.3208 - val_loss: 6.5469 - val_acc: 0.1639\n",
            "Epoch 93/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.6589 - acc: 0.3231 - val_loss: 6.6189 - val_acc: 0.1725\n",
            "Epoch 94/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.6641 - acc: 0.3288 - val_loss: 6.5614 - val_acc: 0.1657\n",
            "Epoch 95/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.6373 - acc: 0.3257 - val_loss: 6.4800 - val_acc: 0.1521\n",
            "Epoch 96/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.6458 - acc: 0.3236 - val_loss: 6.5365 - val_acc: 0.1645\n",
            "Epoch 97/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.6210 - acc: 0.3302 - val_loss: 6.6301 - val_acc: 0.1664\n",
            "Epoch 98/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.6177 - acc: 0.3326 - val_loss: 6.5832 - val_acc: 0.1651\n",
            "Epoch 99/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.6024 - acc: 0.3307 - val_loss: 6.5469 - val_acc: 0.1633\n",
            "Epoch 100/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.5786 - acc: 0.3294 - val_loss: 6.5456 - val_acc: 0.1552\n",
            "Epoch 101/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.5622 - acc: 0.3347 - val_loss: 6.6039 - val_acc: 0.1540\n",
            "Epoch 102/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.5446 - acc: 0.3345 - val_loss: 6.6361 - val_acc: 0.1639\n",
            "Epoch 103/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.5330 - acc: 0.3366 - val_loss: 6.6623 - val_acc: 0.1633\n",
            "Epoch 104/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.5252 - acc: 0.3402 - val_loss: 6.6311 - val_acc: 0.1602\n",
            "Epoch 105/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.5165 - acc: 0.3360 - val_loss: 6.5418 - val_acc: 0.1509\n",
            "Epoch 106/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.5414 - acc: 0.3334 - val_loss: 6.5770 - val_acc: 0.1515\n",
            "Epoch 107/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.5458 - acc: 0.3389 - val_loss: 6.7354 - val_acc: 0.1713\n",
            "Epoch 108/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.5758 - acc: 0.3397 - val_loss: 6.6813 - val_acc: 0.1701\n",
            "Epoch 109/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.5543 - acc: 0.3362 - val_loss: 6.5474 - val_acc: 0.1565\n",
            "Epoch 110/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.5127 - acc: 0.3371 - val_loss: 6.5870 - val_acc: 0.1596\n",
            "Epoch 111/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.4830 - acc: 0.3446 - val_loss: 6.7029 - val_acc: 0.1645\n",
            "Epoch 112/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.4549 - acc: 0.3483 - val_loss: 6.6687 - val_acc: 0.1633\n",
            "Epoch 113/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.4321 - acc: 0.3501 - val_loss: 6.6405 - val_acc: 0.1620\n",
            "Epoch 114/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.4179 - acc: 0.3514 - val_loss: 6.6468 - val_acc: 0.1509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 115/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.4130 - acc: 0.3496 - val_loss: 6.6615 - val_acc: 0.1583\n",
            "Epoch 116/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.3961 - acc: 0.3536 - val_loss: 6.7252 - val_acc: 0.1657\n",
            "Epoch 117/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.3913 - acc: 0.3560 - val_loss: 6.7315 - val_acc: 0.1645\n",
            "Epoch 118/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.3791 - acc: 0.3529 - val_loss: 6.6520 - val_acc: 0.1515\n",
            "Epoch 119/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.3866 - acc: 0.3541 - val_loss: 6.6401 - val_acc: 0.1490\n",
            "Epoch 120/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.3765 - acc: 0.3539 - val_loss: 6.7469 - val_acc: 0.1639\n",
            "Epoch 121/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.3788 - acc: 0.3570 - val_loss: 6.8007 - val_acc: 0.1707\n",
            "Epoch 122/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.3817 - acc: 0.3558 - val_loss: 6.7106 - val_acc: 0.1589\n",
            "Epoch 123/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.3568 - acc: 0.3550 - val_loss: 6.6507 - val_acc: 0.1583\n",
            "Epoch 124/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.3577 - acc: 0.3536 - val_loss: 6.7350 - val_acc: 0.1558\n",
            "Epoch 125/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.3205 - acc: 0.3622 - val_loss: 6.7889 - val_acc: 0.1552\n",
            "Epoch 126/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.2976 - acc: 0.3628 - val_loss: 6.7604 - val_acc: 0.1645\n",
            "Epoch 127/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.2765 - acc: 0.3657 - val_loss: 6.7543 - val_acc: 0.1571\n",
            "Epoch 128/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.2622 - acc: 0.3648 - val_loss: 6.7276 - val_acc: 0.1540\n",
            "Epoch 129/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.2565 - acc: 0.3666 - val_loss: 6.7560 - val_acc: 0.1571\n",
            "Epoch 130/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.2367 - acc: 0.3690 - val_loss: 6.8397 - val_acc: 0.1602\n",
            "Epoch 131/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.2277 - acc: 0.3702 - val_loss: 6.8142 - val_acc: 0.1602\n",
            "Epoch 132/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.2186 - acc: 0.3704 - val_loss: 6.7540 - val_acc: 0.1565\n",
            "Epoch 133/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.2305 - acc: 0.3661 - val_loss: 6.7277 - val_acc: 0.1472\n",
            "Epoch 134/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.2456 - acc: 0.3640 - val_loss: 6.8181 - val_acc: 0.1552\n",
            "Epoch 135/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.2222 - acc: 0.3701 - val_loss: 6.9073 - val_acc: 0.1682\n",
            "Epoch 136/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.2160 - acc: 0.3699 - val_loss: 6.8250 - val_acc: 0.1577\n",
            "Epoch 137/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.1831 - acc: 0.3705 - val_loss: 6.7518 - val_acc: 0.1571\n",
            "Epoch 138/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.1755 - acc: 0.3734 - val_loss: 6.8241 - val_acc: 0.1546\n",
            "Epoch 139/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.1434 - acc: 0.3778 - val_loss: 6.8767 - val_acc: 0.1528\n",
            "Epoch 140/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.1299 - acc: 0.3782 - val_loss: 6.8483 - val_acc: 0.1583\n",
            "Epoch 141/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.1154 - acc: 0.3811 - val_loss: 6.8326 - val_acc: 0.1534\n",
            "Epoch 142/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.1022 - acc: 0.3806 - val_loss: 6.8433 - val_acc: 0.1521\n",
            "Epoch 143/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0907 - acc: 0.3817 - val_loss: 6.8686 - val_acc: 0.1534\n",
            "Epoch 144/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0768 - acc: 0.3840 - val_loss: 6.9150 - val_acc: 0.1614\n",
            "Epoch 145/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0717 - acc: 0.3858 - val_loss: 6.9256 - val_acc: 0.1639\n",
            "Epoch 146/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0634 - acc: 0.3843 - val_loss: 6.8615 - val_acc: 0.1540\n",
            "Epoch 147/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0814 - acc: 0.3818 - val_loss: 6.8356 - val_acc: 0.1484\n",
            "Epoch 148/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0905 - acc: 0.3807 - val_loss: 6.8899 - val_acc: 0.1521\n",
            "Epoch 149/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0905 - acc: 0.3835 - val_loss: 6.9638 - val_acc: 0.1664\n",
            "Epoch 150/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.1122 - acc: 0.3804 - val_loss: 6.9554 - val_acc: 0.1608\n",
            "Epoch 151/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0699 - acc: 0.3817 - val_loss: 6.8972 - val_acc: 0.1552\n",
            "Epoch 152/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0443 - acc: 0.3850 - val_loss: 6.9141 - val_acc: 0.1552\n",
            "Epoch 153/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0183 - acc: 0.3895 - val_loss: 6.9056 - val_acc: 0.1472\n",
            "Epoch 154/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0146 - acc: 0.3886 - val_loss: 6.8961 - val_acc: 0.1472\n",
            "Epoch 155/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.9884 - acc: 0.3950 - val_loss: 6.9900 - val_acc: 0.1540\n",
            "Epoch 156/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.9906 - acc: 0.3936 - val_loss: 7.0626 - val_acc: 0.1682\n",
            "Epoch 157/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0182 - acc: 0.3920 - val_loss: 6.9322 - val_acc: 0.1602\n",
            "Epoch 158/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0114 - acc: 0.3876 - val_loss: 6.8706 - val_acc: 0.1416\n",
            "Epoch 159/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0769 - acc: 0.3798 - val_loss: 6.9259 - val_acc: 0.1552\n",
            "Epoch 160/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0149 - acc: 0.3904 - val_loss: 7.0753 - val_acc: 0.1725\n",
            "Epoch 161/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 3.0177 - acc: 0.3911 - val_loss: 6.9286 - val_acc: 0.1577\n",
            "Epoch 162/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.9398 - acc: 0.3973 - val_loss: 6.8849 - val_acc: 0.1509\n",
            "Epoch 163/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.9379 - acc: 0.3974 - val_loss: 6.9649 - val_acc: 0.1565\n",
            "Epoch 164/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.8922 - acc: 0.4073 - val_loss: 7.0318 - val_acc: 0.1670\n",
            "Epoch 165/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.8767 - acc: 0.4084 - val_loss: 6.9613 - val_acc: 0.1558\n",
            "Epoch 166/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.8504 - acc: 0.4110 - val_loss: 6.9479 - val_acc: 0.1534\n",
            "Epoch 167/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.8359 - acc: 0.4148 - val_loss: 7.0198 - val_acc: 0.1546\n",
            "Epoch 168/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.8198 - acc: 0.4181 - val_loss: 7.0477 - val_acc: 0.1626\n",
            "Epoch 169/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.8039 - acc: 0.4192 - val_loss: 7.0055 - val_acc: 0.1565\n",
            "Epoch 170/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7935 - acc: 0.4191 - val_loss: 6.9857 - val_acc: 0.1546\n",
            "Epoch 171/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7838 - acc: 0.4213 - val_loss: 7.0449 - val_acc: 0.1534\n",
            "Epoch 172/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7771 - acc: 0.4254 - val_loss: 7.0963 - val_acc: 0.1614\n",
            "Epoch 173/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7696 - acc: 0.4247 - val_loss: 7.0701 - val_acc: 0.1589\n",
            "Epoch 174/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7592 - acc: 0.4265 - val_loss: 7.0191 - val_acc: 0.1515\n",
            "Epoch 175/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7645 - acc: 0.4246 - val_loss: 7.0407 - val_acc: 0.1490\n",
            "Epoch 176/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7562 - acc: 0.4264 - val_loss: 7.1270 - val_acc: 0.1558\n",
            "Epoch 177/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7535 - acc: 0.4280 - val_loss: 7.1441 - val_acc: 0.1614\n",
            "Epoch 178/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7689 - acc: 0.4269 - val_loss: 7.0975 - val_acc: 0.1639\n",
            "Epoch 179/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7704 - acc: 0.4286 - val_loss: 7.0397 - val_acc: 0.1478\n",
            "Epoch 180/1000\n",
            "2078/2078 [==============================] - 5s 2ms/sample - loss: 2.7653 - acc: 0.4230 - val_loss: 7.0576 - val_acc: 0.1478\n",
            "Epoch 181/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7354 - acc: 0.4318 - val_loss: 7.1435 - val_acc: 0.1583\n",
            "Epoch 182/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7311 - acc: 0.4307 - val_loss: 7.1662 - val_acc: 0.1657\n",
            "Epoch 183/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.7063 - acc: 0.4354 - val_loss: 7.0708 - val_acc: 0.1515\n",
            "Epoch 184/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.6940 - acc: 0.4374 - val_loss: 7.0711 - val_acc: 0.1509\n",
            "Epoch 185/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.6777 - acc: 0.4425 - val_loss: 7.1354 - val_acc: 0.1620\n",
            "Epoch 186/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.6586 - acc: 0.4466 - val_loss: 7.1707 - val_acc: 0.1608\n",
            "Epoch 187/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.6238 - acc: 0.4504 - val_loss: 7.1407 - val_acc: 0.1515\n",
            "Epoch 188/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.6081 - acc: 0.4528 - val_loss: 7.1054 - val_acc: 0.1534\n",
            "Epoch 189/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.5911 - acc: 0.4585 - val_loss: 7.1407 - val_acc: 0.1583\n",
            "Epoch 190/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.5782 - acc: 0.4601 - val_loss: 7.2119 - val_acc: 0.1546\n",
            "Epoch 191/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.5607 - acc: 0.4591 - val_loss: 7.2326 - val_acc: 0.1534\n",
            "Epoch 192/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.5613 - acc: 0.4634 - val_loss: 7.1628 - val_acc: 0.1534\n",
            "Epoch 193/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.5605 - acc: 0.4632 - val_loss: 7.1433 - val_acc: 0.1490\n",
            "Epoch 194/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.5577 - acc: 0.4626 - val_loss: 7.2145 - val_acc: 0.1509\n",
            "Epoch 195/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.5419 - acc: 0.4662 - val_loss: 7.2850 - val_acc: 0.1577\n",
            "Epoch 196/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.5645 - acc: 0.4651 - val_loss: 7.2095 - val_acc: 0.1620\n",
            "Epoch 197/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.5538 - acc: 0.4662 - val_loss: 7.1594 - val_acc: 0.1472\n",
            "Epoch 198/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.5711 - acc: 0.4562 - val_loss: 7.1934 - val_acc: 0.1472\n",
            "Epoch 199/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.5317 - acc: 0.4693 - val_loss: 7.2744 - val_acc: 0.1596\n",
            "Epoch 200/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.5150 - acc: 0.4718 - val_loss: 7.2597 - val_acc: 0.1620\n",
            "Epoch 201/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.4767 - acc: 0.4755 - val_loss: 7.2095 - val_acc: 0.1534\n",
            "Epoch 202/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.4614 - acc: 0.4769 - val_loss: 7.2113 - val_acc: 0.1515\n",
            "Epoch 203/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.4434 - acc: 0.4848 - val_loss: 7.2966 - val_acc: 0.1577\n",
            "Epoch 204/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.4163 - acc: 0.4872 - val_loss: 7.3062 - val_acc: 0.1596\n",
            "Epoch 205/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3975 - acc: 0.4905 - val_loss: 7.2563 - val_acc: 0.1503\n",
            "Epoch 206/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3823 - acc: 0.4949 - val_loss: 7.2409 - val_acc: 0.1503\n",
            "Epoch 207/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3759 - acc: 0.4951 - val_loss: 7.2977 - val_acc: 0.1565\n",
            "Epoch 208/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3689 - acc: 0.4986 - val_loss: 7.3796 - val_acc: 0.1583\n",
            "Epoch 209/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3696 - acc: 0.4990 - val_loss: 7.3412 - val_acc: 0.1509\n",
            "Epoch 210/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3716 - acc: 0.4970 - val_loss: 7.2376 - val_acc: 0.1466\n",
            "Epoch 211/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3838 - acc: 0.4962 - val_loss: 7.2873 - val_acc: 0.1509\n",
            "Epoch 212/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3806 - acc: 0.4964 - val_loss: 7.4318 - val_acc: 0.1565\n",
            "Epoch 213/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3899 - acc: 0.4908 - val_loss: 7.3278 - val_acc: 0.1577\n",
            "Epoch 214/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3707 - acc: 0.4927 - val_loss: 7.2864 - val_acc: 0.1453\n",
            "Epoch 215/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3572 - acc: 0.4975 - val_loss: 7.3557 - val_acc: 0.1497\n",
            "Epoch 216/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3506 - acc: 0.4981 - val_loss: 7.3919 - val_acc: 0.1596\n",
            "Epoch 217/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.3200 - acc: 0.5042 - val_loss: 7.3562 - val_acc: 0.1540\n",
            "Epoch 218/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2981 - acc: 0.5059 - val_loss: 7.3320 - val_acc: 0.1466\n",
            "Epoch 219/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2794 - acc: 0.5110 - val_loss: 7.3824 - val_acc: 0.1484\n",
            "Epoch 220/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2564 - acc: 0.5144 - val_loss: 7.4288 - val_acc: 0.1546\n",
            "Epoch 221/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2372 - acc: 0.5168 - val_loss: 7.3963 - val_acc: 0.1521\n",
            "Epoch 222/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2219 - acc: 0.5225 - val_loss: 7.4104 - val_acc: 0.1534\n",
            "Epoch 223/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2290 - acc: 0.5235 - val_loss: 7.4242 - val_acc: 0.1515\n",
            "Epoch 224/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2293 - acc: 0.5216 - val_loss: 7.4158 - val_acc: 0.1429\n",
            "Epoch 225/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2362 - acc: 0.5143 - val_loss: 7.4056 - val_acc: 0.1398\n",
            "Epoch 226/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2559 - acc: 0.5137 - val_loss: 7.4397 - val_acc: 0.1534\n",
            "Epoch 227/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2582 - acc: 0.5164 - val_loss: 7.5296 - val_acc: 0.1620\n",
            "Epoch 228/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2798 - acc: 0.5166 - val_loss: 7.4718 - val_acc: 0.1490\n",
            "Epoch 229/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2648 - acc: 0.5135 - val_loss: 7.3788 - val_acc: 0.1342\n",
            "Epoch 230/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2989 - acc: 0.5061 - val_loss: 7.4208 - val_acc: 0.1509\n",
            "Epoch 231/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2376 - acc: 0.5219 - val_loss: 7.5450 - val_acc: 0.1596\n",
            "Epoch 232/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.2129 - acc: 0.5230 - val_loss: 7.4265 - val_acc: 0.1404\n",
            "Epoch 233/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.1705 - acc: 0.5315 - val_loss: 7.3999 - val_acc: 0.1453\n",
            "Epoch 234/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.1460 - acc: 0.5361 - val_loss: 7.4973 - val_acc: 0.1503\n",
            "Epoch 235/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.1147 - acc: 0.5431 - val_loss: 7.5141 - val_acc: 0.1552\n",
            "Epoch 236/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0947 - acc: 0.5449 - val_loss: 7.4545 - val_acc: 0.1472\n",
            "Epoch 237/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0699 - acc: 0.5509 - val_loss: 7.4554 - val_acc: 0.1447\n",
            "Epoch 238/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0621 - acc: 0.5551 - val_loss: 7.5359 - val_acc: 0.1503\n",
            "Epoch 239/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0456 - acc: 0.5562 - val_loss: 7.5622 - val_acc: 0.1515\n",
            "Epoch 240/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0326 - acc: 0.5583 - val_loss: 7.4962 - val_acc: 0.1472\n",
            "Epoch 241/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0168 - acc: 0.5637 - val_loss: 7.4866 - val_acc: 0.1429\n",
            "Epoch 242/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0188 - acc: 0.5637 - val_loss: 7.5672 - val_acc: 0.1453\n",
            "Epoch 243/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0087 - acc: 0.5665 - val_loss: 7.6120 - val_acc: 0.1509\n",
            "Epoch 244/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0136 - acc: 0.5637 - val_loss: 7.5458 - val_acc: 0.1509\n",
            "Epoch 245/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0028 - acc: 0.5640 - val_loss: 7.5132 - val_acc: 0.1398\n",
            "Epoch 246/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0215 - acc: 0.5611 - val_loss: 7.5720 - val_acc: 0.1441\n",
            "Epoch 247/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0095 - acc: 0.5643 - val_loss: 7.6458 - val_acc: 0.1534\n",
            "Epoch 248/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 2.0233 - acc: 0.5573 - val_loss: 7.5669 - val_acc: 0.1509\n",
            "Epoch 249/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.9986 - acc: 0.5635 - val_loss: 7.5441 - val_acc: 0.1404\n",
            "Epoch 250/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.9765 - acc: 0.5700 - val_loss: 7.6070 - val_acc: 0.1404\n",
            "Epoch 251/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.9562 - acc: 0.5696 - val_loss: 7.6414 - val_acc: 0.1509\n",
            "Epoch 252/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.9406 - acc: 0.5745 - val_loss: 7.6200 - val_acc: 0.1459\n",
            "Epoch 253/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.9195 - acc: 0.5784 - val_loss: 7.6123 - val_acc: 0.1429\n",
            "Epoch 254/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8987 - acc: 0.5841 - val_loss: 7.6536 - val_acc: 0.1429\n",
            "Epoch 255/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8771 - acc: 0.5883 - val_loss: 7.6719 - val_acc: 0.1422\n",
            "Epoch 256/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8634 - acc: 0.5901 - val_loss: 7.6461 - val_acc: 0.1410\n",
            "Epoch 257/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8487 - acc: 0.5937 - val_loss: 7.6594 - val_acc: 0.1435\n",
            "Epoch 258/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8361 - acc: 0.5993 - val_loss: 7.7115 - val_acc: 0.1416\n",
            "Epoch 259/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8294 - acc: 0.5983 - val_loss: 7.7169 - val_acc: 0.1404\n",
            "Epoch 260/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8259 - acc: 0.5968 - val_loss: 7.6799 - val_acc: 0.1385\n",
            "Epoch 261/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8238 - acc: 0.5992 - val_loss: 7.6760 - val_acc: 0.1422\n",
            "Epoch 262/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8356 - acc: 0.5995 - val_loss: 7.7535 - val_acc: 0.1459\n",
            "Epoch 263/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8372 - acc: 0.5961 - val_loss: 7.8047 - val_acc: 0.1447\n",
            "Epoch 264/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8456 - acc: 0.5963 - val_loss: 7.7014 - val_acc: 0.1391\n",
            "Epoch 265/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8463 - acc: 0.5901 - val_loss: 7.6566 - val_acc: 0.1299\n",
            "Epoch 266/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8722 - acc: 0.5927 - val_loss: 7.8020 - val_acc: 0.1459\n",
            "Epoch 267/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8732 - acc: 0.5895 - val_loss: 7.8524 - val_acc: 0.1528\n",
            "Epoch 268/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8701 - acc: 0.5837 - val_loss: 7.6790 - val_acc: 0.1379\n",
            "Epoch 269/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8778 - acc: 0.5828 - val_loss: 7.6977 - val_acc: 0.1330\n",
            "Epoch 270/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8744 - acc: 0.5833 - val_loss: 7.8072 - val_acc: 0.1447\n",
            "Epoch 271/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8558 - acc: 0.5859 - val_loss: 7.7953 - val_acc: 0.1509\n",
            "Epoch 272/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.8143 - acc: 0.5948 - val_loss: 7.7501 - val_acc: 0.1416\n",
            "Epoch 273/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.7450 - acc: 0.6117 - val_loss: 7.7618 - val_acc: 0.1361\n",
            "Epoch 274/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.7298 - acc: 0.6167 - val_loss: 7.7973 - val_acc: 0.1404\n",
            "Epoch 275/1000\n",
            "2078/2078 [==============================] - ETA: 0s - loss: 1.7234 - acc: 0.618 - 4s 2ms/sample - loss: 1.7090 - acc: 0.6221 - val_loss: 7.8198 - val_acc: 0.1503\n",
            "Epoch 276/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.7133 - acc: 0.6221 - val_loss: 7.8048 - val_acc: 0.1435\n",
            "Epoch 277/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.6893 - acc: 0.6268 - val_loss: 7.8135 - val_acc: 0.1348\n",
            "Epoch 278/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.6977 - acc: 0.6229 - val_loss: 7.8156 - val_acc: 0.1398\n",
            "Epoch 279/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.6836 - acc: 0.6287 - val_loss: 7.8683 - val_acc: 0.1490\n",
            "Epoch 280/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.6961 - acc: 0.6242 - val_loss: 7.8699 - val_acc: 0.1447\n",
            "Epoch 281/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.6662 - acc: 0.6297 - val_loss: 7.8405 - val_acc: 0.1323\n",
            "Epoch 282/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.6775 - acc: 0.6244 - val_loss: 7.8228 - val_acc: 0.1385\n",
            "Epoch 283/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.6564 - acc: 0.6330 - val_loss: 7.8946 - val_acc: 0.1484\n",
            "Epoch 284/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.6566 - acc: 0.6338 - val_loss: 7.9256 - val_acc: 0.1422\n",
            "Epoch 285/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.6299 - acc: 0.6366 - val_loss: 7.8465 - val_acc: 0.1336\n",
            "Epoch 286/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.6215 - acc: 0.6387 - val_loss: 7.8488 - val_acc: 0.1404\n",
            "Epoch 287/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.6055 - acc: 0.6451 - val_loss: 7.9556 - val_acc: 0.1447\n",
            "Epoch 288/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.5865 - acc: 0.6488 - val_loss: 7.9335 - val_acc: 0.1404\n",
            "Epoch 289/1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.5649 - acc: 0.6511 - val_loss: 7.8714 - val_acc: 0.1367\n",
            "Epoch 290/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.5565 - acc: 0.6550 - val_loss: 7.9157 - val_acc: 0.1391\n",
            "Epoch 291/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.5386 - acc: 0.6601 - val_loss: 7.9933 - val_acc: 0.1429\n",
            "Epoch 292/1000\n",
            "2078/2078 [==============================] - 5s 2ms/sample - loss: 1.5288 - acc: 0.6603 - val_loss: 7.9535 - val_acc: 0.1404\n",
            "Epoch 293/1000\n",
            "2078/2078 [==============================] - 5s 2ms/sample - loss: 1.5183 - acc: 0.6642 - val_loss: 7.9123 - val_acc: 0.1367\n",
            "Epoch 294/1000\n",
            "2078/2078 [==============================] - 5s 2ms/sample - loss: 1.5151 - acc: 0.6622 - val_loss: 7.9586 - val_acc: 0.1385\n",
            "Epoch 295/1000\n",
            "2078/2078 [==============================] - 5s 2ms/sample - loss: 1.5098 - acc: 0.6649 - val_loss: 8.0324 - val_acc: 0.1435\n",
            "Epoch 296/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.5189 - acc: 0.6634 - val_loss: 8.0011 - val_acc: 0.1416\n",
            "Epoch 297/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.5169 - acc: 0.6628 - val_loss: 7.9407 - val_acc: 0.1305\n",
            "Epoch 298/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.5383 - acc: 0.6555 - val_loss: 7.9635 - val_acc: 0.1342\n",
            "Epoch 299/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.5330 - acc: 0.6602 - val_loss: 8.0576 - val_acc: 0.1466\n",
            "Epoch 300/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.5626 - acc: 0.6507 - val_loss: 8.0448 - val_acc: 0.1484\n",
            "Epoch 301/1000\n",
            "2078/2078 [==============================] - 4s 2ms/sample - loss: 1.5401 - acc: 0.6552 - val_loss: 7.9776 - val_acc: 0.1286\n",
            "Epoch 302/1000\n",
            "1664/2078 [=======================>......] - ETA: 0s - loss: 1.5123 - acc: 0.6553"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-d15b0d3c97fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVAL_SPLIT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-YT6DEEJzc9",
        "colab_type": "text"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuCOts65Jzc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZcE-XUxJzdB",
        "colab_type": "text"
      },
      "source": [
        "## Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKB7Dya8JzdC",
        "colab_type": "code",
        "outputId": "40df23de-5ed5-4576-e189-c3f1d5271dee",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(EPOCHS)\n",
        "\n",
        "plt.plot(epochs, acc, 'r')\n",
        "plt.plot(epochs, val_acc, 'b')\n",
        "plt.xlabel('EPOCHS')\n",
        "plt.ylabel('Accuracies')\n",
        "plt.legend('Train Acc', 'Val Acc')\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r')\n",
        "plt.plot(epochs, val_loss, 'b')\n",
        "plt.xlabel('EPOCHS')\n",
        "plt.ylabel('Losses')\n",
        "plt.legend('Train Loss', 'Val Loss')\n",
        "plt.figure()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-15-154f232938e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLjuyPpsJzdI",
        "colab_type": "text"
      },
      "source": [
        "## Generate Poetry by iterating over the predictor from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rqXjtzNJzdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_word_index[0] = ' '"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvPrDST6JzdO",
        "colab_type": "code",
        "outputId": "fa09b083-1f83-4a95-cf7e-fbb6badc8c85",
        "colab": {}
      },
      "source": [
        "sentence = SEEDER.lower()\n",
        "corpus = SEEDER.lower()\n",
        "new_line = False\n",
        "print (sentence, end='\\n')\n",
        "\n",
        "sentence = input()\n",
        "while(sentence != 'stop'):\n",
        "    corpus += '\\n' + sentence\n",
        "    seq = tokenizer.texts_to_sequences([sentence])\n",
        "    seq = pad_sequences(seq, padding=PADDING, truncating=TRUNC, maxlen=INP_LEN)\n",
        "    pred_seq = model.predict(seq)\n",
        "    pred_seq = np.argmax(pred_seq, axis=2)\n",
        "    pred_sent = [reverse_word_index[x] for x in pred_seq[0]]\n",
        "    pred_sent = ' '.join(pred_sent)\n",
        "    print(pred_sent)\n",
        "    corpus += '\\n' + pred_sent\n",
        "    sentence = input()\n",
        "print (\"Bye, See ya later!!!\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi, whats up\n",
            "how are you\n",
            "        you you you\n",
            "i i i \n",
            "  you you you to to weekend\n",
            "lets plaay on weekend\n",
            "      you you you you\n",
            "what the hell\n",
            "        you you you\n",
            "dont say you\n",
            "    i you you to you\n",
            "lol\n",
            "        you you you\n",
            "stop\n",
            "Bye, See ya later!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omug2JR6JzdT",
        "colab_type": "text"
      },
      "source": [
        "## Save Poetry in a file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUdVa6K9JzdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    with open(save_file_path, 'w') as f:\n",
        "        f.write(corpus)\n",
        "        f.close()\n",
        "except:\n",
        "    print(\"\\nWrite was Unsuccessful\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ou7-Dw6JzdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgrG9Z-SJzda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}