{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poetry Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"poetry_laur.txt\"\n",
    "save_file_path = 'predicted_poetry.txt'\n",
    "PADDING = 'pre'\n",
    "TRUNC = 'pre'\n",
    "\n",
    "VOCAB_SIZE = 10000\n",
    "EMB_DIM = 128\n",
    "\n",
    "OPTIMIZER = 'adam'\n",
    "LOSS = 'categorical_crossentropy'\n",
    "METRICS = ['acc']\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 128\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "SEEDER = 'angels stole thy pure love'    ## Seeder word to start prediction of poetry\n",
    "NUM_PREDICTIONS = 1000\n",
    "\n",
    "model_name = \"model_laur.h5\"\n",
    "\n",
    "data = \"This is some random statement \\n being used as placeholder for the actual data that is to be \\n imported later from a file.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1693\n",
      "and you that are blooming in your prime \n",
      "\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "with open(filepath) as f:\n",
    "    data = f.read()\n",
    "    f.close()\n",
    "data = data.replace('\\n', ' \\n<>')\n",
    "sentences = data.lower().split('<>')\n",
    "print(len(sentences))\n",
    "print(sentences[1])\n",
    "print(len(sentences[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2691\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "total_words = len(word_index) + 1\n",
    "print(total_words)\n",
    "print(word_index['\\n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: '\\n', 2: 'the', 3: 'and', 4: 'i', 5: 'to', 6: 'a', 7: 'of', 8: 'my', 9: 'in', 10: 'me', 11: 'for', 12: 'you', 13: 'all', 14: 'was', 15: 'she', 16: 'that', 17: 'on', 18: 'with', 19: 'her', 20: 'but', 21: 'as', 22: 'when', 23: 'love', 24: 'is', 25: 'your', 26: 'it', 27: 'will', 28: 'from', 29: 'by', 30: 'they', 31: 'be', 32: 'are', 33: 'so', 34: 'he', 35: 'old', 36: 'no', 37: 'oh', 38: 'ill', 39: 'at', 40: 'one', 41: 'his', 42: 'there', 43: 'were', 44: 'heart', 45: 'down', 46: 'now', 47: 'we', 48: 'where', 49: 'young', 50: 'never', 51: 'go', 52: 'come', 53: 'then', 54: 'did', 55: 'not', 56: 'said', 57: 'away', 58: 'their', 59: 'sweet', 60: 'them', 61: 'green', 62: 'if', 63: 'take', 64: 'our', 65: 'like', 66: 'night', 67: 'day', 68: 'o', 69: 'out', 70: 'fair', 71: 'this', 72: 'town', 73: 'have', 74: 'can', 75: 'true', 76: 'its', 77: 'thou', 78: 'see', 79: 'dear', 80: 'more', 81: 'theres', 82: 'or', 83: 'had', 84: 'would', 85: 'over', 86: 'hear', 87: 'up', 88: 'ive', 89: 'through', 90: 'home', 91: 'again', 92: 'well', 93: 'oer', 94: 'land', 95: 'good', 96: 'im', 97: 'ye', 98: 'sea', 99: 'left', 100: 'still', 101: 'father', 102: 'long', 103: 'rose', 104: 'could', 105: 'morning', 106: 'wild', 107: 'who', 108: 'eyes', 109: 'came', 110: 'while', 111: 'too', 112: 'back', 113: 'little', 114: 'an', 115: 'took', 116: 'him', 117: 'bow', 118: 'first', 119: 'let', 120: 'man', 121: 'shall', 122: 'know', 123: 'get', 124: 'high', 125: 'gone', 126: 'say', 127: 'ever', 128: 'some', 129: 'mary', 130: 'hand', 131: 'till', 132: 'put', 133: 'own', 134: 'time', 135: 'heard', 136: 'dead', 137: 'may', 138: 'bright', 139: 'mountain', 140: 'early', 141: 'rosin', 142: 'gave', 143: 'thee', 144: 'only', 145: 'far', 146: 'maid', 147: 'must', 148: 'find', 149: 'girl', 150: 'sure', 151: 'round', 152: 'dublin', 153: 'once', 154: 'world', 155: 'delight', 156: 'last', 157: 'johnny', 158: 'seen', 159: 'has', 160: 'fine', 161: 'road', 162: 'mother', 163: 'tis', 164: 'what', 165: 'way', 166: 'moon', 167: 'soul', 168: 'neer', 169: 'id', 170: 'just', 171: 'thats', 172: 'days', 173: 'darling', 174: 'went', 175: 'white', 176: 'die', 177: 'than', 178: 'hair', 179: 'goes', 180: 'meet', 181: 'today', 182: 'do', 183: 'girls', 184: 'shes', 185: 'thyme', 186: 'thy', 187: 'sing', 188: 'pretty', 189: 'new', 190: 'poor', 191: 'into', 192: 'life', 193: 'irish', 194: 'give', 195: 'boy', 196: 'youre', 197: 'make', 198: 'passed', 199: 'lovely', 200: 'black', 201: 'youll', 202: 'died', 203: 'red', 204: 'smile', 205: 'keep', 206: 'loves', 207: 'free', 208: 'leave', 209: 'friends', 210: 'each', 211: 'saw', 212: 'behind', 213: 'song', 214: 'ra', 215: 'dont', 216: 'arms', 217: 'am', 218: 'sun', 219: 'saying', 220: 'made', 221: 'wish', 222: 'cold', 223: 'met', 224: 'before', 225: 'should', 226: 'rocky', 227: 'light', 228: 'wid', 229: 'boys', 230: 'best', 231: 'fields', 232: 'since', 233: 'ball', 234: 'water', 235: 'casey', 236: 'mind', 237: 'along', 238: 'loved', 239: 'place', 240: 'ireland', 241: 'next', 242: 'three', 243: 'many', 244: 'years', 245: 'door', 246: 'us', 247: 'drink', 248: 'got', 249: 'might', 250: 'live', 251: 'roses', 252: 'play', 253: 'soon', 254: 'ground', 255: 'times', 256: 'spent', 257: 'going', 258: 'tree', 259: 'barley', 260: 'grass', 261: 'kind', 262: 'twas', 263: 'bridge', 264: 'around', 265: 'blue', 266: 'tell', 267: 'row', 268: 'how', 269: 'money', 270: 'merry', 271: 'stepped', 272: 'corporal', 273: 'always', 274: 'though', 275: 'near', 276: 'taken', 277: 'ones', 278: 'daughter', 279: 'forever', 280: 'loo', 281: 'shining', 282: 'plenty', 283: 'hes', 284: 'ship', 285: 'banks', 286: 'think', 287: 'very', 288: 'stand', 289: 'heres', 290: 'snow', 291: 'mountains', 292: 'molly', 293: 'wheel', 294: 'street', 295: 'erin', 296: 'side', 297: 'feet', 298: 'star', 299: 'look', 300: 'brave', 301: 'woman', 302: 'sons', 303: 'two', 304: 'says', 305: 'asked', 306: 'lanigans', 307: 'singing', 308: 'men', 309: 'toome', 310: 'stole', 311: 'god', 312: 'hill', 313: 'lonely', 314: 'lover', 315: 'tears', 316: 'fathers', 317: 'low', 318: 'voice', 319: 'quite', 320: 'able', 321: 'nice', 322: 'laid', 323: 'comrades', 324: 'wind', 325: 'another', 326: 'sit', 327: 'face', 328: 'band', 329: 'call', 330: 'colleen', 331: 'until', 332: 'hills', 333: 'mine', 334: 'above', 335: 'upon', 336: 'eer', 337: 'youve', 338: 'fly', 339: 'been', 340: 'late', 341: 'alive', 342: 'ballyjamesduff', 343: 'looked', 344: 'great', 345: 'why', 346: 'every', 347: 'proud', 348: 'found', 349: 'bragh', 350: 'such', 351: 'birds', 352: 'wedding', 353: 'welcome', 354: 'dancing', 355: 'da', 356: 'fell', 357: 'thinking', 358: 'roddy', 359: 'mccorley', 360: 'smiling', 361: 'mallow', 362: 'blooming', 363: 'thought', 364: 'peace', 365: 'soft', 366: 'pure', 367: 'harp', 368: 'dream', 369: 'alas', 370: 'yet', 371: 'clear', 372: 'art', 373: 'off', 374: 'hope', 375: 'fought', 376: 'mothers', 377: 'shore', 378: 'ago', 379: 'fol', 380: 'de', 381: 'house', 382: 'married', 383: 'bound', 384: 'danced', 385: 'devil', 386: 'dawning', 387: 'makes', 388: 'same', 389: 'sat', 390: 'any', 391: 'glass', 392: 'gay', 393: 'relations', 394: 'evening', 395: 'watched', 396: 'right', 397: 'fellows', 398: 'whiskey', 399: 'bonnie', 400: 'grows', 401: 'women', 402: 'flowers', 403: 'beauty', 404: 'cannot', 405: 'handsome', 406: 'happy', 407: 'gold', 408: 'rover', 409: 'none', 410: 'doneen', 411: 'summers', 412: 'people', 413: 'set', 414: 'paddy', 415: 'morn', 416: 'most', 417: 'easy', 418: 'struck', 419: 'beautiful', 420: 'those', 421: 'golden', 422: 'run', 423: 'pipes', 424: 'glen', 425: 'dying', 426: 'here', 427: 'wall', 428: 'across', 429: 'fire', 430: 'eileen', 431: 'longer', 432: 'cheeks', 433: 'valley', 434: 'both', 435: 'dew', 436: 'care', 437: 'bride', 438: 'nothing', 439: 'wont', 440: 'theyre', 441: 'colonel', 442: 'maiden', 443: 'shed', 444: 'til', 445: 'brown', 446: 'breast', 447: 'corn', 448: 'sinking', 449: 'began', 450: 'name', 451: 'cruel', 452: 'sound', 453: 'spancil', 454: 'county', 455: 'lies', 456: 'color', 457: 'thing', 458: 'decay', 459: 'sleep', 460: 'hours', 461: 'loving', 462: 'weary', 463: 'ringing', 464: 'please', 465: 'forget', 466: 'lie', 467: 'ran', 468: 'tore', 469: 'country', 470: 'fear', 471: 'fortune', 472: 'kissed', 473: 'alone', 474: 'ould', 475: 'cry', 476: 'dreams', 477: 'used', 478: 'horse', 479: 'break', 480: 'bells', 481: 'didnt', 482: 'weeks', 483: 'without', 484: 'raw', 485: 'nor', 486: 'twenty', 487: 'tune', 488: 'hed', 489: 'roving', 490: 'leaves', 491: 'cant', 492: 'death', 493: 'ten', 494: 'prison', 495: 'judge', 496: 'against', 497: 'lads', 498: 'shell', 499: 'fill', 500: 'valleys', 501: 'other', 502: 'pale', 503: 'joy', 504: 'wide', 505: 'bring', 506: 'ah', 507: 'cliffs', 508: 'city', 509: 'end', 510: 'turn', 511: 'sky', 512: 'born', 513: 'knew', 514: 'smiled', 515: 'rosie', 516: 'comes', 517: 'sayin', 518: 'lord', 519: 'dungannon', 520: 'blood', 521: 'air', 522: 'danny', 523: 'calling', 524: 'sunshine', 525: 'spring', 526: 'bid', 527: 'grow', 528: 'truth', 529: 'tear', 530: 'rings', 531: 'guns', 532: 'bay', 533: 'oflynn', 534: 'och', 535: 'stick', 536: 'rest', 537: 'four', 538: 'jewel', 539: 'tried', 540: 'grief', 541: 'answer', 542: 'kathleen', 543: 'fond', 544: 'eye', 545: 'goin', 546: 'pistols', 547: 'musha', 548: 'whack', 549: 'creole', 550: 'together', 551: 'room', 552: 'fall', 553: 'swore', 554: 'being', 555: 'step', 556: 'lark', 557: 'cailã\\xadn', 558: 'deas', 559: 'crãºite', 560: 'na', 561: 'mbã³', 562: 'sir', 563: 'isle', 564: 'waiting', 565: 'magic', 566: 'skibbereen', 567: 'loud', 568: 'raise', 569: 'bent', 570: 'aged', 571: 'summer', 572: 'jenny', 573: 'excise', 574: 'rigadoo', 575: 'auld', 576: 'hearts', 577: 'nay', 578: 'stool', 579: 'farrell', 580: 'garden', 581: 'precious', 582: 'child', 583: 'slumber', 584: 'sleeping', 585: 'watch', 586: 'gently', 587: 'minstrel', 588: 'praise', 589: 'bell', 590: 'shaken', 591: 'immortal', 592: 'pray', 593: 'stay', 594: 'spoke', 595: 'cross', 596: 'brothers', 597: 'much', 598: 'past', 599: 'killarney', 600: 'sang', 601: 'tones', 602: 'ral', 603: 'wander', 604: 'cot', 605: 'feel', 606: 'yore', 607: 'answered', 608: 'divil', 609: 'middle', 610: 'bit', 611: 'led', 612: 'soldiers', 613: 'lily', 614: 'bed', 615: 'lassie', 616: 'clothes', 617: 'return', 618: 'broken', 619: 'derry', 620: 'sighed', 621: 'english', 622: 'tomorrow', 623: 'souls', 624: 'van', 625: 'diemans', 626: 'law', 627: 'neither', 628: 'winds', 629: 'rather', 630: 'doesnt', 631: 'rosy', 632: 'neatest', 633: 'hands', 634: 'whereon', 635: 'stands', 636: 'write', 637: 'thousand', 638: 'fare', 639: 'youd', 640: 'velvet', 641: 'neat', 642: 'landed', 643: 'health', 644: 'kellswater', 645: 'quiet', 646: 'stars', 647: 'beside', 648: 'warm', 649: 'sunday', 650: 'grey', 651: 'ocean', 652: 'sad', 653: 'spend', 654: 'kilkenny', 655: 'silver', 656: 'view', 657: 'west', 658: 'plain', 659: 'barrow', 660: 'broad', 661: 'narrow', 662: 'crying', 663: 'wonder', 664: 'save', 665: 'stop', 666: 'tender', 667: 'told', 668: 'lip', 669: 'dance', 670: 'foot', 671: 'kilrain', 672: 'saint', 673: 'visit', 674: 'mossy', 675: 'wexford', 676: 'irishmen', 677: 'shadow', 678: 'tho', 679: 'salley', 680: 'gardens', 681: 'foolish', 682: 'youth', 683: 'fade', 684: 'war', 685: 'believe', 686: 'which', 687: 'change', 688: 'entwine', 689: 'turns', 690: 'turned', 691: 'crown', 692: 'played', 693: 'captain', 694: 'blow', 695: 'children', 696: 'slainte', 697: 'gentle', 698: 'heavens', 699: 'bloom', 700: 'grand', 701: 'bush', 702: 'nest', 703: 'rich', 704: 'parting', 705: 'better', 706: 'window', 707: 'haste', 708: 'fresh', 709: 'stream', 710: 'rays', 711: 'ma', 712: 'ring', 713: 'lad', 714: 'athy', 715: 'drop', 716: 'hardly', 717: 'done', 718: 'arm', 719: 'leg', 720: 'beg', 721: 'drew', 722: 'bold', 723: 'drawn', 724: 'jail', 725: 'writin', 726: 'farewell', 727: 'tired', 728: 'lake', 729: 'want', 730: 'ringlets', 731: 'myself', 732: 'songs', 733: 'reel', 734: 'steps', 735: 'hearty', 736: 'fainted', 737: 'called', 738: 'under', 739: 'toe', 740: 'mairi', 741: 'fairest', 742: 'darlin', 743: 'bird', 744: 'memory', 745: 'lips', 746: 'sweetly', 747: 'morrow', 748: 'consent', 749: 'else', 750: 'sold', 751: 'stout', 752: 'pair', 753: 'drinking', 754: 'meself', 755: 'fray', 756: 'pike', 757: 'coat', 758: 'beneath', 759: 'rent', 760: 'part', 761: 'half', 762: 'head', 763: 'friend', 764: 'standing', 765: 'floor', 766: 'bare', 767: 'wed', 768: 'son', 769: 'pride', 770: 'vision', 771: 'sword', 772: 'after', 773: 'won', 774: 'farmers', 775: 'flower', 776: 'nut', 777: 'surely', 778: 'stood', 779: 'wandered', 780: 'athenry', 781: 'rising', 782: 'beating', 783: 'form', 784: 'dhu', 785: 'buy', 786: 'laughter', 787: 'wear', 788: 'raking', 789: 'rakes', 790: 'claret', 791: 'shure', 792: 'tralee', 793: 'slower', 794: 'lower', 795: 'deep', 796: 'wearin', 797: 'duram', 798: 'takes', 799: 'beware', 800: 'steal', 801: 'brings', 802: 'things', 803: 'joys', 804: 'bunch', 805: 'sailor', 806: 'chanced', 807: 'pass', 808: 'angels', 809: 'send', 810: 'drowsy', 811: 'keeping', 812: 'spirit', 813: 'stealing', 814: 'feeling', 815: 'roam', 816: 'presence', 817: 'heavenward', 818: 'dust', 819: 'dim', 820: 'journey', 821: 'waves', 822: 'frightened', 823: 'leaving', 824: 'struggle', 825: 'parents', 826: 'courage', 827: 'weeping', 828: 'pain', 829: 'mist', 830: 'felt', 831: 'roared', 832: 'making', 833: 'fever', 834: 'moment', 835: 'distance', 836: 'wailing', 837: 'oft', 838: 'held', 839: 'fast', 840: 'cabin', 841: 'honey', 842: 'diddle', 843: 'clearly', 844: 'open', 845: 'opened', 846: 'table', 847: 'wine', 848: 'lay', 849: 'shells', 850: 'sailed', 851: 'drown', 852: 'fetters', 853: 'chains', 854: 'wives', 855: 'sorrow', 856: 'thoughts', 857: 'cursed', 858: 'hell', 859: 'five', 860: 'buried', 861: 'lost', 862: 'endless', 863: 'slavery', 864: 'gun', 865: 'rain', 866: 'cares', 867: 'ghosts', 868: 'runaway', 869: 'twill', 870: 'month', 871: 'meadows', 872: 'prettiest', 873: 'winters', 874: 'satisfied', 875: 'few', 876: 'short', 877: 'lines', 878: 'shone', 879: 'shoulder', 880: 'belfast', 881: 'trade', 882: 'bad', 883: 'caused', 884: 'stray', 885: 'meaning', 886: 'damsel', 887: 'appear', 888: 'seven', 889: 'sentence', 890: 'jolly', 891: 'whenever', 892: 'wee', 893: 'wife', 894: 'lives', 895: 'martha', 896: 'courted', 897: 'bridgit', 898: 'omalley', 899: 'desolation', 900: 'thorn', 901: 'gaze', 902: 'stone', 903: 'approaching', 904: 'sets', 905: 'carrigfergus', 906: 'nights', 907: 'swim', 908: 'wings', 909: 'sober', 910: 'travel', 911: 'native', 912: 'places', 913: 'slopes', 914: 'hares', 915: 'lofty', 916: 'malone', 917: 'wheeled', 918: 'streets', 919: 'enough', 920: 'reilly', 921: 'tough', 922: 'whispers', 923: 'phil', 924: 'threw', 925: 'straight', 926: 'belles', 927: 'moor', 928: 'brand', 929: 'shapes', 930: 'work', 931: 'vow', 932: 'blarney', 933: 'paid', 934: 'bower', 935: 'remain', 936: 'charming', 937: 'storied', 938: 'chieftains', 939: 'slaughter', 940: 'bann', 941: 'boyne', 942: 'liffey', 943: 'gallant', 944: 'awake', 945: 'greet', 946: 'meadow', 947: 'sweeter', 948: 'dirty', 949: 'cats', 950: 'crossed', 951: 'field', 952: 'river', 953: 'full', 954: 'aroon', 955: 'sends', 956: 'woe', 957: 'chain', 958: 'main', 959: 'charms', 960: 'fondly', 961: 'fleet', 962: 'fairy', 963: 'thine', 964: 'known', 965: 'truly', 966: 'close', 967: 'story', 968: 'flag', 969: 'sweetest', 970: 'honor', 971: 'playing', 972: 'mauser', 973: 'music', 974: 'tom', 975: 'hurrah', 976: 'big', 977: 'lead', 978: 'south', 979: 'generation', 980: 'freedom', 981: 'agin', 982: 'creature', 983: 'dad', 984: 'venture', 985: 'word', 986: 'wonderful', 987: 'crazy', 988: 'lazy', 989: 'grave', 990: 'jest', 991: 'remark', 992: 'strangers', 993: 'strong', 994: 'shook', 995: 'walk', 996: 'north', 997: 'ours', 998: 'cease', 999: 'strife', 1000: 'whats', 1001: 'lilacs', 1002: 'prove', 1003: 'sweetheart', 1004: 'letters', 1005: 'sent', 1006: 'speak', 1007: 'brow', 1008: 'albert', 1009: 'mooney', 1010: 'fighting', 1011: 'fingers', 1012: 'toes', 1013: 'john', 1014: 'hurroo', 1015: 'drums', 1016: 'beguiled', 1017: 'carry', 1018: 'bone', 1019: 'havent', 1020: 'walkin', 1021: 'kilgary', 1022: 'pepper', 1023: 'countin', 1024: 'forth', 1025: 'deliver', 1026: 'daddy', 1027: 'em', 1028: 'deceive', 1029: 'between', 1030: 'even', 1031: 'prisoner', 1032: 'fists', 1033: 'knocked', 1034: 'carriages', 1035: 'rollin', 1036: 'juice', 1037: 'courtin', 1038: 'ponchartrain', 1039: 'does', 1040: 'stranger', 1041: 'marry', 1042: 'adieu', 1043: 'ask', 1044: 'tipped', 1045: 'arrived', 1046: 'ladies', 1047: 'potatoes', 1048: 'courting', 1049: 'miss', 1050: 'small', 1051: 'ned', 1052: 'ribbons', 1053: 'heel', 1054: 'bonny', 1055: 'pipe', 1056: 'thrush', 1057: 'sweethearts', 1058: 'unto', 1059: 'rise', 1060: 'softly', 1061: 'milking', 1062: 'rare', 1063: 'pity', 1064: 'treasure', 1065: 'noon', 1066: 'sailing', 1067: 'banish', 1068: 'riches', 1069: 'comfort', 1070: 'yonder', 1071: 'flows', 1072: 'fairer', 1073: 'lass', 1074: 'woods', 1075: 'strayed', 1076: 'locks', 1077: 'breaking', 1078: 'june', 1079: 'started', 1080: 'hearted', 1081: 'beer', 1082: 'daylight', 1083: 'among', 1084: 'bundle', 1085: 'connaught', 1086: 'quay', 1087: 'erins', 1088: 'galway', 1089: 'fearless', 1090: 'bravely', 1091: 'marches', 1092: 'fate', 1093: 'neck', 1094: 'trod', 1095: 'marched', 1096: 'antrim', 1097: 'sash', 1098: 'flashed', 1099: 'hath', 1100: 'foemans', 1101: 'fight', 1102: 'heavy', 1103: 'bore', 1104: 'mans', 1105: 'counter', 1106: 'dozen', 1107: 'gallon', 1108: 'bottles', 1109: 'diamond', 1110: 'resemble', 1111: 'tiny', 1112: 'friendly', 1113: 'weather', 1114: 'inside', 1115: 'remember', 1116: 'someone', 1117: 'hat', 1118: 'body', 1119: 'dancers', 1120: 'hanging', 1121: 'empty', 1122: 'shoes', 1123: 'broke', 1124: 'december', 1125: 'move', 1126: 'reason', 1127: 'roof', 1128: 'naught', 1129: 'tower', 1130: 'power', 1131: 'king', 1132: 'dreaming', 1133: 'crew', 1134: 'whos', 1135: 'mccann', 1136: 'smoke', 1137: 'notes', 1138: 'yeoman', 1139: 'cavalry', 1140: 'guard', 1141: 'forced', 1142: 'brother', 1143: 'cousin', 1144: 'blame', 1145: 'croppy', 1146: 'dressed', 1147: 'trees', 1148: 'wore', 1149: 'words', 1150: 'swiftly', 1151: 'dawn', 1152: 'lovd', 1153: 'voices', 1154: 'moaning', 1155: 'dark', 1156: 'gather', 1157: 'tay', 1158: 'swinging', 1159: 'drinkin', 1160: 'sitting', 1161: 'stile', 1162: 'springing', 1163: 'yours', 1164: 'kept', 1165: 'aisey', 1166: 'rub', 1167: 'dub', 1168: 'dow', 1169: 'shelah', 1170: 'fairly', 1171: 'beggarman', 1172: 'begging', 1173: 'slept', 1174: 'holes', 1175: 'coming', 1176: 'thru', 1177: 'boo', 1178: 'lady', 1179: 'kerry', 1180: 'pipers', 1181: 'laugh', 1182: 'beaming', 1183: 'guineas', 1184: 'least', 1185: 'diggin', 1186: 'mourne', 1187: 'spending', 1188: 'mellow', 1189: 'plying', 1190: 'slowly', 1191: 'mooncoin', 1192: 'flow', 1193: 'sounds', 1194: 'shine', 1195: 'cool', 1196: 'crystal', 1197: 'fountain', 1198: 'moonlight', 1199: 'grandmother', 1200: 'crooning', 1201: 'merrily', 1202: 'spins', 1203: 'lightly', 1204: 'moving', 1205: 'lattice', 1206: 'grove', 1207: 'swings', 1208: 'finger', 1209: 'shamrock', 1210: 'pocket', 1211: 'springtime', 1212: 'gilgarra', 1213: 'rapier', 1214: 'ringum', 1215: 'mornin', 1216: 'heather', 1217: 'build', 1218: 'maidens', 1219: 'prime', 1220: 'nlyme', 1221: 'flavours', 1222: 'lusty', 1223: 'reminded', 1224: 'attend', 1225: 'guardian', 1226: 'creeping', 1227: 'dale', 1228: 'vigil', 1229: 'visions', 1230: 'revealing', 1231: 'breathes', 1232: 'holy', 1233: 'strains', 1234: 'hover', 1235: 'hark', 1236: 'solemn', 1237: 'winging', 1238: 'earthly', 1239: 'shalt', 1240: 'awaken', 1241: 'destiny', 1242: 'emigrants', 1243: 'amid', 1244: 'longing', 1245: 'parted', 1246: 'townland', 1247: 'vessel', 1248: 'crowded', 1249: 'disquieted', 1250: 'folk', 1251: 'escape', 1252: 'hardship', 1253: 'sustaining', 1254: 'glimpse', 1255: 'faded', 1256: 'strangely', 1257: 'seas', 1258: 'anger', 1259: 'desperate', 1260: 'plight', 1261: 'worsened', 1262: 'delirium', 1263: 'possessed', 1264: 'clouded', 1265: 'prayers', 1266: 'begged', 1267: 'forgiveness', 1268: 'seeking', 1269: 'distant', 1270: 'mither', 1271: 'simple', 1272: 'ditty', 1273: 'ld', 1274: 'li', 1275: 'hush', 1276: 'lullaby', 1277: 'huggin', 1278: 'hummin', 1279: 'rock', 1280: 'asleep', 1281: 'outside', 1282: 'modestly', 1283: 'ry', 1284: 'ay', 1285: 'di', 1286: 're', 1287: 'dai', 1288: 'rie', 1289: 'shc', 1290: 'bridle', 1291: 'stable', 1292: 'oats', 1293: 'eat', 1294: 'soldier', 1295: 'aisy', 1296: 'arose', 1297: 'christmas', 1298: '1803', 1299: 'australia', 1300: 'marks', 1301: 'carried', 1302: 'rusty', 1303: 'iron', 1304: 'wains', 1305: 'mainsails', 1306: 'unfurled', 1307: 'curses', 1308: 'hurled', 1309: 'swell', 1310: 'moth', 1311: 'firelights', 1312: 'horses', 1313: 'rode', 1314: 'taking', 1315: 'hades', 1316: 'twilight', 1317: 'forty', 1318: 'slime', 1319: 'climate', 1320: 'bravery', 1321: 'ended', 1322: 'bond', 1323: 'rebel', 1324: 'iii', 1325: 'violin', 1326: 'clay', 1327: 'sooner', 1328: 'sport', 1329: 'colour', 1330: 'knows', 1331: 'earth', 1332: 'serve', 1333: 'clyde', 1334: 'mourn', 1335: 'weep', 1336: 'suffer', 1337: 'diamonds', 1338: 'queen', 1339: 'hung', 1340: 'tied', 1341: 'apprenticed', 1342: 'happiness', 1343: 'misfortune', 1344: 'follow', 1345: 'strolling', 1346: 'selling', 1347: 'bar', 1348: 'customer', 1349: 'slipped', 1350: 'luck', 1351: 'jury', 1352: 'trial', 1353: 'case', 1354: 'warning', 1355: 'liquor', 1356: 'porter', 1357: 'pleasures', 1358: 'fishing', 1359: 'farming', 1360: 'glens', 1361: 'softest', 1362: 'dripping', 1363: 'snare', 1364: 'lose', 1365: 'court', 1366: 'primrose', 1367: 'bee', 1368: 'hopeless', 1369: 'wonders', 1370: 'admiration', 1371: 'haunt', 1372: 'wherever', 1373: 'sands', 1374: 'purer', 1375: 'within', 1376: 'grieve', 1377: 'drumslieve', 1378: 'ballygrant', 1379: 'deepest', 1380: 'boatsman', 1381: 'ferry', 1382: 'childhood', 1383: 'reflections', 1384: 'boyhood', 1385: 'melting', 1386: 'roaming', 1387: 'reported', 1388: 'marble', 1389: 'stones', 1390: 'ink', 1391: 'support', 1392: 'drunk', 1393: 'seldom', 1394: 'sick', 1395: 'numbered', 1396: 'foam', 1397: 'compare', 1398: 'sights', 1399: 'coast', 1400: 'clare', 1401: 'kilkee', 1402: 'kilrush', 1403: 'watching', 1404: 'pheasants', 1405: 'homes', 1406: 'streams', 1407: 'dublins', 1408: 'cockles', 1409: 'mussels', 1410: 'fish', 1411: 'monger', 1412: 'ghost', 1413: 'wheels', 1414: 'eden', 1415: 'vanished', 1416: 'finea', 1417: 'halfway', 1418: 'cootehill', 1419: 'gruff', 1420: 'whispering', 1421: 'crow', 1422: 'newborn', 1423: 'babies', 1424: 'huff', 1425: 'start', 1426: 'sorrowful', 1427: 'squall', 1428: 'babys', 1429: 'toil', 1430: 'worn', 1431: 'fore', 1432: 'flute', 1433: 'yer', 1434: 'boot', 1435: 'magee', 1436: 'scruff', 1437: 'slanderin', 1438: 'marchin', 1439: 'assisted', 1440: 'drain', 1441: 'dudeen', 1442: 'puff', 1443: 'whisperings', 1444: 'barrin', 1445: 'chocolate', 1446: 'feegee', 1447: 'sort', 1448: 'moonshiny', 1449: 'stuff', 1450: 'addle', 1451: 'brain', 1452: 'ringin', 1453: 'glamour', 1454: 'gas', 1455: 'guff', 1456: 'whisper', 1457: 'oil', 1458: 'remarkable', 1459: 'policeman', 1460: 'bluff', 1461: 'maintain', 1462: 'guril', 1463: 'sic', 1464: 'passage', 1465: 'rough', 1466: 'borne', 1467: 'breeze', 1468: 'boundless', 1469: 'stupendous', 1470: 'roll', 1471: 'thundering', 1472: 'motion', 1473: 'mermaids', 1474: 'fierce', 1475: 'tempest', 1476: 'gathers', 1477: 'oneill', 1478: 'odonnell', 1479: 'lucan', 1480: 'oconnell', 1481: 'brian', 1482: 'drove', 1483: 'danes', 1484: 'patrick', 1485: 'vermin', 1486: 'whose', 1487: 'benburb', 1488: 'blackwater', 1489: 'owen', 1490: 'roe', 1491: 'munroe', 1492: 'lambs', 1493: 'skip', 1494: 'views', 1495: 'enchanting', 1496: 'rostrevor', 1497: 'groves', 1498: 'lakes', 1499: 'ride', 1500: 'tide', 1501: 'majestic', 1502: 'shannon', 1503: 'sail', 1504: 'loch', 1505: 'neagh', 1506: 'ross', 1507: 'gorey', 1508: 'saxon', 1509: 'tory', 1510: 'soil', 1511: 'sanctified', 1512: 'enemies', 1513: 'links', 1514: 'encumbered', 1515: 'resound', 1516: 'hosannahs', 1517: 'bide', 1518: 'hushed', 1519: 'lying', 1520: 'kneel', 1521: 'ave', 1522: 'tread', 1523: 'fail', 1524: 'simply', 1525: 'gasworks', 1526: 'croft', 1527: 'dreamed', 1528: 'canal', 1529: 'factory', 1530: 'clouds', 1531: 'drifting', 1532: 'prowling', 1533: 'beat', 1534: 'springs', 1535: 'siren', 1536: 'docks', 1537: 'train', 1538: 'smelled', 1539: 'smokey', 1540: 'sharp', 1541: 'axe', 1542: 'steel', 1543: 'tempered', 1544: 'chop', 1545: 't', 1546: 'agree', 1547: 'leaning', 1548: 'weirs', 1549: 'ray', 1550: 'glow', 1551: 'changeless', 1552: 'constant', 1553: 'bounding', 1554: 'castles', 1555: 'sacked', 1556: 'scattered', 1557: 'fixed', 1558: 'endearing', 1559: 'gifts', 1560: 'fading', 1561: 'wouldst', 1562: 'adored', 1563: 'loveliness', 1564: 'ruin', 1565: 'itself', 1566: 'verdantly', 1567: 'unprofaned', 1568: 'fervor', 1569: 'faith', 1570: 'forgets', 1571: 'sunflower', 1572: 'rag', 1573: 'games', 1574: 'hold', 1575: 'defend', 1576: 'veteran', 1577: 'volunteers', 1578: 'pat', 1579: 'pearse', 1580: 'clark', 1581: 'macdonagh', 1582: 'macdiarmada', 1583: 'mcbryde', 1584: 'james', 1585: 'connolly', 1586: 'placed', 1587: 'machine', 1588: 'ranting', 1589: 'hour', 1590: 'bullet', 1591: 'stuck', 1592: 'craw', 1593: 'poisoning', 1594: 'ceannt', 1595: 'lions', 1596: 'union', 1597: 'poured', 1598: 'dismay', 1599: 'horror', 1600: 'englishmen', 1601: 'khaki', 1602: 'renown', 1603: 'fame', 1604: 'forefathers', 1605: 'blaze', 1606: 'priests', 1607: 'offer', 1608: 'charmin', 1609: 'variety', 1610: 'renownd', 1611: 'learnin', 1612: 'piety', 1613: 'advance', 1614: 'widout', 1615: 'impropriety', 1616: 'flowr', 1617: 'cho', 1618: 'powrfulest', 1619: 'preacher', 1620: 'tenderest', 1621: 'teacher', 1622: 'kindliest', 1623: 'donegal', 1624: 'talk', 1625: 'provost', 1626: 'trinity', 1627: 'famous', 1628: 'greek', 1629: 'latinity', 1630: 'divils', 1631: 'divinity', 1632: 'd', 1633: 'likes', 1634: 'logic', 1635: 'mythology', 1636: 'thayology', 1637: 'conchology', 1638: 'sinners', 1639: 'wishful', 1640: 'childer', 1641: 'avick', 1642: 'gad', 1643: 'flock', 1644: 'grandest', 1645: 'control', 1646: 'checking', 1647: 'coaxin', 1648: 'onaisy', 1649: 'lifting', 1650: 'avoidin', 1651: 'frivolity', 1652: 'seasons', 1653: 'innocent', 1654: 'jollity', 1655: 'playboy', 1656: 'claim', 1657: 'equality', 1658: 'comicality', 1659: 'bishop', 1660: 'lave', 1661: 'gaiety', 1662: 'laity', 1663: 'clergy', 1664: 'jewels', 1665: 'plundering', 1666: 'pillage', 1667: 'starved', 1668: 'cries', 1669: 'thems', 1670: 'bondage', 1671: 'fourth', 1672: 'tabhair', 1673: 'dom', 1674: 'lã¡mh', 1675: 'harmony', 1676: 'east', 1677: 'destroy', 1678: 'command', 1679: 'gesture', 1680: 'troubles', 1681: 'weak', 1682: 'peoples', 1683: 'creeds', 1684: 'lets', 1685: 'needs', 1686: 'passion', 1687: 'fashion', 1688: 'guide', 1689: 'share', 1690: 'sparkling', 1691: 'meeting', 1692: 'iull', 1693: 'contented', 1694: 'ache', 1695: 'painful', 1696: 'wrote', 1697: 'twisted', 1698: 'twined', 1699: 'cheek', 1700: 'bedim', 1701: 'holds', 1702: 'smiles', 1703: 'scarcely', 1704: 'darkning', 1705: 'beyond', 1706: 'yearn', 1707: 'laughs', 1708: 'humble', 1709: 'brightest', 1710: 'gleam', 1711: 'forgot', 1712: 'pulled', 1713: 'comb', 1714: 'counting', 1715: 'knock', 1716: 'murray', 1717: 'fellow', 1718: 'hail', 1719: 'tumblin', 1720: 'apple', 1721: 'pie', 1722: 'gets', 1723: 'doleful', 1724: 'enemy', 1725: 'nearly', 1726: 'slew', 1727: 'queer', 1728: 'mild', 1729: 'legs', 1730: 'indeed', 1731: 'island', 1732: 'sulloon', 1733: 'flesh', 1734: 'yere', 1735: 'armless', 1736: 'boneless', 1737: 'chickenless', 1738: 'egg', 1739: 'yell', 1740: 'bowl', 1741: 'rolling', 1742: 'swearing', 1743: 'rattled', 1744: 'saber', 1745: 'deceiver', 1746: 'rig', 1747: 'um', 1748: 'du', 1749: 'rum', 1750: 'jar', 1751: 'shinin', 1752: 'coins', 1753: 'promised', 1754: 'vowed', 1755: 'devils', 1756: 'awakened', 1757: 'six', 1758: 'guards', 1759: 'numbers', 1760: 'odd', 1761: 'flew', 1762: 'mistaken', 1763: 'mollys', 1764: 'robbing', 1765: 'sentry', 1766: 'sligo', 1767: 'fishin', 1768: 'bowlin', 1769: 'others', 1770: 'railroad', 1771: 'ties', 1772: 'crossings', 1773: 'swamps', 1774: 'elevations', 1775: 'resolved', 1776: 'sunset', 1777: 'higher', 1778: 'win', 1779: 'allegators', 1780: 'wood', 1781: 'treated', 1782: 'shoulders', 1783: 'paint', 1784: 'picture', 1785: 'vain', 1786: 'returned', 1787: 'cottage', 1788: 'sociable', 1789: 'foaming', 1790: 'n', 1791: 'jeremy', 1792: 'lanigan', 1793: 'battered', 1794: 'hadnt', 1795: 'pound', 1796: 'farm', 1797: 'acres', 1798: 'party', 1799: 'listen', 1800: 'glisten', 1801: 'rows', 1802: 'ructions', 1803: 'invitation', 1804: 'minute', 1805: 'bees', 1806: 'cask', 1807: 'judy', 1808: 'odaly', 1809: 'milliner', 1810: 'wink', 1811: 'peggy', 1812: 'mcgilligan', 1813: 'lashings', 1814: 'punch', 1815: 'cakes', 1816: 'bacon', 1817: 'tea', 1818: 'nolans', 1819: 'dolans', 1820: 'ogradys', 1821: 'sounded', 1822: 'taras', 1823: 'hall', 1824: 'nelly', 1825: 'gray', 1826: 'rat', 1827: 'catchers', 1828: 'doing', 1829: 'kinds', 1830: 'nonsensical', 1831: 'polkas', 1832: 'whirligig', 1833: 'julia', 1834: 'banished', 1835: 'nonsense', 1836: 'twist', 1837: 'jig', 1838: 'mavrone', 1839: 'mad', 1840: 'ceiling', 1841: 'brooks', 1842: 'academy', 1843: 'learning', 1844: 'learn', 1845: 'couples', 1846: 'groups', 1847: 'accident', 1848: 'happened', 1849: 'terrance', 1850: 'mccarthy', 1851: 'finnertys', 1852: 'hoops', 1853: 'cried', 1854: 'meelia', 1855: 'murther', 1856: 'gathered', 1857: 'carmody', 1858: 'further', 1859: 'satisfaction', 1860: 'midst', 1861: 'kerrigan', 1862: 'declared', 1863: 'painted', 1864: 'suppose', 1865: 'morgan', 1866: 'powerful', 1867: 'stretched', 1868: 'smashed', 1869: 'chaneys', 1870: 'runctions', 1871: 'lick', 1872: 'phelim', 1873: 'mchugh', 1874: 'replied', 1875: 'introduction', 1876: 'kicked', 1877: 'terrible', 1878: 'hullabaloo', 1879: 'piper', 1880: 'strangled', 1881: 'squeezed', 1882: 'bellows', 1883: 'chanters', 1884: 'entangled', 1885: 'gaily', 1886: 'mairis', 1887: 'hillways', 1888: 'myrtle', 1889: 'bracken', 1890: 'sheilings', 1891: 'sake', 1892: 'rowans', 1893: 'herring', 1894: 'meal', 1895: 'peat', 1896: 'creel', 1897: 'bairns', 1898: 'weel', 1899: 'toast', 1900: 'soar', 1901: 'blackbird', 1902: 'note', 1903: 'linnet', 1904: 'lure', 1905: 'cozy', 1906: 'catch', 1907: 'company', 1908: 'harm', 1909: 'wit', 1910: 'recall', 1911: 'leisure', 1912: 'awhile', 1913: 'sorely', 1914: 'ruby', 1915: 'enthralled', 1916: 'sorry', 1917: 'theyd', 1918: 'falls', 1919: 'lot', 1920: 'tuned', 1921: 'bough', 1922: 'cow', 1923: 'chanting', 1924: 'melodious', 1925: 'scarce', 1926: 'soothed', 1927: 'solace', 1928: 'courtesy', 1929: 'salute', 1930: 'amiable', 1931: 'captive', 1932: 'slave', 1933: 'future', 1934: 'banter', 1935: 'enamour', 1936: 'indies', 1937: 'afford', 1938: 'transparently', 1939: 'flame', 1940: 'add', 1941: 'fuel', 1942: 'grant', 1943: 'desire', 1944: 'expire', 1945: 'wealth', 1946: 'damer', 1947: 'african', 1948: 'devonshire', 1949: 'lamp', 1950: 'alladin', 1951: 'genie', 1952: 'also', 1953: 'withdraw', 1954: 'tease', 1955: 'single', 1956: 'airy', 1957: 'embarrass', 1958: 'besides', 1959: 'almanack', 1960: 'useless', 1961: 'date', 1962: 'ware', 1963: 'rate', 1964: 'fragrance', 1965: 'loses', 1966: 'consumed', 1967: 'october', 1968: 'knowing', 1969: 'steer', 1970: 'blast', 1971: 'danger', 1972: 'farthing', 1973: 'affection', 1974: 'enjoy', 1975: 'choose', 1976: 'killarneys', 1977: 'sister', 1978: 'pains', 1979: 'loss', 1980: 'tuam', 1981: 'saluted', 1982: 'drank', 1983: 'pint', 1984: 'smother', 1985: 'reap', 1986: 'cut', 1987: 'goblins', 1988: 'bought', 1989: 'brogues', 1990: 'rattling', 1991: 'bogs', 1992: 'frightning', 1993: 'dogs', 1994: 'hunt', 1995: 'hare', 1996: 'follol', 1997: 'rah', 1998: 'mullingar', 1999: 'rested', 2000: 'limbs', 2001: 'blithe', 2002: 'heartfrom', 2003: 'paddys', 2004: 'cure', 2005: 'lassies', 2006: 'laughing', 2007: 'curious', 2008: 'style', 2009: 'twould', 2010: 'bubblin', 2011: 'hired', 2012: 'wages', 2013: 'required', 2014: 'almost', 2015: 'deprived', 2016: 'stroll', 2017: 'quality', 2018: 'locality', 2019: 'something', 2020: 'wobblin', 2021: 'enquiring', 2022: 'rogue', 2023: 'brogue', 2024: 'wasnt', 2025: 'vogue', 2026: 'spirits', 2027: 'falling', 2028: 'jumped', 2029: 'aboard', 2030: 'pigs', 2031: 'rigs', 2032: 'jigs', 2033: 'bubbling', 2034: 'holyhead', 2035: 'wished', 2036: 'instead', 2037: 'bouys', 2038: 'liverpool', 2039: 'safely', 2040: 'fool', 2041: 'boil', 2042: 'temper', 2043: 'losing', 2044: 'abusing', 2045: 'shillelagh', 2046: 'nigh', 2047: 'hobble', 2048: 'load', 2049: 'hurray', 2050: 'joined', 2051: 'affray', 2052: 'quitely', 2053: 'cleared', 2054: 'host', 2055: 'march', 2056: 'faces', 2057: 'farmstead', 2058: 'fishers', 2059: 'ban', 2060: 'vengeance', 2061: 'hapless', 2062: 'about', 2063: 'hemp', 2064: 'rope', 2065: 'clung', 2066: 'grim', 2067: 'array', 2068: 'earnest', 2069: 'stalwart', 2070: 'stainless', 2071: 'banner', 2072: 'marching', 2073: 'torn', 2074: 'furious', 2075: 'odds', 2076: 'keen', 2077: 'toomebridge', 2078: 'treads', 2079: 'upwards', 2080: 'traveled', 2081: 'quarters', 2082: 'below', 2083: 'hogshead', 2084: 'stack', 2085: 'stagger', 2086: 'dig', 2087: 'hole', 2088: 'couple', 2089: 'scratch', 2090: 'consolation', 2091: 'tyrant', 2092: 'remorseless', 2093: 'foe', 2094: 'lift', 2095: 'stranded', 2096: 'prince', 2097: 'edward', 2098: 'coffee', 2099: 'trace', 2100: 'fiddlin', 2101: 'dime', 2102: 'shy', 2103: 'hello', 2104: 'wintry', 2105: 'yellow', 2106: 'somewhere', 2107: 'written', 2108: 'begin', 2109: 'tap', 2110: 'caught', 2111: 'leap', 2112: 'clumsy', 2113: 'graceful', 2114: 'fiddlers', 2115: 'everywhere', 2116: 'boots', 2117: 'laughtcr', 2118: 'suits', 2119: 'easter', 2120: 'gowns', 2121: 'sailors', 2122: 'pianos', 2123: 'setting', 2124: 'someones', 2125: 'hats', 2126: 'rack', 2127: 'chair', 2128: 'wooden', 2129: 'feels', 2130: 'touch', 2131: 'awaitin', 2132: 'thc', 2133: 'fiddles', 2134: 'closet', 2135: 'strings', 2136: 'tbe', 2137: 'covers', 2138: 'buttoned', 2139: 'sometimes', 2140: 'melody', 2141: 'passes', 2142: 'slight', 2143: 'lack', 2144: 'moved', 2145: 'homeward', 2146: 'swan', 2147: 'moves', 2148: 'goods', 2149: 'gear', 2150: 'din', 2151: 'rude', 2152: 'wherein', 2153: 'dwell', 2154: 'abandon', 2155: 'energy', 2156: 'blight', 2157: 'praties', 2158: 'sheep', 2159: 'cattle', 2160: 'taxes', 2161: 'unpaid', 2162: 'redeem', 2163: 'bleak', 2164: 'landlord', 2165: 'sheriff', 2166: 'spleen', 2167: 'heaved', 2168: 'sigh', 2169: 'bade', 2170: 'goodbye', 2171: 'stony', 2172: 'anguish', 2173: 'seeing', 2174: 'feeble', 2175: 'frame', 2176: 'wrapped', 2177: 'cï¿½ta', 2178: 'mï¿½r', 2179: 'unseen', 2180: 'stern', 2181: 'rally', 2182: 'cheer', 2183: 'revenge', 2184: 'waking', 2185: 'wisdom', 2186: 'dwelling', 2187: 'battleshield', 2188: 'dignity', 2189: 'shelter', 2190: 'heed', 2191: 'inheritance', 2192: 'heavem', 2193: 'heaven', 2194: 'victory', 2195: 'reach', 2196: 'whatever', 2197: 'befall', 2198: 'ruler', 2199: 'pleasant', 2200: 'rambling', 2201: 'board', 2202: 'followed', 2203: 'shortly', 2204: 'anchor', 2205: '23rd', 2206: 'lrelands', 2207: 'daughters', 2208: 'crowds', 2209: 'assembled', 2210: 'fulfill', 2211: 'jovial', 2212: 'conversations', 2213: 'neighbors', 2214: 'turning', 2215: 'tailor', 2216: 'quigley', 2217: 'bould', 2218: 'britches', 2219: 'lived', 2220: 'flying', 2221: 'dove', 2222: 'hiii', 2223: 'dreamt', 2224: 'joking', 2225: 'manys', 2226: 'cock', 2227: 'shrill', 2228: 'awoke', 2229: 'california', 2230: 'miles', 2231: 'banbridge', 2232: 'july', 2233: 'boreen', 2234: 'sheen', 2235: 'coaxing', 2236: 'elf', 2237: 'shake', 2238: 'bantry', 2239: 'onward', 2240: 'sped', 2241: 'gazed', 2242: 'passerby', 2243: 'gem', 2244: 'irelands', 2245: 'travelled', 2246: 'hit', 2247: 'career', 2248: 'square', 2249: 'surrendered', 2250: 'tenant', 2251: 'shawl', 2252: 'gown', 2253: 'crossroads', 2254: 'dress', 2255: 'try', 2256: 'sheeps', 2257: 'deludhering', 2258: 'yoke', 2259: 'rust', 2260: 'plow', 2261: 'fireside', 2262: 'sits', 2263: 'whistle', 2264: 'changing', 2265: 'fright', 2266: 'downfall', 2267: 'cornwall', 2268: 'parlour', 2269: 'passing', 2270: 'william', 2271: 'betray', 2272: 'guinea', 2273: 'walking', 2274: 'mounted', 2275: 'platform', 2276: 'deny', 2277: 'walked', 2278: 'margin', 2279: 'lough', 2280: 'leane', 2281: 'bloomed', 2282: 'whom', 2283: 'cap', 2284: 'cloak', 2285: 'glossy', 2286: 'pail', 2287: 'palm', 2288: 'venus', 2289: 'bank', 2290: 'travelians', 2291: 'babes', 2292: 'freebirds', 2293: 'grew', 2294: 'matters', 2295: 'famine', 2296: 'rebelled', 2297: 'windswept', 2298: 'harbour', 2299: 'botany', 2300: 'whilst', 2301: 'wan', 2302: 'cloud', 2303: 'shannons', 2304: 'returnd', 2305: 'doubts', 2306: 'fears', 2307: 'aching', 2308: 'seemd', 2309: 'mingling', 2310: 'flood', 2311: 'path', 2312: 'wrath', 2313: 'lamenting', 2314: 'sudden', 2315: 'kissd', 2316: 'showrs', 2317: 'flowing', 2318: 'laughd', 2319: 'beam', 2320: 'soared', 2321: 'aloft', 2322: 'phantom', 2323: 'outspread', 2324: 'throbbing', 2325: 'hid', 2326: 'treasures', 2327: 'pots', 2328: 'tin', 2329: 'cans', 2330: 'mash', 2331: 'bran', 2332: 'barney', 2333: 'peeled', 2334: 'searching', 2335: 'connemara', 2336: 'butcher', 2337: 'quart', 2338: 'bottle', 2339: 'help', 2340: 'gate', 2341: 'glory', 2342: 'lane', 2343: 'village', 2344: 'church', 2345: 'spire', 2346: 'graveyard', 2347: 'baby', 2348: 'blessing', 2349: 'hoping', 2350: 'trust', 2351: 'strength', 2352: 'thank', 2353: 'bidding', 2354: 'bread', 2355: 'shines', 2356: 'fifty', 2357: 'often', 2358: 'shut', 2359: 'frisky', 2360: 'pig', 2361: 'whisky', 2362: 'uncle', 2363: 'enlisted', 2364: 'trudged', 2365: 'bosom', 2366: 'daisy', 2367: 'drubbing', 2368: 'shirts', 2369: 'battle', 2370: 'blows', 2371: 'pate', 2372: 'bothered', 2373: 'rarely', 2374: 'dropped', 2375: 'honest', 2376: 'thinks', 2377: 'eight', 2378: 'score', 2379: 'basin', 2380: 'zoo', 2381: 'everybody', 2382: 'calls', 2383: 'trades', 2384: 'dinner', 2385: 'slip', 2386: 'corner', 2387: 'barn', 2388: 'currabawn', 2389: 'shocking', 2390: 'wet', 2391: 'raindrops', 2392: 'rats', 2393: 'peek', 2394: 'waken', 2395: 'spotted', 2396: 'apron', 2397: 'calico', 2398: 'blouse', 2399: 'frighten', 2400: 'afraid', 2401: 'flaxen', 2402: 'haired', 2403: 'rags', 2404: 'tags', 2405: 'leggins', 2406: 'collar', 2407: 'tie', 2408: 'goggles', 2409: 'fashioned', 2410: 'bag', 2411: 'bulging', 2412: 'sack', 2413: 'peeping', 2414: 'skin', 2415: 'rink', 2416: 'doodle', 2417: 'getting', 2418: 'raked', 2419: 'gladness', 2420: 'tuning', 2421: 'fills', 2422: 'eily', 2423: 'prouder', 2424: 'thady', 2425: 'boldly', 2426: 'lasses', 2427: 'fled', 2428: 'silent', 2429: 'glad', 2430: 'echo', 2431: 'companions', 2432: 'soars', 2433: 'enchanted', 2434: 'granted', 2435: 'adoration', 2436: 'gives', 2437: 'joyous', 2438: 'elation', 2439: 'covered', 2440: 'winter', 2441: 'riding', 2442: 'cherry', 2443: 'coal', 2444: 'falter', 2445: 'bowed', 2446: 'bonnet', 2447: 'courteous', 2448: 'looks', 2449: 'engaging', 2450: 'sell', 2451: 'purse', 2452: 'yearly', 2453: 'need', 2454: 'market', 2455: 'gain', 2456: 'dearly', 2457: 'tarry', 2458: 'although', 2459: 'parlay', 2460: 'ranks', 2461: 'girded', 2462: 'slung', 2463: 'warrior', 2464: 'bard', 2465: 'betrays', 2466: 'rights', 2467: 'faithful', 2468: 'chords', 2469: 'asunder', 2470: 'sully', 2471: 'bravry', 2472: 'londons', 2473: 'sight', 2474: 'workin', 2475: 'sow', 2476: 'wheat', 2477: 'gangs', 2478: 'sweep', 2479: 'expressed', 2480: 'london', 2481: 'top', 2482: 'dresses', 2483: 'bath', 2484: 'startin', 2485: 'fashions', 2486: 'mccree', 2487: 'nature', 2488: 'designed', 2489: 'complexions', 2490: 'cream', 2491: 'regard', 2492: 'sip', 2493: 'colors', 2494: 'wait', 2495: 'waitin', 2496: 'sweeps', 2497: 'beauing', 2498: 'belling', 2499: 'windows', 2500: 'cursing', 2501: 'faster', 2502: 'waiters', 2503: 'bailiffs', 2504: 'duns', 2505: 'bacchus', 2506: 'begotten', 2507: 'politicians', 2508: 'funds', 2509: 'dadda', 2510: 'living', 2511: 'drives', 2512: 'having', 2513: 'racking', 2514: 'tenants', 2515: 'stewards', 2516: 'teasing', 2517: 'raising', 2518: 'wishing', 2519: 'sunny', 2520: 'doves', 2521: 'coo', 2522: 'neath', 2523: 'sunbeam', 2524: 'robin', 2525: 'waters', 2526: 'larks', 2527: 'join', 2528: 'breaks', 2529: 'oftimes', 2530: 'lilies', 2531: 'declining', 2532: 'vale', 2533: 'shades', 2534: 'mantle', 2535: 'spreading', 2536: 'listening', 2537: 'shedding', 2538: 'beginning', 2539: 'spinning', 2540: 'blind', 2541: 'drowsily', 2542: 'knitting', 2543: 'cheerily', 2544: 'noiselessly', 2545: 'whirring', 2546: 'foots', 2547: 'stirring', 2548: 'sprightly', 2549: 'chara', 2550: 'tapping', 2551: 'ivy', 2552: 'flapping', 2553: 'somebody', 2554: 'sighing', 2555: 'autumn', 2556: 'noise', 2557: 'chirping', 2558: 'holly', 2559: 'shoving', 2560: 'wrong', 2561: 'coolin', 2562: 'casement', 2563: 'rove', 2564: 'moons', 2565: 'brightly', 2566: 'shakes', 2567: 'lays', 2568: 'longs', 2569: 'lingers', 2570: 'glance', 2571: 'puts', 2572: 'lazily', 2573: 'easily', 2574: 'lowly', 2575: 'reels', 2576: 'noiseless', 2577: 'leaps', 2578: 'ere', 2579: 'lovers', 2580: 'roved', 2581: 'verdant', 2582: 'braes', 2583: 'skreen', 2584: 'countrie', 2585: 'foreign', 2586: 'strand', 2587: 'dewy', 2588: 'climb', 2589: 'rob', 2590: 'boat', 2591: 'sails', 2592: 'loaded', 2593: 'sink', 2594: 'leaned', 2595: 'oak', 2596: 'trusty', 2597: 'false', 2598: 'reached', 2599: 'pricked', 2600: 'waxes', 2601: 'fades', 2602: 'wholl', 2603: 'cockle', 2604: 'gloom', 2605: 'news', 2606: 'forbid', 2607: 'patricks', 2608: 'napper', 2609: 'tandy', 2610: 'hows', 2611: 'distressful', 2612: 'englands', 2613: 'remind', 2614: 'pull', 2615: 'throw', 2616: 'sod', 2617: 'root', 2618: 'underfoot', 2619: 'laws', 2620: 'blades', 2621: 'growin', 2622: 'dare', 2623: 'show', 2624: 'caubeen', 2625: 'year', 2626: 'returning', 2627: 'store', 2628: 'ale', 2629: 'frequent', 2630: 'landlady', 2631: 'credit', 2632: 'custom', 2633: 'sovereigns', 2634: 'landladys', 2635: 'wines', 2636: 'confess', 2637: 'pardon', 2638: 'prodigal', 2639: 'caress', 2640: 'forgive', 2641: 'ofttimes', 2642: 'wondering', 2643: 'powr', 2644: 'beguile', 2645: 'teardrop', 2646: 'lilting', 2647: 'laughters', 2648: 'twinkle', 2649: 'lilt', 2650: 'seems', 2651: 'linnets', 2652: 'real', 2653: 'regret', 2654: 'throughout', 2655: 'youths', 2656: 'chance', 2657: 'spied', 2658: 'receiver', 2659: 'counted', 2660: 'penny', 2661: 'bu', 2662: 'rungum', 2663: 'chamber', 2664: 'course', 2665: 'charges', 2666: 'filled', 2667: 'ready', 2668: 'footmen', 2669: 'likewise', 2670: 'draw', 2671: 'pistol', 2672: 'couldnt', 2673: 'shoot', 2674: 'robbin', 2675: 'jailer', 2676: 'tight', 2677: 'fisted', 2678: 'army', 2679: 'stationed', 2680: 'cork', 2681: 'roamin', 2682: 'swear', 2683: 'treat', 2684: 'sportin', 2685: 'hurley', 2686: 'bollin', 2687: 'maids', 2688: 'summertime', 2689: 'pluck', 2690: 'yon'}\n"
     ]
    }
   ],
   "source": [
    "## create reverse_word_index\n",
    "reverse_word_index = {}\n",
    "for word, i in word_index.items():\n",
    "    reverse_word_index[i] = word\n",
    "print(reverse_word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Sentences to Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 52 13]\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "new_seq = []\n",
    "for row in sequences:\n",
    "    for i in range(2, len(row)+1):\n",
    "        new_seq.append(row[:i])\n",
    "padded_seq = pad_sequences(new_seq, padding=PADDING, truncating=TRUNC)\n",
    "print(padded_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract trainX and trainY from sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13730, 16)\n",
      "(13730, 2691)\n"
     ]
    }
   ],
   "source": [
    "trainX = padded_seq[:,:-1]\n",
    "trainY = padded_seq[:,-1]\n",
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=total_words)\n",
    "\n",
    "INP_LEN = trainX.shape[1]\n",
    "OUT_LEN = trainY.shape[1]\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epochs, log={}):\n",
    "        if (log.get('acc')>0.90):\n",
    "            self.model.stop_training = True\n",
    "            print(\"\\n Stopped training since model reached accuracy of 90%\")\n",
    "callback = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(total_words, EMB_DIM, input_length=INP_LEN),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(total_words, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 16, 128)           344448    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2691)              174915    \n",
      "=================================================================\n",
      "Total params: 560,579\n",
      "Trainable params: 560,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12357 samples, validate on 1373 samples\n",
      "WARNING:tensorflow:From C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "12357/12357 [==============================] - 9s 729us/sample - loss: 6.7922 - acc: 0.1160 - val_loss: 6.2226 - val_acc: 0.1253\n",
      "Epoch 2/500\n",
      "12357/12357 [==============================] - 6s 499us/sample - loss: 6.0098 - acc: 0.1230 - val_loss: 6.2186 - val_acc: 0.1253\n",
      "Epoch 3/500\n",
      "12357/12357 [==============================] - 6s 474us/sample - loss: 5.8807 - acc: 0.1230 - val_loss: 6.2006 - val_acc: 0.1253\n",
      "Epoch 4/500\n",
      "12357/12357 [==============================] - 6s 470us/sample - loss: 5.7892 - acc: 0.1230 - val_loss: 6.2192 - val_acc: 0.1253\n",
      "Epoch 5/500\n",
      "12357/12357 [==============================] - 6s 469us/sample - loss: 5.7213 - acc: 0.1283 - val_loss: 6.2344 - val_acc: 0.1333\n",
      "Epoch 6/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 5.6626 - acc: 0.1451 - val_loss: 6.2509 - val_acc: 0.1420\n",
      "Epoch 7/500\n",
      "12357/12357 [==============================] - 6s 517us/sample - loss: 5.6155 - acc: 0.1533 - val_loss: 6.2520 - val_acc: 0.1435\n",
      "Epoch 8/500\n",
      "12357/12357 [==============================] - 7s 551us/sample - loss: 5.5727 - acc: 0.1586 - val_loss: 6.2593 - val_acc: 0.1486\n",
      "Epoch 9/500\n",
      "12357/12357 [==============================] - 6s 508us/sample - loss: 5.5340 - acc: 0.1646 - val_loss: 6.2763 - val_acc: 0.1464\n",
      "Epoch 10/500\n",
      "12357/12357 [==============================] - 6s 517us/sample - loss: 5.4987 - acc: 0.1682 - val_loss: 6.2668 - val_acc: 0.1486\n",
      "Epoch 11/500\n",
      "12357/12357 [==============================] - 6s 463us/sample - loss: 5.4635 - acc: 0.1699 - val_loss: 6.2790 - val_acc: 0.1500\n",
      "Epoch 12/500\n",
      "12357/12357 [==============================] - 6s 484us/sample - loss: 5.4301 - acc: 0.1712 - val_loss: 6.2750 - val_acc: 0.1479\n",
      "Epoch 13/500\n",
      "12357/12357 [==============================] - 6s 495us/sample - loss: 5.3947 - acc: 0.1726 - val_loss: 6.2788 - val_acc: 0.1486\n",
      "Epoch 14/500\n",
      "12357/12357 [==============================] - 6s 491us/sample - loss: 5.3532 - acc: 0.1737 - val_loss: 6.2756 - val_acc: 0.1537\n",
      "Epoch 15/500\n",
      "12357/12357 [==============================] - 6s 513us/sample - loss: 5.2987 - acc: 0.1762 - val_loss: 6.2588 - val_acc: 0.1566\n",
      "Epoch 16/500\n",
      "12357/12357 [==============================] - 6s 487us/sample - loss: 5.2479 - acc: 0.1778 - val_loss: 6.2724 - val_acc: 0.1602\n",
      "Epoch 17/500\n",
      "12357/12357 [==============================] - 6s 490us/sample - loss: 5.1979 - acc: 0.1829 - val_loss: 6.2652 - val_acc: 0.1595\n",
      "Epoch 18/500\n",
      "12357/12357 [==============================] - 6s 518us/sample - loss: 5.1505 - acc: 0.1889 - val_loss: 6.2616 - val_acc: 0.1631\n",
      "Epoch 19/500\n",
      "12357/12357 [==============================] - 6s 497us/sample - loss: 5.1052 - acc: 0.1962 - val_loss: 6.2624 - val_acc: 0.1595\n",
      "Epoch 20/500\n",
      "12357/12357 [==============================] - 6s 498us/sample - loss: 5.0578 - acc: 0.2045 - val_loss: 6.2944 - val_acc: 0.1537\n",
      "Epoch 21/500\n",
      "12357/12357 [==============================] - 6s 479us/sample - loss: 5.0126 - acc: 0.2081 - val_loss: 6.2724 - val_acc: 0.1631\n",
      "Epoch 22/500\n",
      "12357/12357 [==============================] - 6s 491us/sample - loss: 4.9637 - acc: 0.2111 - val_loss: 6.2975 - val_acc: 0.1588\n",
      "Epoch 23/500\n",
      "12357/12357 [==============================] - 6s 486us/sample - loss: 4.9093 - acc: 0.2143 - val_loss: 6.3328 - val_acc: 0.1559\n",
      "Epoch 24/500\n",
      "12357/12357 [==============================] - 6s 500us/sample - loss: 4.8576 - acc: 0.2195 - val_loss: 6.3652 - val_acc: 0.1566\n",
      "Epoch 25/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 4.8014 - acc: 0.2227 - val_loss: 6.3867 - val_acc: 0.1551\n",
      "Epoch 26/500\n",
      "12357/12357 [==============================] - 6s 496us/sample - loss: 4.7504 - acc: 0.2267 - val_loss: 6.4081 - val_acc: 0.1529\n",
      "Epoch 27/500\n",
      "12357/12357 [==============================] - 6s 486us/sample - loss: 4.7023 - acc: 0.2280 - val_loss: 6.4377 - val_acc: 0.1529\n",
      "Epoch 28/500\n",
      "12357/12357 [==============================] - 6s 525us/sample - loss: 4.6552 - acc: 0.2294 - val_loss: 6.4290 - val_acc: 0.1653\n",
      "Epoch 29/500\n",
      "12357/12357 [==============================] - 6s 493us/sample - loss: 4.6094 - acc: 0.2328 - val_loss: 6.4699 - val_acc: 0.1544\n",
      "Epoch 30/500\n",
      "12357/12357 [==============================] - 6s 494us/sample - loss: 4.5629 - acc: 0.2371 - val_loss: 6.4751 - val_acc: 0.1573\n",
      "Epoch 31/500\n",
      "12357/12357 [==============================] - 6s 495us/sample - loss: 4.5162 - acc: 0.2399 - val_loss: 6.4999 - val_acc: 0.1602\n",
      "Epoch 32/500\n",
      "12357/12357 [==============================] - 6s 492us/sample - loss: 4.4714 - acc: 0.2436 - val_loss: 6.5106 - val_acc: 0.1631\n",
      "Epoch 33/500\n",
      "12357/12357 [==============================] - 6s 500us/sample - loss: 4.4316 - acc: 0.2454 - val_loss: 6.5312 - val_acc: 0.1588\n",
      "Epoch 34/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 4.3874 - acc: 0.2489 - val_loss: 6.5316 - val_acc: 0.1551\n",
      "Epoch 35/500\n",
      "12357/12357 [==============================] - 6s 508us/sample - loss: 4.3464 - acc: 0.2516 - val_loss: 6.5618 - val_acc: 0.1537\n",
      "Epoch 36/500\n",
      "12357/12357 [==============================] - 6s 504us/sample - loss: 4.3026 - acc: 0.2558 - val_loss: 6.5811 - val_acc: 0.1551\n",
      "Epoch 37/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 4.2586 - acc: 0.2589 - val_loss: 6.5944 - val_acc: 0.1595\n",
      "Epoch 38/500\n",
      "12357/12357 [==============================] - 7s 538us/sample - loss: 4.2148 - acc: 0.2616 - val_loss: 6.6259 - val_acc: 0.1551\n",
      "Epoch 39/500\n",
      "12357/12357 [==============================] - 6s 494us/sample - loss: 4.1709 - acc: 0.2669 - val_loss: 6.6532 - val_acc: 0.1566\n",
      "Epoch 40/500\n",
      "12357/12357 [==============================] - 6s 506us/sample - loss: 4.1294 - acc: 0.2725 - val_loss: 6.6628 - val_acc: 0.1573\n",
      "Epoch 41/500\n",
      "12357/12357 [==============================] - 6s 502us/sample - loss: 4.0865 - acc: 0.2748 - val_loss: 6.6661 - val_acc: 0.1639\n",
      "Epoch 42/500\n",
      "12357/12357 [==============================] - ETA: 0s - loss: 4.0462 - acc: 0.279 - 6s 497us/sample - loss: 4.0475 - acc: 0.2795 - val_loss: 6.7022 - val_acc: 0.1617\n",
      "Epoch 43/500\n",
      "12357/12357 [==============================] - 6s 493us/sample - loss: 4.0033 - acc: 0.2832 - val_loss: 6.7205 - val_acc: 0.1580\n",
      "Epoch 44/500\n",
      "12357/12357 [==============================] - 6s 502us/sample - loss: 3.9594 - acc: 0.2857 - val_loss: 6.7404 - val_acc: 0.1573\n",
      "Epoch 45/500\n",
      "12357/12357 [==============================] - 6s 509us/sample - loss: 3.9145 - acc: 0.2917 - val_loss: 6.7689 - val_acc: 0.1544\n",
      "Epoch 46/500\n",
      "12357/12357 [==============================] - 6s 510us/sample - loss: 3.8662 - acc: 0.2933 - val_loss: 6.7935 - val_acc: 0.1515\n",
      "Epoch 47/500\n",
      "12357/12357 [==============================] - 7s 545us/sample - loss: 3.8186 - acc: 0.2972 - val_loss: 6.8210 - val_acc: 0.1537\n",
      "Epoch 48/500\n",
      "12357/12357 [==============================] - 6s 512us/sample - loss: 3.7764 - acc: 0.3029 - val_loss: 6.8426 - val_acc: 0.1529\n",
      "Epoch 49/500\n",
      "12357/12357 [==============================] - 6s 513us/sample - loss: 3.7366 - acc: 0.3057 - val_loss: 6.8540 - val_acc: 0.1522\n",
      "Epoch 50/500\n",
      "12357/12357 [==============================] - 6s 513us/sample - loss: 3.6966 - acc: 0.3112 - val_loss: 6.8869 - val_acc: 0.1515\n",
      "Epoch 51/500\n",
      "12357/12357 [==============================] - 6s 513us/sample - loss: 3.6471 - acc: 0.3144 - val_loss: 6.9077 - val_acc: 0.1529\n",
      "Epoch 52/500\n",
      "12357/12357 [==============================] - 6s 516us/sample - loss: 3.5967 - acc: 0.3171 - val_loss: 6.9274 - val_acc: 0.1493\n",
      "Epoch 53/500\n",
      "12357/12357 [==============================] - 6s 517us/sample - loss: 3.5502 - acc: 0.3247 - val_loss: 6.9441 - val_acc: 0.1479\n",
      "Epoch 54/500\n",
      "12357/12357 [==============================] - 6s 520us/sample - loss: 3.5034 - acc: 0.3285 - val_loss: 6.9715 - val_acc: 0.1493\n",
      "Epoch 55/500\n",
      "12357/12357 [==============================] - 6s 521us/sample - loss: 3.4533 - acc: 0.3344 - val_loss: 6.9842 - val_acc: 0.1500\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12357/12357 [==============================] - 6s 466us/sample - loss: 3.4108 - acc: 0.3395 - val_loss: 7.0137 - val_acc: 0.1508\n",
      "Epoch 57/500\n",
      "12357/12357 [==============================] - 6s 516us/sample - loss: 3.3747 - acc: 0.3434 - val_loss: 7.0259 - val_acc: 0.1544\n",
      "Epoch 58/500\n",
      "12357/12357 [==============================] - 6s 477us/sample - loss: 3.3290 - acc: 0.3483 - val_loss: 7.0651 - val_acc: 0.1508\n",
      "Epoch 59/500\n",
      "12357/12357 [==============================] - 6s 468us/sample - loss: 3.2899 - acc: 0.3587 - val_loss: 7.0613 - val_acc: 0.1500\n",
      "Epoch 60/500\n",
      "12357/12357 [==============================] - 6s 483us/sample - loss: 3.2439 - acc: 0.3621 - val_loss: 7.1071 - val_acc: 0.1508\n",
      "Epoch 61/500\n",
      "12357/12357 [==============================] - 6s 493us/sample - loss: 3.2038 - acc: 0.3651 - val_loss: 7.1468 - val_acc: 0.1537\n",
      "Epoch 62/500\n",
      "12357/12357 [==============================] - 6s 497us/sample - loss: 3.1643 - acc: 0.3728 - val_loss: 7.1591 - val_acc: 0.1515\n",
      "Epoch 63/500\n",
      "12357/12357 [==============================] - 6s 487us/sample - loss: 3.1216 - acc: 0.3766 - val_loss: 7.1703 - val_acc: 0.1522\n",
      "Epoch 64/500\n",
      "12357/12357 [==============================] - 6s 489us/sample - loss: 3.0842 - acc: 0.3801 - val_loss: 7.2233 - val_acc: 0.1551\n",
      "Epoch 65/500\n",
      "12357/12357 [==============================] - 6s 493us/sample - loss: 3.0475 - acc: 0.3880 - val_loss: 7.2164 - val_acc: 0.1508\n",
      "Epoch 66/500\n",
      "12357/12357 [==============================] - 6s 489us/sample - loss: 3.0054 - acc: 0.3939 - val_loss: 7.2544 - val_acc: 0.1559\n",
      "Epoch 67/500\n",
      "12357/12357 [==============================] - 7s 553us/sample - loss: 2.9657 - acc: 0.3986 - val_loss: 7.2827 - val_acc: 0.1515\n",
      "Epoch 68/500\n",
      "12357/12357 [==============================] - 7s 562us/sample - loss: 2.9349 - acc: 0.4028 - val_loss: 7.3127 - val_acc: 0.1559\n",
      "Epoch 69/500\n",
      "12357/12357 [==============================] - 6s 471us/sample - loss: 2.9014 - acc: 0.4094 - val_loss: 7.3452 - val_acc: 0.1544\n",
      "Epoch 70/500\n",
      "12357/12357 [==============================] - 6s 471us/sample - loss: 2.8637 - acc: 0.4159 - val_loss: 7.3734 - val_acc: 0.1515\n",
      "Epoch 71/500\n",
      "12357/12357 [==============================] - ETA: 0s - loss: 2.8242 - acc: 0.421 - 6s 470us/sample - loss: 2.8272 - acc: 0.4208 - val_loss: 7.3806 - val_acc: 0.1500\n",
      "Epoch 72/500\n",
      "12357/12357 [==============================] - 6s 471us/sample - loss: 2.7945 - acc: 0.4287 - val_loss: 7.4188 - val_acc: 0.1522\n",
      "Epoch 73/500\n",
      "12357/12357 [==============================] - 6s 471us/sample - loss: 2.7668 - acc: 0.4301 - val_loss: 7.4547 - val_acc: 0.1515\n",
      "Epoch 74/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 2.7320 - acc: 0.4360 - val_loss: 7.4594 - val_acc: 0.1529\n",
      "Epoch 75/500\n",
      "12357/12357 [==============================] - 6s 495us/sample - loss: 2.7053 - acc: 0.4407 - val_loss: 7.4776 - val_acc: 0.1580\n",
      "Epoch 76/500\n",
      "12357/12357 [==============================] - 7s 591us/sample - loss: 2.6793 - acc: 0.4461 - val_loss: 7.4988 - val_acc: 0.1537\n",
      "Epoch 77/500\n",
      "12357/12357 [==============================] - 7s 589us/sample - loss: 2.6431 - acc: 0.4516 - val_loss: 7.5161 - val_acc: 0.1559\n",
      "Epoch 78/500\n",
      "12357/12357 [==============================] - 6s 510us/sample - loss: 2.6096 - acc: 0.4607 - val_loss: 7.5460 - val_acc: 0.1544\n",
      "Epoch 79/500\n",
      "12357/12357 [==============================] - 7s 564us/sample - loss: 2.5798 - acc: 0.4648 - val_loss: 7.5850 - val_acc: 0.1529\n",
      "Epoch 80/500\n",
      "12357/12357 [==============================] - 7s 546us/sample - loss: 2.5490 - acc: 0.4721 - val_loss: 7.5830 - val_acc: 0.1508\n",
      "Epoch 81/500\n",
      "12357/12357 [==============================] - 6s 497us/sample - loss: 2.5215 - acc: 0.4744 - val_loss: 7.6107 - val_acc: 0.1522\n",
      "Epoch 82/500\n",
      "12357/12357 [==============================] - 6s 508us/sample - loss: 2.4992 - acc: 0.4805 - val_loss: 7.6457 - val_acc: 0.1449\n",
      "Epoch 83/500\n",
      "12357/12357 [==============================] - 6s 513us/sample - loss: 2.4746 - acc: 0.4855 - val_loss: 7.6710 - val_acc: 0.1471\n",
      "Epoch 84/500\n",
      "12357/12357 [==============================] - 6s 508us/sample - loss: 2.4517 - acc: 0.4877 - val_loss: 7.6953 - val_acc: 0.1500\n",
      "Epoch 85/500\n",
      "12357/12357 [==============================] - 6s 495us/sample - loss: 2.4200 - acc: 0.4934 - val_loss: 7.7172 - val_acc: 0.1508\n",
      "Epoch 86/500\n",
      "12357/12357 [==============================] - 7s 530us/sample - loss: 2.3963 - acc: 0.5011 - val_loss: 7.7587 - val_acc: 0.1493\n",
      "Epoch 87/500\n",
      "12357/12357 [==============================] - 6s 502us/sample - loss: 2.3714 - acc: 0.5034 - val_loss: 7.7606 - val_acc: 0.1522\n",
      "Epoch 88/500\n",
      "12357/12357 [==============================] - 6s 494us/sample - loss: 2.3555 - acc: 0.5051 - val_loss: 7.7751 - val_acc: 0.1428\n",
      "Epoch 89/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 2.3219 - acc: 0.5105 - val_loss: 7.8098 - val_acc: 0.1428\n",
      "Epoch 90/500\n",
      "12357/12357 [==============================] - 6s 504us/sample - loss: 2.3062 - acc: 0.5133 - val_loss: 7.8378 - val_acc: 0.1435\n",
      "Epoch 91/500\n",
      "12357/12357 [==============================] - 6s 489us/sample - loss: 2.2872 - acc: 0.5185 - val_loss: 7.8502 - val_acc: 0.1391\n",
      "Epoch 92/500\n",
      "12357/12357 [==============================] - 6s 491us/sample - loss: 2.2605 - acc: 0.5232 - val_loss: 7.8663 - val_acc: 0.1398\n",
      "Epoch 93/500\n",
      "12357/12357 [==============================] - 6s 495us/sample - loss: 2.2448 - acc: 0.5265 - val_loss: 7.9109 - val_acc: 0.1406\n",
      "Epoch 94/500\n",
      "12357/12357 [==============================] - 6s 500us/sample - loss: 2.2210 - acc: 0.5242 - val_loss: 7.9281 - val_acc: 0.1406\n",
      "Epoch 95/500\n",
      "12357/12357 [==============================] - 7s 528us/sample - loss: 2.1920 - acc: 0.5319 - val_loss: 7.9355 - val_acc: 0.142033 - acc: 0.531\n",
      "Epoch 96/500\n",
      "12357/12357 [==============================] - 6s 493us/sample - loss: 2.1625 - acc: 0.5393 - val_loss: 7.9964 - val_acc: 0.1406\n",
      "Epoch 97/500\n",
      "12357/12357 [==============================] - 6s 491us/sample - loss: 2.1494 - acc: 0.5401 - val_loss: 8.0221 - val_acc: 0.1362\n",
      "Epoch 98/500\n",
      "12357/12357 [==============================] - 6s 507us/sample - loss: 2.1281 - acc: 0.5461 - val_loss: 8.0179 - val_acc: 0.1420\n",
      "Epoch 99/500\n",
      "12357/12357 [==============================] - 7s 560us/sample - loss: 2.1004 - acc: 0.5546 - val_loss: 8.0493 - val_acc: 0.1398\n",
      "Epoch 100/500\n",
      "12357/12357 [==============================] - 6s 514us/sample - loss: 2.0854 - acc: 0.5520 - val_loss: 8.0556 - val_acc: 0.1406\n",
      "Epoch 101/500\n",
      "12357/12357 [==============================] - 6s 509us/sample - loss: 2.0656 - acc: 0.5616 - val_loss: 8.0975 - val_acc: 0.1398\n",
      "Epoch 102/500\n",
      "12357/12357 [==============================] - 6s 516us/sample - loss: 2.0453 - acc: 0.5611 - val_loss: 8.1091 - val_acc: 0.1377\n",
      "Epoch 103/500\n",
      "12357/12357 [==============================] - 6s 520us/sample - loss: 2.0340 - acc: 0.5650 - val_loss: 8.1087 - val_acc: 0.1369\n",
      "Epoch 104/500\n",
      "12357/12357 [==============================] - 6s 525us/sample - loss: 2.0127 - acc: 0.5726 - val_loss: 8.1580 - val_acc: 0.1326\n",
      "Epoch 105/500\n",
      "12357/12357 [==============================] - 9s 694us/sample - loss: 1.9976 - acc: 0.5724 - val_loss: 8.1494 - val_acc: 0.1406\n",
      "Epoch 106/500\n",
      "12357/12357 [==============================] - 6s 486us/sample - loss: 1.9735 - acc: 0.5748 - val_loss: 8.2267 - val_acc: 0.1377\n",
      "Epoch 107/500\n",
      "12357/12357 [==============================] - 6s 463us/sample - loss: 1.9650 - acc: 0.5791 - val_loss: 8.2019 - val_acc: 0.1369\n",
      "Epoch 108/500\n",
      "12357/12357 [==============================] - 7s 558us/sample - loss: 1.9404 - acc: 0.5844 - val_loss: 8.2309 - val_acc: 0.1406\n",
      "Epoch 109/500\n",
      "12357/12357 [==============================] - 7s 537us/sample - loss: 1.9221 - acc: 0.5883 - val_loss: 8.2647 - val_acc: 0.1391\n",
      "Epoch 110/500\n",
      "12357/12357 [==============================] - 6s 521us/sample - loss: 1.9036 - acc: 0.5929 - val_loss: 8.2771 - val_acc: 0.1377\n",
      "Epoch 111/500\n",
      "12357/12357 [==============================] - 7s 543us/sample - loss: 1.8872 - acc: 0.5926 - val_loss: 8.2752 - val_acc: 0.1391\n",
      "Epoch 112/500\n",
      "12357/12357 [==============================] - 6s 517us/sample - loss: 1.8751 - acc: 0.5974 - val_loss: 8.2916 - val_acc: 0.1384\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12357/12357 [==============================] - 6s 482us/sample - loss: 1.8999 - acc: 0.5946 - val_loss: 8.3313 - val_acc: 0.1355\n",
      "Epoch 114/500\n",
      "12357/12357 [==============================] - 6s 510us/sample - loss: 1.8782 - acc: 0.5935 - val_loss: 8.3747 - val_acc: 0.1333\n",
      "Epoch 115/500\n",
      "12357/12357 [==============================] - 7s 559us/sample - loss: 1.8422 - acc: 0.6031 - val_loss: 8.3447 - val_acc: 0.1318\n",
      "Epoch 116/500\n",
      "12357/12357 [==============================] - 7s 527us/sample - loss: 1.8105 - acc: 0.6122 - val_loss: 8.3700 - val_acc: 0.1384\n",
      "Epoch 117/500\n",
      "12357/12357 [==============================] - 7s 568us/sample - loss: 1.7936 - acc: 0.6159 - val_loss: 8.4054 - val_acc: 0.1333\n",
      "Epoch 118/500\n",
      "12357/12357 [==============================] - 6s 504us/sample - loss: 1.7738 - acc: 0.6201 - val_loss: 8.4138 - val_acc: 0.1377\n",
      "Epoch 119/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 1.7737 - acc: 0.6180 - val_loss: 8.4438 - val_acc: 0.1413\n",
      "Epoch 120/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 1.7572 - acc: 0.6224 - val_loss: 8.4625 - val_acc: 0.1355\n",
      "Epoch 121/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 1.7447 - acc: 0.6256 - val_loss: 8.4681 - val_acc: 0.1384\n",
      "Epoch 122/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 1.7204 - acc: 0.6307 - val_loss: 8.4809 - val_acc: 0.1377\n",
      "Epoch 123/500\n",
      "12357/12357 [==============================] - 7s 578us/sample - loss: 1.7179 - acc: 0.6302 - val_loss: 8.4897 - val_acc: 0.1347\n",
      "Epoch 124/500\n",
      "12357/12357 [==============================] - 7s 540us/sample - loss: 1.7022 - acc: 0.6337 - val_loss: 8.4982 - val_acc: 0.1333\n",
      "Epoch 125/500\n",
      "12357/12357 [==============================] - 6s 516us/sample - loss: 1.7082 - acc: 0.6320 - val_loss: 8.5289 - val_acc: 0.1340\n",
      "Epoch 126/500\n",
      "12357/12357 [==============================] - 6s 486us/sample - loss: 1.6755 - acc: 0.6396 - val_loss: 8.5326 - val_acc: 0.1326\n",
      "Epoch 127/500\n",
      "12357/12357 [==============================] - 6s 510us/sample - loss: 1.6691 - acc: 0.6381 - val_loss: 8.5591 - val_acc: 0.1355\n",
      "Epoch 128/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 1.6551 - acc: 0.6454 - val_loss: 8.5744 - val_acc: 0.1318\n",
      "Epoch 129/500\n",
      "12357/12357 [==============================] - 7s 592us/sample - loss: 1.6406 - acc: 0.6449 - val_loss: 8.5818 - val_acc: 0.1296\n",
      "Epoch 130/500\n",
      "12357/12357 [==============================] - 7s 529us/sample - loss: 1.6477 - acc: 0.6429 - val_loss: 8.6119 - val_acc: 0.1340\n",
      "Epoch 131/500\n",
      "12357/12357 [==============================] - 6s 498us/sample - loss: 1.6248 - acc: 0.6499 - val_loss: 8.6246 - val_acc: 0.1355\n",
      "Epoch 132/500\n",
      "12357/12357 [==============================] - 6s 525us/sample - loss: 1.6058 - acc: 0.6524 - val_loss: 8.6420 - val_acc: 0.1333\n",
      "Epoch 133/500\n",
      "12357/12357 [==============================] - 6s 502us/sample - loss: 1.5830 - acc: 0.6564 - val_loss: 8.6494 - val_acc: 0.1311\n",
      "Epoch 134/500\n",
      "12357/12357 [==============================] - 6s 494us/sample - loss: 1.5710 - acc: 0.6608 - val_loss: 8.6787 - val_acc: 0.1304\n",
      "Epoch 135/500\n",
      "12357/12357 [==============================] - 6s 506us/sample - loss: 1.5660 - acc: 0.6608 - val_loss: 8.6711 - val_acc: 0.1289\n",
      "Epoch 136/500\n",
      "12357/12357 [==============================] - 6s 487us/sample - loss: 1.5617 - acc: 0.6624 - val_loss: 8.7152 - val_acc: 0.1326\n",
      "Epoch 137/500\n",
      "12357/12357 [==============================] - 6s 506us/sample - loss: 1.5476 - acc: 0.6634 - val_loss: 8.7392 - val_acc: 0.1282\n",
      "Epoch 138/500\n",
      "12357/12357 [==============================] - 6s 506us/sample - loss: 1.5262 - acc: 0.6707 - val_loss: 8.7259 - val_acc: 0.1282\n",
      "Epoch 139/500\n",
      "12357/12357 [==============================] - 6s 487us/sample - loss: 1.5092 - acc: 0.6748 - val_loss: 8.7632 - val_acc: 0.1275\n",
      "Epoch 140/500\n",
      "12357/12357 [==============================] - 6s 490us/sample - loss: 1.4996 - acc: 0.6752 - val_loss: 8.7669 - val_acc: 0.1304\n",
      "Epoch 141/500\n",
      "12357/12357 [==============================] - 6s 506us/sample - loss: 1.4948 - acc: 0.6747 - val_loss: 8.7641 - val_acc: 0.1311\n",
      "Epoch 142/500\n",
      "12357/12357 [==============================] - 7s 547us/sample - loss: 1.4824 - acc: 0.6779 - val_loss: 8.7931 - val_acc: 0.1260\n",
      "Epoch 143/500\n",
      "12357/12357 [==============================] - 7s 527us/sample - loss: 1.4689 - acc: 0.6795 - val_loss: 8.8029 - val_acc: 0.1311\n",
      "Epoch 144/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 1.4555 - acc: 0.6842 - val_loss: 8.8098 - val_acc: 0.1333\n",
      "Epoch 145/500\n",
      "12357/12357 [==============================] - 6s 481us/sample - loss: 1.4489 - acc: 0.6859 - val_loss: 8.8562 - val_acc: 0.1260\n",
      "Epoch 146/500\n",
      "12357/12357 [==============================] - 6s 513us/sample - loss: 1.4478 - acc: 0.6824 - val_loss: 8.8360 - val_acc: 0.1296\n",
      "Epoch 147/500\n",
      "12357/12357 [==============================] - 6s 518us/sample - loss: 1.4426 - acc: 0.6854 - val_loss: 8.8726 - val_acc: 0.1289\n",
      "Epoch 148/500\n",
      "12357/12357 [==============================] - 6s 507us/sample - loss: 1.4296 - acc: 0.6882 - val_loss: 8.8814 - val_acc: 0.1326\n",
      "Epoch 149/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 1.4151 - acc: 0.6885 - val_loss: 8.8787 - val_acc: 0.1318\n",
      "Epoch 150/500\n",
      "12357/12357 [==============================] - 6s 502us/sample - loss: 1.4057 - acc: 0.6930 - val_loss: 8.9036 - val_acc: 0.1296\n",
      "Epoch 151/500\n",
      "12357/12357 [==============================] - 8s 640us/sample - loss: 1.4040 - acc: 0.6915 - val_loss: 8.9229 - val_acc: 0.1275\n",
      "Epoch 152/500\n",
      "12357/12357 [==============================] - 7s 544us/sample - loss: 1.3920 - acc: 0.6953 - val_loss: 8.9173 - val_acc: 0.1311\n",
      "Epoch 153/500\n",
      "12357/12357 [==============================] - 6s 493us/sample - loss: 1.3747 - acc: 0.6999 - val_loss: 8.9375 - val_acc: 0.1340\n",
      "Epoch 154/500\n",
      "12357/12357 [==============================] - 6s 517us/sample - loss: 1.3662 - acc: 0.7020 - val_loss: 8.9550 - val_acc: 0.1282\n",
      "Epoch 155/500\n",
      "12357/12357 [==============================] - 6s 518us/sample - loss: 1.3560 - acc: 0.7029 - val_loss: 8.9656 - val_acc: 0.1340\n",
      "Epoch 156/500\n",
      "12357/12357 [==============================] - 7s 546us/sample - loss: 1.3430 - acc: 0.7062 - val_loss: 8.9662 - val_acc: 0.1333\n",
      "Epoch 157/500\n",
      "12357/12357 [==============================] - 6s 519us/sample - loss: 1.3343 - acc: 0.7085 - val_loss: 8.9682 - val_acc: 0.1340\n",
      "Epoch 158/500\n",
      "12357/12357 [==============================] - 6s 502us/sample - loss: 1.3392 - acc: 0.7097 - val_loss: 8.9701 - val_acc: 0.1224\n",
      "Epoch 159/500\n",
      "12357/12357 [==============================] - 7s 567us/sample - loss: 1.3338 - acc: 0.7075 - val_loss: 9.0020 - val_acc: 0.1253\n",
      "Epoch 160/500\n",
      "12357/12357 [==============================] - 7s 542us/sample - loss: 1.3344 - acc: 0.7065 - val_loss: 9.0326 - val_acc: 0.1275\n",
      "Epoch 161/500\n",
      "12357/12357 [==============================] - 7s 579us/sample - loss: 1.3338 - acc: 0.7049 - val_loss: 9.0009 - val_acc: 0.1245\n",
      "Epoch 162/500\n",
      "12357/12357 [==============================] - 7s 543us/sample - loss: 1.3008 - acc: 0.7157 - val_loss: 9.0108 - val_acc: 0.1318\n",
      "Epoch 163/500\n",
      "12357/12357 [==============================] - 7s 533us/sample - loss: 1.2879 - acc: 0.7175 - val_loss: 9.0492 - val_acc: 0.1311\n",
      "Epoch 164/500\n",
      "12357/12357 [==============================] - 7s 531us/sample - loss: 1.2771 - acc: 0.7196 - val_loss: 9.0334 - val_acc: 0.1275\n",
      "Epoch 165/500\n",
      "12357/12357 [==============================] - 6s 524us/sample - loss: 1.2704 - acc: 0.7225 - val_loss: 9.0689 - val_acc: 0.1282\n",
      "Epoch 166/500\n",
      "12357/12357 [==============================] - 6s 496us/sample - loss: 1.2662 - acc: 0.7206 - val_loss: 9.0542 - val_acc: 0.1333\n",
      "Epoch 167/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 1.2593 - acc: 0.7223 - val_loss: 9.0832 - val_acc: 0.1311\n",
      "Epoch 168/500\n",
      "12357/12357 [==============================] - 6s 504us/sample - loss: 1.2470 - acc: 0.7274 - val_loss: 9.0561 - val_acc: 0.1304\n",
      "Epoch 169/500\n",
      "12357/12357 [==============================] - 7s 551us/sample - loss: 1.2406 - acc: 0.7270 - val_loss: 9.0715 - val_acc: 0.1304\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12357/12357 [==============================] - 7s 528us/sample - loss: 1.2403 - acc: 0.7285 - val_loss: 9.0820 - val_acc: 0.1282\n",
      "Epoch 171/500\n",
      "12357/12357 [==============================] - 6s 488us/sample - loss: 1.2209 - acc: 0.7313 - val_loss: 9.1055 - val_acc: 0.1289\n",
      "Epoch 172/500\n",
      "12357/12357 [==============================] - 6s 481us/sample - loss: 1.2130 - acc: 0.7320 - val_loss: 9.1313 - val_acc: 0.1311\n",
      "Epoch 173/500\n",
      "12357/12357 [==============================] - 6s 490us/sample - loss: 1.2043 - acc: 0.7353 - val_loss: 9.1246 - val_acc: 0.1275\n",
      "Epoch 174/500\n",
      "12357/12357 [==============================] - 6s 490us/sample - loss: 1.2007 - acc: 0.7353 - val_loss: 9.1107 - val_acc: 0.1340\n",
      "Epoch 175/500\n",
      "12357/12357 [==============================] - 6s 485us/sample - loss: 1.2036 - acc: 0.7350 - val_loss: 9.1441 - val_acc: 0.1340\n",
      "Epoch 176/500\n",
      "12357/12357 [==============================] - 6s 484us/sample - loss: 1.1975 - acc: 0.7355 - val_loss: 9.1554 - val_acc: 0.1304\n",
      "Epoch 177/500\n",
      "12357/12357 [==============================] - 6s 484us/sample - loss: 1.1852 - acc: 0.7376 - val_loss: 9.1793 - val_acc: 0.1260\n",
      "Epoch 178/500\n",
      "12357/12357 [==============================] - 6s 493us/sample - loss: 1.1789 - acc: 0.7405 - val_loss: 9.1619 - val_acc: 0.1304\n",
      "Epoch 179/500\n",
      "12357/12357 [==============================] - 7s 572us/sample - loss: 1.1754 - acc: 0.7399 - val_loss: 9.2009 - val_acc: 0.1282\n",
      "Epoch 180/500\n",
      "12357/12357 [==============================] - 6s 498us/sample - loss: 1.1602 - acc: 0.7440 - val_loss: 9.1766 - val_acc: 0.1355\n",
      "Epoch 181/500\n",
      "12357/12357 [==============================] - 6s 520us/sample - loss: 1.1523 - acc: 0.7465 - val_loss: 9.2116 - val_acc: 0.1267\n",
      "Epoch 182/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 1.1408 - acc: 0.7482 - val_loss: 9.2372 - val_acc: 0.1275\n",
      "Epoch 183/500\n",
      "12357/12357 [==============================] - 6s 465us/sample - loss: 1.1458 - acc: 0.7494 - val_loss: 9.2012 - val_acc: 0.1282\n",
      "Epoch 184/500\n",
      "12357/12357 [==============================] - 6s 477us/sample - loss: 1.1454 - acc: 0.7474 - val_loss: 9.2344 - val_acc: 0.1275\n",
      "Epoch 185/500\n",
      "12357/12357 [==============================] - 6s 497us/sample - loss: 1.1306 - acc: 0.7469 - val_loss: 9.2513 - val_acc: 0.1245\n",
      "Epoch 186/500\n",
      "12357/12357 [==============================] - 6s 478us/sample - loss: 1.1225 - acc: 0.7502 - val_loss: 9.2714 - val_acc: 0.1245\n",
      "Epoch 187/500\n",
      "12357/12357 [==============================] - 6s 494us/sample - loss: 1.1152 - acc: 0.7536 - val_loss: 9.2604 - val_acc: 0.1224\n",
      "Epoch 188/500\n",
      "12357/12357 [==============================] - 6s 493us/sample - loss: 1.1141 - acc: 0.7514 - val_loss: 9.3089 - val_acc: 0.1238\n",
      "Epoch 189/500\n",
      "12357/12357 [==============================] - 7s 554us/sample - loss: 1.1147 - acc: 0.7514 - val_loss: 9.2477 - val_acc: 0.1238\n",
      "Epoch 190/500\n",
      "12357/12357 [==============================] - 6s 502us/sample - loss: 1.1056 - acc: 0.7533 - val_loss: 9.2923 - val_acc: 0.1216\n",
      "Epoch 191/500\n",
      "12357/12357 [==============================] - 6s 492us/sample - loss: 1.1108 - acc: 0.7516 - val_loss: 9.2752 - val_acc: 0.1282\n",
      "Epoch 192/500\n",
      "12357/12357 [==============================] - 7s 534us/sample - loss: 1.0925 - acc: 0.7549 - val_loss: 9.3090 - val_acc: 0.1289\n",
      "Epoch 193/500\n",
      "12357/12357 [==============================] - 7s 532us/sample - loss: 1.0929 - acc: 0.7556 - val_loss: 9.3253 - val_acc: 0.1238\n",
      "Epoch 194/500\n",
      "12357/12357 [==============================] - 7s 531us/sample - loss: 1.0931 - acc: 0.7560 - val_loss: 9.3604 - val_acc: 0.1245\n",
      "Epoch 195/500\n",
      "12357/12357 [==============================] - 7s 578us/sample - loss: 1.0997 - acc: 0.7531 - val_loss: 9.3271 - val_acc: 0.1253\n",
      "Epoch 196/500\n",
      "12357/12357 [==============================] - 6s 524us/sample - loss: 1.1230 - acc: 0.7457 - val_loss: 9.3352 - val_acc: 0.1224\n",
      "Epoch 197/500\n",
      "12357/12357 [==============================] - 6s 515us/sample - loss: 1.1046 - acc: 0.7512 - val_loss: 9.3706 - val_acc: 0.1209\n",
      "Epoch 198/500\n",
      "12357/12357 [==============================] - 7s 552us/sample - loss: 1.0754 - acc: 0.7590 - val_loss: 9.3511 - val_acc: 0.1245\n",
      "Epoch 199/500\n",
      "12357/12357 [==============================] - 6s 514us/sample - loss: 1.0631 - acc: 0.7616 - val_loss: 9.3654 - val_acc: 0.1224\n",
      "Epoch 200/500\n",
      "12357/12357 [==============================] - 6s 512us/sample - loss: 1.0500 - acc: 0.7619 - val_loss: 9.3673 - val_acc: 0.1231\n",
      "Epoch 201/500\n",
      "12357/12357 [==============================] - 6s 513us/sample - loss: 1.0419 - acc: 0.7653 - val_loss: 9.3905 - val_acc: 0.1209\n",
      "Epoch 202/500\n",
      "12357/12357 [==============================] - 7s 534us/sample - loss: 1.0263 - acc: 0.7710 - val_loss: 9.4054 - val_acc: 0.1245\n",
      "Epoch 203/500\n",
      "12357/12357 [==============================] - 7s 539us/sample - loss: 1.0139 - acc: 0.7732 - val_loss: 9.4169 - val_acc: 0.1224\n",
      "Epoch 204/500\n",
      "12357/12357 [==============================] - 7s 555us/sample - loss: 1.0159 - acc: 0.7732 - val_loss: 9.3912 - val_acc: 0.1231\n",
      "Epoch 205/500\n",
      "12357/12357 [==============================] - 7s 540us/sample - loss: 1.0106 - acc: 0.7742 - val_loss: 9.4104 - val_acc: 0.1224\n",
      "Epoch 206/500\n",
      "12357/12357 [==============================] - 7s 529us/sample - loss: 1.0005 - acc: 0.7770 - val_loss: 9.4572 - val_acc: 0.1202\n",
      "Epoch 207/500\n",
      "12357/12357 [==============================] - 7s 565us/sample - loss: 1.0105 - acc: 0.7749 - val_loss: 9.4431 - val_acc: 0.1209\n",
      "Epoch 208/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 0.9933 - acc: 0.7773 - val_loss: 9.4314 - val_acc: 0.1245\n",
      "Epoch 209/500\n",
      "12357/12357 [==============================] - 6s 522us/sample - loss: 0.9867 - acc: 0.7790 - val_loss: 9.4186 - val_acc: 0.1231\n",
      "Epoch 210/500\n",
      "12357/12357 [==============================] - 6s 513us/sample - loss: 0.9849 - acc: 0.7778 - val_loss: 9.4533 - val_acc: 0.1231\n",
      "Epoch 211/500\n",
      "12357/12357 [==============================] - 6s 508us/sample - loss: 0.9955 - acc: 0.7773 - val_loss: 9.4791 - val_acc: 0.1238\n",
      "Epoch 212/500\n",
      "12357/12357 [==============================] - 6s 508us/sample - loss: 0.9980 - acc: 0.7745 - val_loss: 9.4530 - val_acc: 0.1253\n",
      "Epoch 213/500\n",
      "12357/12357 [==============================] - 6s 506us/sample - loss: 0.9849 - acc: 0.7778 - val_loss: 9.4833 - val_acc: 0.1245\n",
      "Epoch 214/500\n",
      "12357/12357 [==============================] - 6s 508us/sample - loss: 0.9653 - acc: 0.7827 - val_loss: 9.4664 - val_acc: 0.1253\n",
      "Epoch 215/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 0.9639 - acc: 0.7827 - val_loss: 9.5115 - val_acc: 0.1216\n",
      "Epoch 216/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 0.9516 - acc: 0.7868 - val_loss: 9.5065 - val_acc: 0.1216\n",
      "Epoch 217/500\n",
      "12357/12357 [==============================] - 7s 543us/sample - loss: 0.9425 - acc: 0.7900 - val_loss: 9.5083 - val_acc: 0.1224\n",
      "Epoch 218/500\n",
      "12357/12357 [==============================] - 6s 521us/sample - loss: 0.9392 - acc: 0.7883 - val_loss: 9.4843 - val_acc: 0.1231\n",
      "Epoch 219/500\n",
      "12357/12357 [==============================] - 6s 517us/sample - loss: 0.9317 - acc: 0.7905 - val_loss: 9.5059 - val_acc: 0.1209\n",
      "Epoch 220/500\n",
      "12357/12357 [==============================] - 7s 554us/sample - loss: 0.9271 - acc: 0.7929 - val_loss: 9.5106 - val_acc: 0.1209\n",
      "Epoch 221/500\n",
      "12357/12357 [==============================] - 7s 532us/sample - loss: 0.9287 - acc: 0.7927 - val_loss: 9.5287 - val_acc: 0.1202\n",
      "Epoch 222/500\n",
      "12357/12357 [==============================] - 6s 509us/sample - loss: 0.9229 - acc: 0.7917 - val_loss: 9.5649 - val_acc: 0.1238\n",
      "Epoch 223/500\n",
      "12357/12357 [==============================] - 6s 516us/sample - loss: 0.9303 - acc: 0.7919 - val_loss: 9.5557 - val_acc: 0.1180\n",
      "Epoch 224/500\n",
      "12357/12357 [==============================] - 6s 513us/sample - loss: 0.9287 - acc: 0.7905 - val_loss: 9.5750 - val_acc: 0.1180\n",
      "Epoch 225/500\n",
      "12357/12357 [==============================] - 6s 516us/sample - loss: 0.9112 - acc: 0.7945 - val_loss: 9.5925 - val_acc: 0.1202\n",
      "Epoch 226/500\n",
      "12357/12357 [==============================] - 7s 548us/sample - loss: 0.9115 - acc: 0.7944 - val_loss: 9.5588 - val_acc: 0.1224\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12357/12357 [==============================] - 6s 490us/sample - loss: 0.9136 - acc: 0.7942 - val_loss: 9.5875 - val_acc: 0.1194\n",
      "Epoch 228/500\n",
      "12357/12357 [==============================] - 6s 458us/sample - loss: 0.8971 - acc: 0.7968 - val_loss: 9.6094 - val_acc: 0.1173\n",
      "Epoch 229/500\n",
      "12357/12357 [==============================] - 6s 474us/sample - loss: 0.8974 - acc: 0.7969 - val_loss: 9.6140 - val_acc: 0.1202\n",
      "Epoch 230/500\n",
      "12357/12357 [==============================] - 7s 534us/sample - loss: 0.8903 - acc: 0.8000 - val_loss: 9.6282 - val_acc: 0.1173\n",
      "Epoch 231/500\n",
      "12357/12357 [==============================] - 7s 582us/sample - loss: 0.8896 - acc: 0.7985 - val_loss: 9.6225 - val_acc: 0.1165\n",
      "Epoch 232/500\n",
      "12357/12357 [==============================] - 6s 484us/sample - loss: 0.8813 - acc: 0.8011 - val_loss: 9.6395 - val_acc: 0.1180\n",
      "Epoch 233/500\n",
      "12357/12357 [==============================] - 6s 481us/sample - loss: 0.8676 - acc: 0.8046 - val_loss: 9.6426 - val_acc: 0.1180\n",
      "Epoch 234/500\n",
      "12357/12357 [==============================] - 6s 487us/sample - loss: 0.8691 - acc: 0.8027 - val_loss: 9.6125 - val_acc: 0.1173\n",
      "Epoch 235/500\n",
      "12357/12357 [==============================] - 6s 506us/sample - loss: 0.8874 - acc: 0.7983 - val_loss: 9.6564 - val_acc: 0.1187\n",
      "Epoch 236/500\n",
      "12357/12357 [==============================] - 6s 509us/sample - loss: 0.9078 - acc: 0.7898 - val_loss: 9.6647 - val_acc: 0.1151\n",
      "Epoch 237/500\n",
      "12357/12357 [==============================] - 6s 502us/sample - loss: 0.8784 - acc: 0.8017 - val_loss: 9.6531 - val_acc: 0.1173\n",
      "Epoch 238/500\n",
      "12357/12357 [==============================] - 6s 463us/sample - loss: 0.8690 - acc: 0.8024 - val_loss: 9.6935 - val_acc: 0.1194\n",
      "Epoch 239/500\n",
      "12357/12357 [==============================] - 6s 462us/sample - loss: 0.8574 - acc: 0.8064 - val_loss: 9.6605 - val_acc: 0.1187\n",
      "Epoch 240/500\n",
      "12357/12357 [==============================] - 6s 465us/sample - loss: 0.8449 - acc: 0.8089 - val_loss: 9.6950 - val_acc: 0.1173\n",
      "Epoch 241/500\n",
      "12357/12357 [==============================] - 6s 482us/sample - loss: 0.8443 - acc: 0.8083 - val_loss: 9.6939 - val_acc: 0.1194\n",
      "Epoch 242/500\n",
      "12357/12357 [==============================] - 6s 504us/sample - loss: 0.8409 - acc: 0.8104 - val_loss: 9.6901 - val_acc: 0.1194\n",
      "Epoch 243/500\n",
      "12357/12357 [==============================] - ETA: 0s - loss: 0.8333 - acc: 0.8107- ETA: 1s - l - 6s 481us/sample - loss: 0.8338 - acc: 0.8105 - val_loss: 9.7273 - val_acc: 0.1202\n",
      "Epoch 244/500\n",
      "12357/12357 [==============================] - 6s 475us/sample - loss: 0.8328 - acc: 0.8098 - val_loss: 9.7108 - val_acc: 0.1194\n",
      "Epoch 245/500\n",
      "12357/12357 [==============================] - 6s 469us/sample - loss: 0.8304 - acc: 0.8107 - val_loss: 9.7516 - val_acc: 0.1165\n",
      "Epoch 246/500\n",
      "12357/12357 [==============================] - 6s 508us/sample - loss: 0.8338 - acc: 0.8108 - val_loss: 9.7225 - val_acc: 0.1180\n",
      "Epoch 247/500\n",
      "12357/12357 [==============================] - 6s 469us/sample - loss: 0.8203 - acc: 0.8130 - val_loss: 9.7193 - val_acc: 0.1187\n",
      "Epoch 248/500\n",
      "12357/12357 [==============================] - 6s 469us/sample - loss: 0.8213 - acc: 0.8123 - val_loss: 9.7393 - val_acc: 0.1224\n",
      "Epoch 249/500\n",
      "12357/12357 [==============================] - 6s 469us/sample - loss: 0.8174 - acc: 0.8144 - val_loss: 9.7517 - val_acc: 0.1194\n",
      "Epoch 250/500\n",
      "12357/12357 [==============================] - 6s 468us/sample - loss: 0.8223 - acc: 0.8114 - val_loss: 9.7504 - val_acc: 0.1253\n",
      "Epoch 251/500\n",
      "12357/12357 [==============================] - 6s 479us/sample - loss: 0.8122 - acc: 0.8144 - val_loss: 9.7463 - val_acc: 0.1209\n",
      "Epoch 252/500\n",
      "12357/12357 [==============================] - 6s 483us/sample - loss: 0.7940 - acc: 0.8186 - val_loss: 9.7873 - val_acc: 0.1209\n",
      "Epoch 253/500\n",
      "12357/12357 [==============================] - 6s 513us/sample - loss: 0.8015 - acc: 0.8193 - val_loss: 9.7934 - val_acc: 0.1194\n",
      "Epoch 254/500\n",
      "12357/12357 [==============================] - 6s 500us/sample - loss: 0.7934 - acc: 0.8193 - val_loss: 9.7889 - val_acc: 0.1231\n",
      "Epoch 255/500\n",
      "12357/12357 [==============================] - 6s 495us/sample - loss: 0.7923 - acc: 0.8203 - val_loss: 9.8025 - val_acc: 0.1202\n",
      "Epoch 256/500\n",
      "12357/12357 [==============================] - 7s 540us/sample - loss: 0.8041 - acc: 0.8149 - val_loss: 9.8191 - val_acc: 0.1180\n",
      "Epoch 257/500\n",
      "12357/12357 [==============================] - 6s 492us/sample - loss: 0.8027 - acc: 0.8146 - val_loss: 9.8061 - val_acc: 0.1180\n",
      "Epoch 258/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 0.7865 - acc: 0.8206 - val_loss: 9.8336 - val_acc: 0.1187\n",
      "Epoch 259/500\n",
      "12357/12357 [==============================] - 6s 494us/sample - loss: 0.7767 - acc: 0.8226 - val_loss: 9.8297 - val_acc: 0.1209\n",
      "Epoch 260/500\n",
      "12357/12357 [==============================] - 6s 496us/sample - loss: 0.7799 - acc: 0.8209 - val_loss: 9.8441 - val_acc: 0.1209\n",
      "Epoch 261/500\n",
      "12357/12357 [==============================] - 6s 509us/sample - loss: 0.7856 - acc: 0.8221 - val_loss: 9.8274 - val_acc: 0.1194\n",
      "Epoch 262/500\n",
      "12357/12357 [==============================] - 6s 526us/sample - loss: 0.7643 - acc: 0.8250 - val_loss: 9.8295 - val_acc: 0.1209\n",
      "Epoch 263/500\n",
      "12357/12357 [==============================] - 7s 546us/sample - loss: 0.8074 - acc: 0.8129 - val_loss: 9.8239 - val_acc: 0.1165\n",
      "Epoch 264/500\n",
      "12357/12357 [==============================] - 6s 504us/sample - loss: 0.8266 - acc: 0.8091 - val_loss: 9.8276 - val_acc: 0.1216\n",
      "Epoch 265/500\n",
      "12357/12357 [==============================] - 7s 534us/sample - loss: 0.7936 - acc: 0.8165 - val_loss: 9.8045 - val_acc: 0.1216\n",
      "Epoch 266/500\n",
      "12357/12357 [==============================] - 6s 498us/sample - loss: 0.7689 - acc: 0.8233 - val_loss: 9.8397 - val_acc: 0.1202\n",
      "Epoch 267/500\n",
      "12357/12357 [==============================] - 6s 498us/sample - loss: 0.7473 - acc: 0.8288 - val_loss: 9.8328 - val_acc: 0.1253\n",
      "Epoch 268/500\n",
      "12357/12357 [==============================] - 6s 489us/sample - loss: 0.7365 - acc: 0.8288 - val_loss: 9.8227 - val_acc: 0.1216\n",
      "Epoch 269/500\n",
      "12357/12357 [==============================] - 6s 493us/sample - loss: 0.7273 - acc: 0.8315 - val_loss: 9.8613 - val_acc: 0.1209\n",
      "Epoch 270/500\n",
      "12357/12357 [==============================] - 6s 491us/sample - loss: 0.7258 - acc: 0.8319 - val_loss: 9.8542 - val_acc: 0.1180\n",
      "Epoch 271/500\n",
      "12357/12357 [==============================] - 6s 503us/sample - loss: 0.7277 - acc: 0.8313 - val_loss: 9.8613 - val_acc: 0.1187\n",
      "Epoch 272/500\n",
      "12357/12357 [==============================] - 6s 495us/sample - loss: 0.7461 - acc: 0.8249 - val_loss: 9.8589 - val_acc: 0.1202\n",
      "Epoch 273/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 0.7316 - acc: 0.8297 - val_loss: 9.8706 - val_acc: 0.1180\n",
      "Epoch 274/500\n",
      "12357/12357 [==============================] - 6s 510us/sample - loss: 0.7537 - acc: 0.8251 - val_loss: 9.8550 - val_acc: 0.1216\n",
      "Epoch 275/500\n",
      "12357/12357 [==============================] - 7s 540us/sample - loss: 0.7378 - acc: 0.8269 - val_loss: 9.8878 - val_acc: 0.1194\n",
      "Epoch 276/500\n",
      "12357/12357 [==============================] - 6s 489us/sample - loss: 0.7306 - acc: 0.8280 - val_loss: 9.8957 - val_acc: 0.1194\n",
      "Epoch 277/500\n",
      "12357/12357 [==============================] - 6s 493us/sample - loss: 0.7128 - acc: 0.8339 - val_loss: 9.8916 - val_acc: 0.1224\n",
      "Epoch 278/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 0.7361 - acc: 0.8269 - val_loss: 9.8804 - val_acc: 0.1260\n",
      "Epoch 279/500\n",
      "12357/12357 [==============================] - 6s 521us/sample - loss: 0.7162 - acc: 0.8305 - val_loss: 9.9278 - val_acc: 0.1231\n",
      "Epoch 280/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 0.7076 - acc: 0.8344 - val_loss: 9.9075 - val_acc: 0.1216 acc: 0. - ETA: 0s - loss: 0.7103\n",
      "Epoch 281/500\n",
      "12357/12357 [==============================] - 6s 490us/sample - loss: 0.7023 - acc: 0.8336 - val_loss: 9.9264 - val_acc: 0.1253\n",
      "Epoch 282/500\n",
      "12357/12357 [==============================] - 6s 495us/sample - loss: 0.6968 - acc: 0.8368 - val_loss: 9.9093 - val_acc: 0.1224\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12357/12357 [==============================] - 6s 462us/sample - loss: 0.6941 - acc: 0.8376 - val_loss: 9.9412 - val_acc: 0.1238\n",
      "Epoch 284/500\n",
      "12357/12357 [==============================] - 6s 475us/sample - loss: 0.6941 - acc: 0.8355 - val_loss: 9.9086 - val_acc: 0.1209\n",
      "Epoch 285/500\n",
      "12357/12357 [==============================] - 7s 570us/sample - loss: 0.6901 - acc: 0.8367 - val_loss: 9.9400 - val_acc: 0.1173\n",
      "Epoch 286/500\n",
      "12357/12357 [==============================] - 7s 539us/sample - loss: 0.6897 - acc: 0.8367 - val_loss: 9.9795 - val_acc: 0.1187\n",
      "Epoch 287/500\n",
      "12357/12357 [==============================] - 6s 511us/sample - loss: 0.6956 - acc: 0.8357 - val_loss: 9.9164 - val_acc: 0.1216\n",
      "Epoch 288/500\n",
      "12357/12357 [==============================] - 6s 466us/sample - loss: 0.7139 - acc: 0.8326 - val_loss: 9.9332 - val_acc: 0.1209\n",
      "Epoch 289/500\n",
      "12357/12357 [==============================] - 6s 454us/sample - loss: 0.7011 - acc: 0.8332 - val_loss: 9.9822 - val_acc: 0.1180\n",
      "Epoch 290/500\n",
      "12357/12357 [==============================] - 6s 453us/sample - loss: 0.6977 - acc: 0.8357 - val_loss: 9.9239 - val_acc: 0.1224\n",
      "Epoch 291/500\n",
      "12357/12357 [==============================] - 6s 466us/sample - loss: 0.6852 - acc: 0.8384 - val_loss: 9.9845 - val_acc: 0.1165\n",
      "Epoch 292/500\n",
      "12357/12357 [==============================] - 6s 467us/sample - loss: 0.6785 - acc: 0.8397 - val_loss: 10.0195 - val_acc: 0.1173\n",
      "Epoch 293/500\n",
      "12357/12357 [==============================] - 6s 464us/sample - loss: 0.6927 - acc: 0.8360 - val_loss: 9.9976 - val_acc: 0.1187\n",
      "Epoch 294/500\n",
      "12357/12357 [==============================] - 6s 463us/sample - loss: 0.6685 - acc: 0.8430 - val_loss: 9.9946 - val_acc: 0.1209\n",
      "Epoch 295/500\n",
      "12357/12357 [==============================] - 6s 494us/sample - loss: 0.6733 - acc: 0.8408 - val_loss: 9.9954 - val_acc: 0.1173\n",
      "Epoch 296/500\n",
      "12357/12357 [==============================] - 6s 470us/sample - loss: 0.6938 - acc: 0.8343 - val_loss: 10.0002 - val_acc: 0.1224\n",
      "Epoch 297/500\n",
      "12357/12357 [==============================] - 6s 470us/sample - loss: 0.6850 - acc: 0.8374 - val_loss: 9.9784 - val_acc: 0.1187\n",
      "Epoch 298/500\n",
      "12357/12357 [==============================] - 6s 452us/sample - loss: 0.6788 - acc: 0.8363 - val_loss: 10.0287 - val_acc: 0.1165\n",
      "Epoch 299/500\n",
      "12357/12357 [==============================] - 6s 454us/sample - loss: 0.6608 - acc: 0.8422 - val_loss: 9.9961 - val_acc: 0.1194\n",
      "Epoch 300/500\n",
      "12357/12357 [==============================] - 6s 473us/sample - loss: 0.6535 - acc: 0.8434 - val_loss: 10.0119 - val_acc: 0.1202\n",
      "Epoch 301/500\n",
      "12357/12357 [==============================] - 6s 470us/sample - loss: 0.6469 - acc: 0.8465 - val_loss: 10.0327 - val_acc: 0.1158\n",
      "Epoch 302/500\n",
      "12357/12357 [==============================] - 6s 458us/sample - loss: 0.6520 - acc: 0.8456 - val_loss: 10.0312 - val_acc: 0.1194\n",
      "Epoch 303/500\n",
      "12357/12357 [==============================] - 6s 454us/sample - loss: 0.6694 - acc: 0.8390 - val_loss: 10.0130 - val_acc: 0.1158\n",
      "Epoch 304/500\n",
      "12357/12357 [==============================] - 6s 476us/sample - loss: 0.6541 - acc: 0.8458 - val_loss: 10.0016 - val_acc: 0.1173\n",
      "Epoch 305/500\n",
      "12357/12357 [==============================] - 6s 497us/sample - loss: 0.6463 - acc: 0.8438 - val_loss: 10.0409 - val_acc: 0.1143\n",
      "Epoch 306/500\n",
      "12357/12357 [==============================] - 6s 459us/sample - loss: 0.6690 - acc: 0.8370 - val_loss: 10.0326 - val_acc: 0.1143\n",
      "Epoch 307/500\n",
      "12357/12357 [==============================] - 6s 464us/sample - loss: 0.6643 - acc: 0.8399 - val_loss: 10.0318 - val_acc: 0.1209\n",
      "Epoch 308/500\n",
      "12357/12357 [==============================] - 6s 469us/sample - loss: 0.6593 - acc: 0.8403 - val_loss: 10.0499 - val_acc: 0.1165\n",
      "Epoch 309/500\n",
      "12357/12357 [==============================] - 6s 467us/sample - loss: 0.6546 - acc: 0.8415 - val_loss: 10.0540 - val_acc: 0.1231\n",
      "Epoch 310/500\n",
      "12357/12357 [==============================] - 6s 467us/sample - loss: 0.6441 - acc: 0.8456 - val_loss: 10.0427 - val_acc: 0.1194\n",
      "Epoch 311/500\n",
      "12357/12357 [==============================] - 6s 456us/sample - loss: 0.6325 - acc: 0.8504 - val_loss: 10.0962 - val_acc: 0.1224\n",
      "Epoch 312/500\n",
      "12357/12357 [==============================] - 6s 465us/sample - loss: 0.6243 - acc: 0.8509 - val_loss: 10.1040 - val_acc: 0.1143\n",
      "Epoch 313/500\n",
      "12357/12357 [==============================] - 6s 477us/sample - loss: 0.6196 - acc: 0.8516 - val_loss: 10.1045 - val_acc: 0.1194\n",
      "Epoch 314/500\n",
      "12357/12357 [==============================] - 6s 481us/sample - loss: 0.6149 - acc: 0.8519 - val_loss: 10.0935 - val_acc: 0.1209\n",
      "Epoch 315/500\n",
      "12357/12357 [==============================] - 6s 524us/sample - loss: 0.6169 - acc: 0.8504 - val_loss: 10.0797 - val_acc: 0.1209\n",
      "Epoch 316/500\n",
      "12357/12357 [==============================] - 6s 470us/sample - loss: 0.6147 - acc: 0.8522 - val_loss: 10.0956 - val_acc: 0.1202\n",
      "Epoch 317/500\n",
      "12357/12357 [==============================] - 6s 477us/sample - loss: 0.6088 - acc: 0.8531 - val_loss: 10.0985 - val_acc: 0.1158\n",
      "Epoch 318/500\n",
      "12357/12357 [==============================] - 6s 461us/sample - loss: 0.6056 - acc: 0.8558 - val_loss: 10.1229 - val_acc: 0.1136\n",
      "Epoch 319/500\n",
      "12357/12357 [==============================] - 6s 506us/sample - loss: 0.6031 - acc: 0.8543 - val_loss: 10.1101 - val_acc: 0.1151\n",
      "Epoch 320/500\n",
      "12357/12357 [==============================] - 6s 511us/sample - loss: 0.6016 - acc: 0.8544 - val_loss: 10.1078 - val_acc: 0.1165\n",
      "Epoch 321/500\n",
      "12357/12357 [==============================] - 5s 423us/sample - loss: 0.6081 - acc: 0.8513 - val_loss: 10.1136 - val_acc: 0.1216\n",
      "Epoch 322/500\n",
      "12357/12357 [==============================] - 6s 458us/sample - loss: 0.6067 - acc: 0.8521 - val_loss: 10.1050 - val_acc: 0.1216\n",
      "Epoch 323/500\n",
      "12357/12357 [==============================] - 6s 467us/sample - loss: 0.6295 - acc: 0.8483 - val_loss: 10.1243 - val_acc: 0.1216\n",
      "Epoch 324/500\n",
      "12357/12357 [==============================] - 6s 469us/sample - loss: 0.6427 - acc: 0.8426 - val_loss: 10.1112 - val_acc: 0.1245\n",
      "Epoch 325/500\n",
      "12357/12357 [==============================] - 6s 483us/sample - loss: 0.6340 - acc: 0.8466 - val_loss: 10.1599 - val_acc: 0.1224\n",
      "Epoch 326/500\n",
      "12357/12357 [==============================] - 6s 502us/sample - loss: 0.6763 - acc: 0.8338 - val_loss: 10.1503 - val_acc: 0.1245\n",
      "Epoch 327/500\n",
      "12357/12357 [==============================] - 6s 474us/sample - loss: 0.6326 - acc: 0.8459 - val_loss: 10.0989 - val_acc: 0.1209\n",
      "Epoch 328/500\n",
      "12357/12357 [==============================] - 6s 483us/sample - loss: 0.6190 - acc: 0.8483 - val_loss: 10.1548 - val_acc: 0.1209\n",
      "Epoch 329/500\n",
      "12357/12357 [==============================] - 6s 477us/sample - loss: 0.5987 - acc: 0.8548 - val_loss: 10.1862 - val_acc: 0.1143\n",
      "Epoch 330/500\n",
      "12357/12357 [==============================] - 6s 498us/sample - loss: 0.5907 - acc: 0.8551 - val_loss: 10.1994 - val_acc: 0.1173\n",
      "Epoch 331/500\n",
      "12357/12357 [==============================] - 6s 506us/sample - loss: 0.5967 - acc: 0.8546 - val_loss: 10.1773 - val_acc: 0.1165\n",
      "Epoch 332/500\n",
      "12357/12357 [==============================] - 6s 484us/sample - loss: 0.5877 - acc: 0.8564 - val_loss: 10.2062 - val_acc: 0.1180\n",
      "Epoch 333/500\n",
      "12357/12357 [==============================] - 6s 470us/sample - loss: 0.5847 - acc: 0.8550 - val_loss: 10.1918 - val_acc: 0.1216\n",
      "Epoch 334/500\n",
      "12357/12357 [==============================] - 6s 490us/sample - loss: 0.5814 - acc: 0.8568 - val_loss: 10.2168 - val_acc: 0.1216\n",
      "Epoch 335/500\n",
      "12357/12357 [==============================] - 7s 528us/sample - loss: 0.5754 - acc: 0.8574 - val_loss: 10.2008 - val_acc: 0.1238\n",
      "Epoch 336/500\n",
      "12357/12357 [==============================] - 7s 554us/sample - loss: 0.5769 - acc: 0.8587 - val_loss: 10.2020 - val_acc: 0.1158\n",
      "Epoch 337/500\n",
      "12357/12357 [==============================] - 6s 485us/sample - loss: 0.5807 - acc: 0.8575 - val_loss: 10.2293 - val_acc: 0.1194\n",
      "Epoch 338/500\n",
      "12357/12357 [==============================] - 7s 602us/sample - loss: 0.5806 - acc: 0.8561 - val_loss: 10.2231 - val_acc: 0.1202\n",
      "Epoch 339/500\n",
      "12357/12357 [==============================] - 6s 516us/sample - loss: 0.5889 - acc: 0.8560 - val_loss: 10.2554 - val_acc: 0.1136\n",
      "Epoch 340/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12357/12357 [==============================] - 6s 479us/sample - loss: 0.5775 - acc: 0.8543 - val_loss: 10.2499 - val_acc: 0.1129\n",
      "Epoch 341/500\n",
      "12357/12357 [==============================] - 6s 467us/sample - loss: 0.5707 - acc: 0.8589 - val_loss: 10.2562 - val_acc: 0.1180\n",
      "Epoch 342/500\n",
      "12357/12357 [==============================] - 6s 460us/sample - loss: 0.5774 - acc: 0.8558 - val_loss: 10.2738 - val_acc: 0.1173\n",
      "Epoch 343/500\n",
      "12357/12357 [==============================] - 6s 473us/sample - loss: 0.5753 - acc: 0.8586 - val_loss: 10.1937 - val_acc: 0.1224\n",
      "Epoch 344/500\n",
      "12357/12357 [==============================] - 6s 474us/sample - loss: 0.5960 - acc: 0.8515 - val_loss: 10.2894 - val_acc: 0.1085\n",
      "Epoch 345/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 0.5976 - acc: 0.8516 - val_loss: 10.2503 - val_acc: 0.1173\n",
      "Epoch 346/500\n",
      "12357/12357 [==============================] - 6s 471us/sample - loss: 0.5787 - acc: 0.8547 - val_loss: 10.2782 - val_acc: 0.1151\n",
      "Epoch 347/500\n",
      "12357/12357 [==============================] - 6s 500us/sample - loss: 0.5638 - acc: 0.8591 - val_loss: 10.3084 - val_acc: 0.1129\n",
      "Epoch 348/500\n",
      "12357/12357 [==============================] - 7s 536us/sample - loss: 0.5582 - acc: 0.8594 - val_loss: 10.3020 - val_acc: 0.1158\n",
      "Epoch 349/500\n",
      "12357/12357 [==============================] - 6s 520us/sample - loss: 0.5542 - acc: 0.8602 - val_loss: 10.3005 - val_acc: 0.1173\n",
      "Epoch 350/500\n",
      "12357/12357 [==============================] - 6s 485us/sample - loss: 0.5505 - acc: 0.8614 - val_loss: 10.3160 - val_acc: 0.1122\n",
      "Epoch 351/500\n",
      "12357/12357 [==============================] - 6s 482us/sample - loss: 0.5749 - acc: 0.8564 - val_loss: 10.3125 - val_acc: 0.1151\n",
      "Epoch 352/500\n",
      "12357/12357 [==============================] - 6s 503us/sample - loss: 0.5971 - acc: 0.8492 - val_loss: 10.3373 - val_acc: 0.1129\n",
      "Epoch 353/500\n",
      "12357/12357 [==============================] - 8s 615us/sample - loss: 0.5773 - acc: 0.8547 - val_loss: 10.3084 - val_acc: 0.1136\n",
      "Epoch 354/500\n",
      "12357/12357 [==============================] - 7s 546us/sample - loss: 0.5670 - acc: 0.8573 - val_loss: 10.3200 - val_acc: 0.1165\n",
      "Epoch 355/500\n",
      "12357/12357 [==============================] - 7s 599us/sample - loss: 0.5519 - acc: 0.8619 - val_loss: 10.3401 - val_acc: 0.1165\n",
      "Epoch 356/500\n",
      "12357/12357 [==============================] - 7s 547us/sample - loss: 0.5467 - acc: 0.8620 - val_loss: 10.2988 - val_acc: 0.1151\n",
      "Epoch 357/500\n",
      "12357/12357 [==============================] - 6s 511us/sample - loss: 0.5403 - acc: 0.8641 - val_loss: 10.3382 - val_acc: 0.1129\n",
      "Epoch 358/500\n",
      "12357/12357 [==============================] - 6s 489us/sample - loss: 0.5362 - acc: 0.8636 - val_loss: 10.3595 - val_acc: 0.1158\n",
      "Epoch 359/500\n",
      "12357/12357 [==============================] - 6s 486us/sample - loss: 0.5306 - acc: 0.8649 - val_loss: 10.3514 - val_acc: 0.1180\n",
      "Epoch 360/500\n",
      "12357/12357 [==============================] - 6s 489us/sample - loss: 0.5289 - acc: 0.8654 - val_loss: 10.3619 - val_acc: 0.1143\n",
      "Epoch 361/500\n",
      "12357/12357 [==============================] - 6s 502us/sample - loss: 0.5402 - acc: 0.8642 - val_loss: 10.3487 - val_acc: 0.1122\n",
      "Epoch 362/500\n",
      "12357/12357 [==============================] - 7s 536us/sample - loss: 0.5360 - acc: 0.8649 - val_loss: 10.3825 - val_acc: 0.1122\n",
      "Epoch 363/500\n",
      "12357/12357 [==============================] - 7s 533us/sample - loss: 0.5326 - acc: 0.8653 - val_loss: 10.3489 - val_acc: 0.1122\n",
      "Epoch 364/500\n",
      "12357/12357 [==============================] - 7s 563us/sample - loss: 0.5286 - acc: 0.8645 - val_loss: 10.3768 - val_acc: 0.1100\n",
      "Epoch 365/500\n",
      "12357/12357 [==============================] - 6s 501us/sample - loss: 0.5372 - acc: 0.8646 - val_loss: 10.3612 - val_acc: 0.1114\n",
      "Epoch 366/500\n",
      "12357/12357 [==============================] - 7s 532us/sample - loss: 0.5758 - acc: 0.8526 - val_loss: 10.3947 - val_acc: 0.1158\n",
      "Epoch 367/500\n",
      "12357/12357 [==============================] - 7s 539us/sample - loss: 0.5960 - acc: 0.8485 - val_loss: 10.3145 - val_acc: 0.1224\n",
      "Epoch 368/500\n",
      "12357/12357 [==============================] - 7s 533us/sample - loss: 0.5879 - acc: 0.8504 - val_loss: 10.4016 - val_acc: 0.1158\n",
      "Epoch 369/500\n",
      "12357/12357 [==============================] - 7s 534us/sample - loss: 0.5742 - acc: 0.8559 - val_loss: 10.4037 - val_acc: 0.1173\n",
      "Epoch 370/500\n",
      "12357/12357 [==============================] - 6s 522us/sample - loss: 0.5497 - acc: 0.8602 - val_loss: 10.4155 - val_acc: 0.1158\n",
      "Epoch 371/500\n",
      "12357/12357 [==============================] - 6s 519us/sample - loss: 0.5527 - acc: 0.8595 - val_loss: 10.4320 - val_acc: 0.1173\n",
      "Epoch 372/500\n",
      "12357/12357 [==============================] - 7s 531us/sample - loss: 0.5378 - acc: 0.8633 - val_loss: 10.4445 - val_acc: 0.1165\n",
      "Epoch 373/500\n",
      "12357/12357 [==============================] - 7s 547us/sample - loss: 0.5264 - acc: 0.8658 - val_loss: 10.4403 - val_acc: 0.1209\n",
      "Epoch 374/500\n",
      "12357/12357 [==============================] - 6s 521us/sample - loss: 0.5180 - acc: 0.8678 - val_loss: 10.4538 - val_acc: 0.1173\n",
      "Epoch 375/500\n",
      "12357/12357 [==============================] - 6s 516us/sample - loss: 0.5119 - acc: 0.8679 - val_loss: 10.4748 - val_acc: 0.1165\n",
      "Epoch 376/500\n",
      "12357/12357 [==============================] - 6s 523us/sample - loss: 0.5121 - acc: 0.8682 - val_loss: 10.4502 - val_acc: 0.1173\n",
      "Epoch 377/500\n",
      "12357/12357 [==============================] - 6s 518us/sample - loss: 0.5213 - acc: 0.8665 - val_loss: 10.4747 - val_acc: 0.1173\n",
      "Epoch 378/500\n",
      "12357/12357 [==============================] - 6s 520us/sample - loss: 0.5203 - acc: 0.8659 - val_loss: 10.4807 - val_acc: 0.1187\n",
      "Epoch 379/500\n",
      "12357/12357 [==============================] - 6s 517us/sample - loss: 0.5124 - acc: 0.8675 - val_loss: 10.4881 - val_acc: 0.1209\n",
      "Epoch 380/500\n",
      "12357/12357 [==============================] - 6s 522us/sample - loss: 0.5164 - acc: 0.8663 - val_loss: 10.4731 - val_acc: 0.1194\n",
      "Epoch 381/500\n",
      "12357/12357 [==============================] - 6s 517us/sample - loss: 0.5092 - acc: 0.8683 - val_loss: 10.4803 - val_acc: 0.1187\n",
      "Epoch 382/500\n",
      "12357/12357 [==============================] - 7s 551us/sample - loss: 0.5160 - acc: 0.8653 - val_loss: 10.4895 - val_acc: 0.1194\n",
      "Epoch 383/500\n",
      "12357/12357 [==============================] - 6s 523us/sample - loss: 0.5156 - acc: 0.8666 - val_loss: 10.4771 - val_acc: 0.1194\n",
      "Epoch 384/500\n",
      "12357/12357 [==============================] - 6s 524us/sample - loss: 0.5851 - acc: 0.8504 - val_loss: 10.4807 - val_acc: 0.1151\n",
      "Epoch 385/500\n",
      "12357/12357 [==============================] - 6s 523us/sample - loss: 0.5769 - acc: 0.8515 - val_loss: 10.4599 - val_acc: 0.1151\n",
      "Epoch 386/500\n",
      "12357/12357 [==============================] - 6s 523us/sample - loss: 0.5436 - acc: 0.8587 - val_loss: 10.4730 - val_acc: 0.1216\n",
      "Epoch 387/500\n",
      "12357/12357 [==============================] - 7s 529us/sample - loss: 0.5243 - acc: 0.8636 - val_loss: 10.4748 - val_acc: 0.1194\n",
      "Epoch 388/500\n",
      "12357/12357 [==============================] - 6s 525us/sample - loss: 0.5135 - acc: 0.8673 - val_loss: 10.5029 - val_acc: 0.1180\n",
      "Epoch 389/500\n",
      "12357/12357 [==============================] - 6s 525us/sample - loss: 0.5035 - acc: 0.8700 - val_loss: 10.4748 - val_acc: 0.1173\n",
      "Epoch 390/500\n",
      "12357/12357 [==============================] - 7s 543us/sample - loss: 0.4980 - acc: 0.8704 - val_loss: 10.4861 - val_acc: 0.1180\n",
      "Epoch 391/500\n",
      "12357/12357 [==============================] - 7s 534us/sample - loss: 0.4942 - acc: 0.8711 - val_loss: 10.5163 - val_acc: 0.1114\n",
      "Epoch 392/500\n",
      "12357/12357 [==============================] - 7s 562us/sample - loss: 0.4939 - acc: 0.8713 - val_loss: 10.5257 - val_acc: 0.1165\n",
      "Epoch 393/500\n",
      "12357/12357 [==============================] - 7s 538us/sample - loss: 0.4926 - acc: 0.8693 - val_loss: 10.4958 - val_acc: 0.1180\n",
      "Epoch 394/500\n",
      "12357/12357 [==============================] - 7s 533us/sample - loss: 0.4897 - acc: 0.8711 - val_loss: 10.5031 - val_acc: 0.1180\n",
      "Epoch 395/500\n",
      "12357/12357 [==============================] - 6s 526us/sample - loss: 0.4879 - acc: 0.8711 - val_loss: 10.5133 - val_acc: 0.1114\n",
      "Epoch 396/500\n",
      "12357/12357 [==============================] - 6s 523us/sample - loss: 0.4877 - acc: 0.8695 - val_loss: 10.5055 - val_acc: 0.1209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/500\n",
      "12357/12357 [==============================] - 6s 483us/sample - loss: 0.4849 - acc: 0.8706 - val_loss: 10.5474 - val_acc: 0.1165\n",
      "Epoch 398/500\n",
      "12357/12357 [==============================] - 6s 492us/sample - loss: 0.4975 - acc: 0.8687 - val_loss: 10.5412 - val_acc: 0.1194\n",
      "Epoch 399/500\n",
      "12357/12357 [==============================] - 7s 540us/sample - loss: 0.5088 - acc: 0.8653 - val_loss: 10.5369 - val_acc: 0.1216\n",
      "Epoch 400/500\n",
      "12357/12357 [==============================] - 7s 543us/sample - loss: 0.5780 - acc: 0.8507 - val_loss: 10.5129 - val_acc: 0.1194\n",
      "Epoch 401/500\n",
      "12357/12357 [==============================] - 6s 521us/sample - loss: 0.5707 - acc: 0.8502 - val_loss: 10.5209 - val_acc: 0.1165\n",
      "Epoch 402/500\n",
      "12357/12357 [==============================] - 6s 484us/sample - loss: 0.5703 - acc: 0.8533 - val_loss: 10.5091 - val_acc: 0.1158\n",
      "Epoch 403/500\n",
      "12357/12357 [==============================] - 6s 487us/sample - loss: 0.5653 - acc: 0.8538 - val_loss: 10.5189 - val_acc: 0.1143\n",
      "Epoch 404/500\n",
      "12357/12357 [==============================] - 6s 479us/sample - loss: 0.6054 - acc: 0.8449 - val_loss: 10.5241 - val_acc: 0.1202\n",
      "Epoch 405/500\n",
      "12357/12357 [==============================] - 6s 475us/sample - loss: 0.5356 - acc: 0.8612 - val_loss: 10.5541 - val_acc: 0.1143\n",
      "Epoch 406/500\n",
      "12357/12357 [==============================] - 6s 476us/sample - loss: 0.5167 - acc: 0.8653 - val_loss: 10.5281 - val_acc: 0.1194\n",
      "Epoch 407/500\n",
      "12357/12357 [==============================] - 6s 477us/sample - loss: 0.5269 - acc: 0.8623 - val_loss: 10.5890 - val_acc: 0.1202\n",
      "Epoch 408/500\n",
      "12357/12357 [==============================] - 6s 482us/sample - loss: 0.5373 - acc: 0.8585 - val_loss: 10.5258 - val_acc: 0.1194\n",
      "Epoch 409/500\n",
      "12357/12357 [==============================] - 6s 479us/sample - loss: 0.5108 - acc: 0.8660 - val_loss: 10.5259 - val_acc: 0.1209\n",
      "Epoch 410/500\n",
      "12357/12357 [==============================] - 6s 494us/sample - loss: 0.5156 - acc: 0.8654 - val_loss: 10.5158 - val_acc: 0.1202\n",
      "Epoch 411/500\n",
      "12357/12357 [==============================] - 7s 527us/sample - loss: 0.5235 - acc: 0.8628 - val_loss: 10.5480 - val_acc: 0.1209\n",
      "Epoch 412/500\n",
      "12357/12357 [==============================] - 6s 489us/sample - loss: 0.5167 - acc: 0.8656 - val_loss: 10.5233 - val_acc: 0.1224\n",
      "Epoch 413/500\n",
      "12357/12357 [==============================] - 6s 499us/sample - loss: 0.5046 - acc: 0.8674 - val_loss: 10.5524 - val_acc: 0.1158\n",
      "Epoch 414/500\n",
      "12357/12357 [==============================] - 6s 486us/sample - loss: 0.4956 - acc: 0.8683 - val_loss: 10.5553 - val_acc: 0.1165\n",
      "Epoch 415/500\n",
      "12357/12357 [==============================] - 6s 494us/sample - loss: 0.4887 - acc: 0.8710 - val_loss: 10.5244 - val_acc: 0.1187\n",
      "Epoch 416/500\n",
      "12357/12357 [==============================] - 6s 518us/sample - loss: 0.4922 - acc: 0.8703 - val_loss: 10.5481 - val_acc: 0.1202\n",
      "Epoch 417/500\n",
      "12357/12357 [==============================] - 6s 497us/sample - loss: 0.4885 - acc: 0.8719 - val_loss: 10.5404 - val_acc: 0.1209\n",
      "Epoch 418/500\n",
      "12357/12357 [==============================] - 6s 504us/sample - loss: 0.4859 - acc: 0.8704 - val_loss: 10.5424 - val_acc: 0.1129\n",
      "Epoch 419/500\n",
      "12357/12357 [==============================] - 6s 498us/sample - loss: 0.4811 - acc: 0.8720 - val_loss: 10.5452 - val_acc: 0.1202\n",
      "Epoch 420/500\n",
      "12357/12357 [==============================] - 7s 535us/sample - loss: 0.4766 - acc: 0.8720 - val_loss: 10.5680 - val_acc: 0.1224\n",
      "Epoch 421/500\n",
      "12357/12357 [==============================] - 6s 506us/sample - loss: 0.4739 - acc: 0.8730 - val_loss: 10.5549 - val_acc: 0.1238\n",
      "Epoch 422/500\n",
      "12357/12357 [==============================] - 6s 509us/sample - loss: 0.4744 - acc: 0.8731 - val_loss: 10.5709 - val_acc: 0.1194\n",
      "Epoch 423/500\n",
      "12357/12357 [==============================] - 6s 504us/sample - loss: 0.4720 - acc: 0.8715 - val_loss: 10.5807 - val_acc: 0.1187\n",
      "Epoch 424/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 0.4688 - acc: 0.8739 - val_loss: 10.6138 - val_acc: 0.1180\n",
      "Epoch 425/500\n",
      "12357/12357 [==============================] - 6s 506us/sample - loss: 0.4685 - acc: 0.8734 - val_loss: 10.5876 - val_acc: 0.1180\n",
      "Epoch 426/500\n",
      "12357/12357 [==============================] - 7s 546us/sample - loss: 0.4661 - acc: 0.8723 - val_loss: 10.6069 - val_acc: 0.1209\n",
      "Epoch 427/500\n",
      "12357/12357 [==============================] - 6s 510us/sample - loss: 0.4634 - acc: 0.8721 - val_loss: 10.6141 - val_acc: 0.1194\n",
      "Epoch 428/500\n",
      "12357/12357 [==============================] - 6s 509us/sample - loss: 0.4640 - acc: 0.8743 - val_loss: 10.6011 - val_acc: 0.1202\n",
      "Epoch 429/500\n",
      "12357/12357 [==============================] - 6s 514us/sample - loss: 0.4676 - acc: 0.8742 - val_loss: 10.6165 - val_acc: 0.1187\n",
      "Epoch 430/500\n",
      "12357/12357 [==============================] - 7s 551us/sample - loss: 0.4674 - acc: 0.8740 - val_loss: 10.6248 - val_acc: 0.1165\n",
      "Epoch 431/500\n",
      "12357/12357 [==============================] - 6s 510us/sample - loss: 0.4710 - acc: 0.8724 - val_loss: 10.6119 - val_acc: 0.1231\n",
      "Epoch 432/500\n",
      "12357/12357 [==============================] - 6s 524us/sample - loss: 0.4736 - acc: 0.8717 - val_loss: 10.6381 - val_acc: 0.1180\n",
      "Epoch 433/500\n",
      "12357/12357 [==============================] - 6s 513us/sample - loss: 0.4862 - acc: 0.8696 - val_loss: 10.6433 - val_acc: 0.1173\n",
      "Epoch 434/500\n",
      "12357/12357 [==============================] - 7s 528us/sample - loss: 0.4831 - acc: 0.8688 - val_loss: 10.6075 - val_acc: 0.1158\n",
      "Epoch 435/500\n",
      "12357/12357 [==============================] - 7s 532us/sample - loss: 0.4942 - acc: 0.8670 - val_loss: 10.6209 - val_acc: 0.1209\n",
      "Epoch 436/500\n",
      "12357/12357 [==============================] - 6s 523us/sample - loss: 0.4889 - acc: 0.8678 - val_loss: 10.6565 - val_acc: 0.1202\n",
      "Epoch 437/500\n",
      "12357/12357 [==============================] - 6s 524us/sample - loss: 0.5048 - acc: 0.8627 - val_loss: 10.6525 - val_acc: 0.1202\n",
      "Epoch 438/500\n",
      "12357/12357 [==============================] - 6s 522us/sample - loss: 0.4937 - acc: 0.8670 - val_loss: 10.6108 - val_acc: 0.1173\n",
      "Epoch 439/500\n",
      "12357/12357 [==============================] - 7s 561us/sample - loss: 0.4799 - acc: 0.8706 - val_loss: 10.6235 - val_acc: 0.1173\n",
      "Epoch 440/500\n",
      "12357/12357 [==============================] - 6s 519us/sample - loss: 0.4911 - acc: 0.8679 - val_loss: 10.6248 - val_acc: 0.1180\n",
      "Epoch 441/500\n",
      "12357/12357 [==============================] - 7s 532us/sample - loss: 0.4737 - acc: 0.8721 - val_loss: 10.6347 - val_acc: 0.1202\n",
      "Epoch 442/500\n",
      "12357/12357 [==============================] - 6s 521us/sample - loss: 0.4634 - acc: 0.8732 - val_loss: 10.6709 - val_acc: 0.1216\n",
      "Epoch 443/500\n",
      "12357/12357 [==============================] - 6s 522us/sample - loss: 0.4626 - acc: 0.8738 - val_loss: 10.6457 - val_acc: 0.1194\n",
      "Epoch 444/500\n",
      "12357/12357 [==============================] - 7s 578us/sample - loss: 0.4597 - acc: 0.8729 - val_loss: 10.6606 - val_acc: 0.1253\n",
      "Epoch 445/500\n",
      "12357/12357 [==============================] - 7s 589us/sample - loss: 0.4610 - acc: 0.8730 - val_loss: 10.6614 - val_acc: 0.1187\n",
      "Epoch 446/500\n",
      "12357/12357 [==============================] - 7s 545us/sample - loss: 0.4647 - acc: 0.8729 - val_loss: 10.6395 - val_acc: 0.1180\n",
      "Epoch 447/500\n",
      "12357/12357 [==============================] - 7s 556us/sample - loss: 0.4651 - acc: 0.8738 - val_loss: 10.6589 - val_acc: 0.1194\n",
      "Epoch 448/500\n",
      "12357/12357 [==============================] - 7s 555us/sample - loss: 0.4612 - acc: 0.8736 - val_loss: 10.6688 - val_acc: 0.1187\n",
      "Epoch 449/500\n",
      "12357/12357 [==============================] - 7s 528us/sample - loss: 0.4889 - acc: 0.8675 - val_loss: 10.6952 - val_acc: 0.1209\n",
      "Epoch 450/500\n",
      "12357/12357 [==============================] - 7s 529us/sample - loss: 0.4693 - acc: 0.8722 - val_loss: 10.6785 - val_acc: 0.1209\n",
      "Epoch 451/500\n",
      "12357/12357 [==============================] - 7s 539us/sample - loss: 0.4663 - acc: 0.8738 - val_loss: 10.6797 - val_acc: 0.1151\n",
      "Epoch 452/500\n",
      "12357/12357 [==============================] - 6s 523us/sample - loss: 0.4674 - acc: 0.8706 - val_loss: 10.7186 - val_acc: 0.1194\n",
      "Epoch 453/500\n",
      "12357/12357 [==============================] - 7s 538us/sample - loss: 0.4598 - acc: 0.8746 - val_loss: 10.6982 - val_acc: 0.1180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/500\n",
      "12357/12357 [==============================] - 7s 544us/sample - loss: 0.4540 - acc: 0.8757 - val_loss: 10.6809 - val_acc: 0.1202\n",
      "Epoch 455/500\n",
      "12357/12357 [==============================] - 6s 491us/sample - loss: 0.4511 - acc: 0.8751 - val_loss: 10.6826 - val_acc: 0.1202loss: 0.4547 - ac\n",
      "Epoch 456/500\n",
      "12357/12357 [==============================] - 6s 483us/sample - loss: 0.4495 - acc: 0.8751 - val_loss: 10.7087 - val_acc: 0.1158\n",
      "Epoch 457/500\n",
      "12357/12357 [==============================] - 7s 533us/sample - loss: 0.4469 - acc: 0.8753 - val_loss: 10.7129 - val_acc: 0.1165\n",
      "Epoch 458/500\n",
      "12357/12357 [==============================] - 6s 492us/sample - loss: 0.4434 - acc: 0.8767 - val_loss: 10.7313 - val_acc: 0.1136\n",
      "Epoch 459/500\n",
      "12357/12357 [==============================] - 6s 481us/sample - loss: 0.4401 - acc: 0.8776 - val_loss: 10.7219 - val_acc: 0.1143\n",
      "Epoch 460/500\n",
      "12357/12357 [==============================] - 6s 486us/sample - loss: 0.4402 - acc: 0.8763 - val_loss: 10.7172 - val_acc: 0.1136\n",
      "Epoch 461/500\n",
      "12357/12357 [==============================] - 6s 484us/sample - loss: 0.4406 - acc: 0.8768 - val_loss: 10.7443 - val_acc: 0.1143\n",
      "Epoch 462/500\n",
      "12357/12357 [==============================] - 6s 482us/sample - loss: 0.4437 - acc: 0.8753 - val_loss: 10.7550 - val_acc: 0.1151\n",
      "Epoch 463/500\n",
      "12357/12357 [==============================] - 6s 482us/sample - loss: 0.4435 - acc: 0.8751 - val_loss: 10.7417 - val_acc: 0.1158\n",
      "Epoch 464/500\n",
      "12357/12357 [==============================] - 6s 486us/sample - loss: 0.4487 - acc: 0.8744 - val_loss: 10.7405 - val_acc: 0.1202\n",
      "Epoch 465/500\n",
      "12357/12357 [==============================] - 6s 482us/sample - loss: 0.4717 - acc: 0.8703 - val_loss: 10.7732 - val_acc: 0.1216\n",
      "Epoch 466/500\n",
      "12357/12357 [==============================] - 6s 480us/sample - loss: 0.5303 - acc: 0.8535 - val_loss: 10.7196 - val_acc: 0.1260\n",
      "Epoch 467/500\n",
      "12357/12357 [==============================] - 6s 520us/sample - loss: 0.5031 - acc: 0.8625 - val_loss: 10.6992 - val_acc: 0.1173\n",
      "Epoch 468/500\n",
      "12357/12357 [==============================] - 6s 481us/sample - loss: 0.4699 - acc: 0.8693 - val_loss: 10.7140 - val_acc: 0.1216\n",
      "Epoch 469/500\n",
      "12357/12357 [==============================] - 6s 478us/sample - loss: 0.4611 - acc: 0.8721 - val_loss: 10.7157 - val_acc: 0.1202\n",
      "Epoch 470/500\n",
      "12357/12357 [==============================] - 6s 491us/sample - loss: 0.4607 - acc: 0.8725 - val_loss: 10.7220 - val_acc: 0.1209\n",
      "Epoch 471/500\n",
      "12357/12357 [==============================] - 6s 491us/sample - loss: 0.4471 - acc: 0.8745 - val_loss: 10.7475 - val_acc: 0.1136\n",
      "Epoch 472/500\n",
      "12357/12357 [==============================] - 6s 485us/sample - loss: 0.4469 - acc: 0.8741 - val_loss: 10.7069 - val_acc: 0.1238\n",
      "Epoch 473/500\n",
      "12357/12357 [==============================] - 6s 497us/sample - loss: 0.4490 - acc: 0.8740 - val_loss: 10.7585 - val_acc: 0.1173\n",
      "Epoch 474/500\n",
      "12357/12357 [==============================] - 6s 504us/sample - loss: 0.4409 - acc: 0.8759 - val_loss: 10.7655 - val_acc: 0.1209\n",
      "Epoch 475/500\n",
      "12357/12357 [==============================] - 6s 506us/sample - loss: 0.4373 - acc: 0.8752 - val_loss: 10.7836 - val_acc: 0.1202\n",
      "Epoch 476/500\n",
      "12357/12357 [==============================] - 6s 509us/sample - loss: 0.4341 - acc: 0.8776 - val_loss: 10.7847 - val_acc: 0.1245\n",
      "Epoch 477/500\n",
      "12357/12357 [==============================] - 7s 537us/sample - loss: 0.4311 - acc: 0.8780 - val_loss: 10.7328 - val_acc: 0.1245\n",
      "Epoch 478/500\n",
      "12357/12357 [==============================] - 6s 497us/sample - loss: 0.4299 - acc: 0.8766 - val_loss: 10.7705 - val_acc: 0.1231\n",
      "Epoch 479/500\n",
      "12357/12357 [==============================] - 6s 504us/sample - loss: 0.4290 - acc: 0.8764 - val_loss: 10.7718 - val_acc: 0.1224\n",
      "Epoch 480/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 0.4269 - acc: 0.8775 - val_loss: 10.7983 - val_acc: 0.1180\n",
      "Epoch 481/500\n",
      "12357/12357 [==============================] - 6s 505us/sample - loss: 0.4295 - acc: 0.8772 - val_loss: 10.8108 - val_acc: 0.1173\n",
      "Epoch 482/500\n",
      "12357/12357 [==============================] - 6s 509us/sample - loss: 0.4290 - acc: 0.8759 - val_loss: 10.7977 - val_acc: 0.1187\n",
      "Epoch 483/500\n",
      "12357/12357 [==============================] - 6s 512us/sample - loss: 0.4315 - acc: 0.8759 - val_loss: 10.7872 - val_acc: 0.1180\n",
      "Epoch 484/500\n",
      "12357/12357 [==============================] - 6s 511us/sample - loss: 0.4365 - acc: 0.8743 - val_loss: 10.7595 - val_acc: 0.1202\n",
      "Epoch 485/500\n",
      "12357/12357 [==============================] - 6s 520us/sample - loss: 0.4418 - acc: 0.8732 - val_loss: 10.7900 - val_acc: 0.1165\n",
      "Epoch 486/500\n",
      "12357/12357 [==============================] - 7s 535us/sample - loss: 0.4865 - acc: 0.8649 - val_loss: 10.7433 - val_acc: 0.1180\n",
      "Epoch 487/500\n",
      "12357/12357 [==============================] - 6s 519us/sample - loss: 0.4724 - acc: 0.8669 - val_loss: 10.7946 - val_acc: 0.1202\n",
      "Epoch 488/500\n",
      "12357/12357 [==============================] - 6s 509us/sample - loss: 0.4775 - acc: 0.8669 - val_loss: 10.8113 - val_acc: 0.1151\n",
      "Epoch 489/500\n",
      "12357/12357 [==============================] - 6s 514us/sample - loss: 0.4614 - acc: 0.8696 - val_loss: 10.7887 - val_acc: 0.1129\n",
      "Epoch 490/500\n",
      "12357/12357 [==============================] - 6s 512us/sample - loss: 0.4528 - acc: 0.8737 - val_loss: 10.8090 - val_acc: 0.1122\n",
      "Epoch 491/500\n",
      "12357/12357 [==============================] - 6s 510us/sample - loss: 0.4495 - acc: 0.8715 - val_loss: 10.8097 - val_acc: 0.1202\n",
      "Epoch 492/500\n",
      "12357/12357 [==============================] - 6s 509us/sample - loss: 0.4423 - acc: 0.8737 - val_loss: 10.8265 - val_acc: 0.1202\n",
      "Epoch 493/500\n",
      "12357/12357 [==============================] - 6s 512us/sample - loss: 0.4341 - acc: 0.8763 - val_loss: 10.8221 - val_acc: 0.1187\n",
      "Epoch 494/500\n",
      "12357/12357 [==============================] - 6s 520us/sample - loss: 0.4581 - acc: 0.8687 - val_loss: 10.8084 - val_acc: 0.1187\n",
      "Epoch 495/500\n",
      "12357/12357 [==============================] - 6s 523us/sample - loss: 0.4443 - acc: 0.8751 - val_loss: 10.8162 - val_acc: 0.1224\n",
      "Epoch 496/500\n",
      "12357/12357 [==============================] - 7s 539us/sample - loss: 0.4431 - acc: 0.8751 - val_loss: 10.8401 - val_acc: 0.1202\n",
      "Epoch 497/500\n",
      "12357/12357 [==============================] - 6s 518us/sample - loss: 0.4366 - acc: 0.8756 - val_loss: 10.8470 - val_acc: 0.1143\n",
      "Epoch 498/500\n",
      "12357/12357 [==============================] - 6s 515us/sample - loss: 0.4384 - acc: 0.8746 - val_loss: 10.7864 - val_acc: 0.1202\n",
      "Epoch 499/500\n",
      "12357/12357 [==============================] - 6s 514us/sample - loss: 0.4349 - acc: 0.8746 - val_loss: 10.8213 - val_acc: 0.1202\n",
      "Epoch 500/500\n",
      "12357/12357 [==============================] - 6s 519us/sample - loss: 0.4271 - acc: 0.8764 - val_loss: 10.8214 - val_acc: 0.1194\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY, validation_split=VAL_SPLIT, verbose=1, epochs = EPOCHS, batch_size=BATCH_SIZE, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\matplotlib\\legend.py:798: UserWarning: Legend does not support 'T' instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\matplotlib\\legend.py:798: UserWarning: Legend does not support 'r' instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\matplotlib\\legend.py:798: UserWarning: Legend does not support 'a' instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\matplotlib\\legend.py:798: UserWarning: Legend does not support 'i' instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\matplotlib\\legend.py:798: UserWarning: Legend does not support 'n' instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\matplotlib\\legend.py:798: UserWarning: Legend does not support ' ' instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\matplotlib\\legend.py:798: UserWarning: Legend does not support 'A' instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\matplotlib\\legend.py:798: UserWarning: Legend does not support 'L' instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n",
      "C:\\Users\\XARC\\Anaconda3\\lib\\site-packages\\matplotlib\\legend.py:798: UserWarning: Legend does not support 'o' instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \"aka-proxy-artists\".format(orig_handle)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(EPOCHS)\n",
    "\n",
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.xlabel('EPOCHS')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.legend('Train Acc', 'Val Acc')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.xlabel('EPOCHS')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend('Train Loss', 'Val Loss')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Poetry by iterating over the predictor from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angels stole thy pure love \n",
      "sends his early ray \n",
      "i beg for your provost and fellows of trinity \n",
      "is a hell for a lonely my bride \n",
      "a prison ship lies waiting in the bay \n",
      "a big mauser bullet got stuck in the firelights \n",
      "is the grass my hole in my breast \n",
      "for the black velvet street my darling \n",
      "are thinking of the rose of the summer \n",
      "a fade of yore \n",
      "in the morning early \n",
      "i was standing there and asked \n",
      "me was i hired wages i required i was almost tired of the \n",
      "day that i first saw the light \n",
      "no other leave see by the night \n",
      "from ballygrant \n",
      "in the island \n",
      "to me my sailed at brooks \n",
      "entwine itself verdantly still \n",
      "for mallow water crying \n",
      "cockles and mussels alive alive o \n",
      "when i was a young man i heard my father say \n",
      "that if they were bound for a ball or a bath \n",
      "a drink love round a customer \n",
      "i spent with me it \n",
      "was early early in the spring \n",
      "in the morning early \n",
      "i was standing there and asked \n",
      "me was i hired wages i required i was almost tired of the \n",
      "day that i first saw the light \n",
      "no other leave see by the night \n",
      "from ballygrant \n",
      "in the island \n",
      "to me my sailed at brooks \n",
      "entwine itself verdantly still \n",
      "for mallow water crying \n",
      "cockles and mussels alive alive o \n",
      "when i was a young man i heard my father say \n",
      "that if they were bound for a ball or a bath \n",
      "a drink love round a customer \n",
      "i spent with me it \n",
      "was early early in the spring \n",
      "in the morning early \n",
      "i was standing there and asked \n",
      "me was i hired wages i required i was almost tired of the \n",
      "day that i first saw the light \n",
      "no other leave see by the night \n",
      "from ballygrant \n",
      "in the island \n",
      "to me my sailed at brooks \n",
      "entwine itself verdantly still \n",
      "for mallow water crying \n",
      "cockles and mussels alive alive o \n",
      "when i was a young man i heard my father say \n",
      "that if they were bound for a ball or a bath \n",
      "a drink love round a customer \n",
      "i spent with me it \n",
      "was early early in the spring \n",
      "in the morning early \n",
      "i was standing there and asked \n",
      "me was i hired wages i required i was almost tired of the \n",
      "day that i first saw the light \n",
      "no other leave see by the night \n",
      "from ballygrant \n",
      "in the island \n",
      "to me my sailed at brooks \n",
      "entwine itself verdantly still \n",
      "for mallow water crying \n",
      "cockles and mussels alive alive o \n",
      "when i was a young man i heard my father say \n",
      "that if they were bound for a ball or a bath \n",
      "a drink love round a customer \n",
      "i spent with me it \n",
      "was early early in the spring \n",
      "in the morning early \n",
      "i was standing there and asked \n",
      "me was i hired wages i required i was almost tired of the \n",
      "day that i first saw the light \n",
      "no other leave see by the night \n",
      "from ballygrant \n",
      "in the island \n",
      "to me my sailed at brooks \n",
      "entwine itself verdantly still \n",
      "for mallow water crying \n",
      "cockles and mussels alive alive o \n",
      "when i was a young man i heard my father say \n",
      "that if they were bound for a ball or a bath \n",
      "a drink love round a customer \n",
      "i spent with me it \n",
      "was early early in the spring \n",
      "in the morning early \n",
      "i was standing there and asked \n",
      "me was i hired wages i required i was almost tired of the \n",
      "day that i first saw the light \n",
      "no other leave see by the night \n",
      "from ballygrant \n",
      "in the island \n",
      "to me my sailed at brooks \n",
      "entwine itself verdantly still \n",
      "for mallow water crying \n",
      "cockles and mussels alive alive o \n",
      "when i was a young man i heard my father say \n",
      "that if they were bound for a ball or a bath \n",
      "a drink love round a customer \n",
      "i spent with me it \n",
      "was early early in the spring \n",
      "in the morning early \n",
      "i was standing there and asked \n",
      "me was i hired wages i required i was almost tired of the \n",
      "day that i first saw the light \n",
      "no other leave see by the night \n",
      "from ballygrant \n",
      "in the island \n",
      "to me my sailed at brooks \n",
      "entwine itself verdantly still \n",
      "for mallow water crying \n",
      "cockles and mussels alive alive o \n",
      "when i was a young man i heard my father say \n",
      "that if they were bound for a ball or a bath \n",
      "a drink love round a customer \n",
      "i spent with me it \n",
      "was early early in the spring \n",
      "in the morning early \n",
      "i was standing there and asked \n",
      "me was i hired wages i required i was almost tired of the \n",
      "day that i first saw the light \n",
      "no other leave see by the night \n",
      "from ballygrant \n",
      "in the island \n",
      "to me my sailed at brooks \n",
      "entwine itself verdantly still \n",
      "for mallow water crying \n",
      "cockles and mussels alive alive o \n",
      "when i was a young man i heard my father say \n",
      "that if they were bound for a ball or a bath \n",
      "a drink love round a customer \n",
      "i spent "
     ]
    }
   ],
   "source": [
    "sentence = SEEDER.lower()\n",
    "corpus = SEEDER.lower()\n",
    "new_line = False\n",
    "print (sentence, end=' ')\n",
    "for i in range(NUM_PREDICTIONS):\n",
    "    seq = tokenizer.texts_to_sequences([sentence])\n",
    "    seq = pad_sequences(seq, padding=PADDING, truncating=TRUNC, maxlen=INP_LEN)\n",
    "    new_word = model.predict_classes(seq)\n",
    "    new_word = reverse_word_index[new_word[0]]\n",
    "    if new_line:\n",
    "        corpus += new_word\n",
    "        new_line = False\n",
    "    else:\n",
    "        corpus += ' ' + new_word\n",
    "    \n",
    "    if new_word=='\\n':\n",
    "        sentence = reverse_word_index[seq[0][-1]]\n",
    "        new_line = True\n",
    "        print (new_word, end='')\n",
    "        #sentence = reverse_word_index[random.randint(1, total_words)]\n",
    "    else:\n",
    "        sentence += ' ' + new_word\n",
    "        print (new_word, end=' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Poetry in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(save_file_path, 'w') as f:\n",
    "        f.write(corpus)\n",
    "        f.close()\n",
    "except:\n",
    "    print(\"\\nWrite was Unsuccessful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
