{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of cats_vs_dogs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANSHAY/deeplearning/blob/master/8_cats_vs_dogs/Copy_of_cats_vs_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ihN1MWza0gT1"
      },
      "source": [
        "## Classification of Cats vs Dogs using CNN with Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oiZt65HS0xGF"
      },
      "source": [
        "## Download and unzip the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gUjCIajs3hJo",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "import random\n",
        "from shutil import copyfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZKJEvLLF0iWx",
        "outputId": "7b9cb488-d739-494c-c995-71e28f2b482c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "# If the URL doesn't work, visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
        "# And right click on the 'Download Manually' link to get a new URL to the dataset\n",
        "\n",
        "# Note: This is a very large dataset and will take time to download\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
        "    -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "local_zip = '/tmp/cats-and-dogs.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-14 09:35:33--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 92.122.255.148, 2a02:26f0:db:29f::e59, 2a02:26f0:db:2a3::e59\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|92.122.255.148|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
            "\n",
            "/tmp/cats-and-dogs. 100%[===================>] 786.68M  57.1MB/s    in 17s     \n",
            "\n",
            "2019-06-14 09:35:50 (46.9 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hs1AZwad05n7"
      },
      "source": [
        "## Define paths for data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aKr9wueO1b2K",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    os.mkdir('/tmp/cats_vs_dogs')\n",
        "    os.mkdir('/tmp/cats_vs_dogs/models')\n",
        "    os.mkdir('/tmp/cats_vs_dogs/train')\n",
        "    os.mkdir('/tmp/cats_vs_dogs/test')\n",
        "    os.mkdir('/tmp/cats_vs_dogs/train/cats')\n",
        "    os.mkdir('/tmp/cats_vs_dogs/train/dogs')\n",
        "    os.mkdir('/tmp/cats_vs_dogs/test/cats')\n",
        "    os.mkdir('/tmp/cats_vs_dogs/test/dogs')\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j3KSgSGn452M"
      },
      "source": [
        "## Split the data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KWEFSn5Q1kb_",
        "outputId": "7e37cf76-ead2-4a74-ff6b-1f17570d9afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE):\n",
        "        file = SOURCE + filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[-testing_length:]\n",
        "\n",
        "    for filename in training_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TRAINING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in testing_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TESTING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats_vs_dogs/train/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats_vs_dogs/test/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats_vs_dogs/train/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats_vs_dogs/test/dogs/\"\n",
        "\n",
        "split_size = 0.99\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
        "\n",
        "# Expected output\n",
        "# 666.jpg is zero length, so ignoring\n",
        "# 11702.jpg is zero length, so ignoring"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "666.jpg is zero length, so ignoring.\n",
            "11702.jpg is zero length, so ignoring.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KCyJtAZa5yvY"
      },
      "source": [
        "## Main code starts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJr8wnoTSqrP",
        "colab_type": "text"
      },
      "source": [
        "#### import all modules\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mvyvtswJ0gT6",
        "colab": {}
      },
      "source": [
        "# import all modules\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSimQ0BNSwhR",
        "colab_type": "text"
      },
      "source": [
        "#### define metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lRB7OluP0gUH",
        "outputId": "83272cd4-3fd9-4024-eada-965d3dca4cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "## define metadata\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "print(\"\\nDefining metadata\")\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "Nrows = 150\n",
        "Ncols = 150\n",
        "BATCH_SIZE = 20\n",
        "NUM_EPOCHS = 74\n",
        "FILTER_SIZE = (3,3)\n",
        "model_path = \"/model\"+\"_R\"+str(Nrows)+\"_C\"+str(Ncols)+\"_fs\"+str(FILTER_SIZE[0])+\"_ep\"+str(NUM_EPOCHS)+\".h5\"\n",
        "print(\"\\nMetadata defined\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-14 09:37:25--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.133.128, 2a00:1450:400c:c0c::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.133.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep  19%[==>                 ]  16.01M  80.0MB/s               \r        /tmp/incept  49%[========>           ]  41.70M   104MB/s               \r       /tmp/incepti  88%[================>   ]  74.25M   124MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   132MB/s    in 0.6s    \n",
            "\n",
            "2019-06-14 09:37:26 (132 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "\n",
            "Defining metadata\n",
            "\n",
            "Metadata defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt_70BM5S0Mf",
        "colab_type": "text"
      },
      "source": [
        "#### Function to plot Loss and Accuracy of a model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SsdWDhFy0gUY",
        "colab": {}
      },
      "source": [
        "# Function to plot Loss and Accuracy of a model\n",
        "\n",
        "def plot_results(history):\n",
        "    # Retrieve a list of list results on training and val data\n",
        "    # sets for each training epoch\n",
        "    acc=history.history['acc']\n",
        "    val_acc=history.history['val_acc']\n",
        "    loss=history.history['loss']\n",
        "    val_loss=history.history['val_loss']\n",
        "    \n",
        "    # Get number of epochs\n",
        "    epochs=range(len(acc)) \n",
        "    \n",
        "    # Plot training and validation accuracy per epoch\n",
        "    plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "    plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.figure()\n",
        "    \n",
        "    # Plot training and validation loss per epoch\n",
        "    plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "    plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "    \n",
        "    plt.title('Training and validation loss')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VQo6iHTS3YM",
        "colab_type": "text"
      },
      "source": [
        "#### define callbacks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RvC5dtuf0gUe",
        "colab": {}
      },
      "source": [
        "# define callbacks\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epochs, logs={}):\n",
        "        if (logs.get('acc') > 0.99):\n",
        "            self.model.stop_training = True\n",
        "            print (\"\\nStopping training as accuracy is above 99%\")\n",
        "callback = myCallback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap-Yh1trS7qf",
        "colab_type": "text"
      },
      "source": [
        "#### define model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pIvZ_oGX0gUi",
        "colab": {}
      },
      "source": [
        "# define model\n",
        "\n",
        "def fetch_model(train_gen=None, val_gen=None):\n",
        "    try:\n",
        "        print(\"\\nLoading saved model\")\n",
        "        model = tf.keras.models.load_model(model_path)\n",
        "        print(\"\\nmodel loaded\")\n",
        "    except:\n",
        "        print(\"\\nModel not found. Training new model...\")\n",
        "        pre_trained_model = InceptionV3(input_shape=(Nrows,Ncols,3),\n",
        "                                        include_top=False,\n",
        "                                        weights=None)\n",
        "        pre_trained_model.load_weights(local_weights_file)\n",
        "        num_layers = len(pre_trained_model.layers)\n",
        "        for i, layer in enumerate(pre_trained_model.layers):\n",
        "          if i < num_layers-14:\n",
        "            layer.trainable=False\n",
        "          else:\n",
        "            layer.trainable=True            \n",
        "        last_layer = pre_trained_model.get_layer('mixed7')\n",
        "        last_output = last_layer.output\n",
        "        last_layer.trainable = True\n",
        "        x = tf.keras.layers.Conv2D(256, FILTER_SIZE, activation='relu')(last_output)\n",
        "        x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
        "        x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "        x = tf.keras.layers.Flatten()(x)\n",
        "        x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "        x = tf.keras.layers.Dropout(0.2)(x)\n",
        "        x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = tf.keras.models.Model(pre_trained_model.input, x)\n",
        "        \n",
        "        ## compile model\n",
        "        model.compile(optimizer=RMSprop(lr=0.001),\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['acc'])\n",
        "        model.summary()\n",
        "        \n",
        "        ## fit model to data - training\n",
        "        history = model.fit_generator(train_gen,\n",
        "                                      epochs=NUM_EPOCHS,\n",
        "                                      steps_per_epoch=100,\n",
        "                                      validation_steps=50,\n",
        "                                      validation_data=val_gen,\n",
        "                                      verbose=1,\n",
        "                                      callbacks=[callback])\n",
        "        print(\"\\nNew model trained\")\n",
        "        ## save model to file\n",
        "        print(\"\\nSaving model for later use...\")\n",
        "        model.save(model_path)\n",
        "        print(\"\\nModel Successfully saved\")\n",
        "        ## plot results\n",
        "        print(\"\\nPlotting results...\")\n",
        "        plot_results(history)\n",
        "        print(\"\\n........................\")\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TEYaG6hy0gUo"
      },
      "source": [
        "# cats vs dogs classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9V8dgFNTEPD",
        "colab_type": "text"
      },
      "source": [
        "#### load data - change directories to the location of data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gd5oN0xa0gUq",
        "outputId": "6b88753f-0881-4789-f231-61beff494302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "## load data - change directories to the location of data\n",
        "\n",
        "print(\"\\nLoading data...\")\n",
        "train_dir = \"/tmp/cats_vs_dogs/train\"\n",
        "val_dir = \"/tmp/cats_vs_dogs/test\"\n",
        "\n",
        "train_data_gen = ImageDataGenerator(rescale=1/255.0, horizontal_flip=True)\n",
        "val_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_data_gen.flow_from_directory(\n",
        "                    train_dir,\n",
        "                    target_size=((Nrows, Ncols)),\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    class_mode='binary')\n",
        "val_gen = val_data_gen.flow_from_directory(\n",
        "                    val_dir,\n",
        "                    target_size=((Nrows, Ncols)),\n",
        "                    class_mode='binary')\n",
        "print(\"\\nData Generators defined\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading data...\n",
            "Found 24748 images belonging to 2 classes.\n",
            "Found 250 images belonging to 2 classes.\n",
            "\n",
            "Data Generators defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26FLxPFOTI5-",
        "colab_type": "text"
      },
      "source": [
        "#### fetch model (training)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V1cSDPSa0gU5",
        "outputId": "63656539-5e29-4cc4-bdad-b0d2869f41d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15571
        }
      },
      "source": [
        "# fetch model (training)\n",
        "\n",
        "print(\"\\nTraining model...\")\n",
        "model = fetch_model(train_gen, val_gen)\n",
        "print(\"\\nTraining Complete\")\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training model...\n",
            "\n",
            "Loading saved model\n",
            "\n",
            "Model not found. Training new model...\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_379 (Conv2D)             (None, 74, 74, 32)   864         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_376 (BatchN (None, 74, 74, 32)   96          conv2d_379[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, 74, 74, 32)   0           batch_normalization_376[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_380 (Conv2D)             (None, 72, 72, 32)   9216        activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_377 (BatchN (None, 72, 72, 32)   96          conv2d_380[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_377 (Activation)     (None, 72, 72, 32)   0           batch_normalization_377[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_381 (Conv2D)             (None, 72, 72, 64)   18432       activation_377[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_378 (BatchN (None, 72, 72, 64)   192         conv2d_381[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_378 (Activation)     (None, 72, 72, 64)   0           batch_normalization_378[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 35, 35, 64)   0           activation_378[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_382 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_379 (BatchN (None, 35, 35, 80)   240         conv2d_382[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_379 (Activation)     (None, 35, 35, 80)   0           batch_normalization_379[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_383 (Conv2D)             (None, 33, 33, 192)  138240      activation_379[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_380 (BatchN (None, 33, 33, 192)  576         conv2d_383[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_380 (Activation)     (None, 33, 33, 192)  0           batch_normalization_380[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling2D) (None, 16, 16, 192)  0           activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_387 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_384 (BatchN (None, 16, 16, 64)   192         conv2d_387[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_384 (Activation)     (None, 16, 16, 64)   0           batch_normalization_384[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_385 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_388 (Conv2D)             (None, 16, 16, 96)   55296       activation_384[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_382 (BatchN (None, 16, 16, 48)   144         conv2d_385[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_385 (BatchN (None, 16, 16, 96)   288         conv2d_388[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_382 (Activation)     (None, 16, 16, 48)   0           batch_normalization_382[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_385 (Activation)     (None, 16, 16, 96)   0           batch_normalization_385[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_36 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_384 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_386 (Conv2D)             (None, 16, 16, 64)   76800       activation_382[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_389 (Conv2D)             (None, 16, 16, 96)   82944       activation_385[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_390 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_381 (BatchN (None, 16, 16, 64)   192         conv2d_384[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_383 (BatchN (None, 16, 16, 64)   192         conv2d_386[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_386 (BatchN (None, 16, 16, 96)   288         conv2d_389[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_387 (BatchN (None, 16, 16, 32)   96          conv2d_390[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_381 (Activation)     (None, 16, 16, 64)   0           batch_normalization_381[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_383 (Activation)     (None, 16, 16, 64)   0           batch_normalization_383[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_386 (Activation)     (None, 16, 16, 96)   0           batch_normalization_386[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_387 (Activation)     (None, 16, 16, 32)   0           batch_normalization_387[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_381[0][0]             \n",
            "                                                                 activation_383[0][0]             \n",
            "                                                                 activation_386[0][0]             \n",
            "                                                                 activation_387[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_394 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_391 (BatchN (None, 16, 16, 64)   192         conv2d_394[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_391 (Activation)     (None, 16, 16, 64)   0           batch_normalization_391[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_392 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_395 (Conv2D)             (None, 16, 16, 96)   55296       activation_391[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_389 (BatchN (None, 16, 16, 48)   144         conv2d_392[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_392 (BatchN (None, 16, 16, 96)   288         conv2d_395[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_389 (Activation)     (None, 16, 16, 48)   0           batch_normalization_389[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_392 (Activation)     (None, 16, 16, 96)   0           batch_normalization_392[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_37 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_391 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_393 (Conv2D)             (None, 16, 16, 64)   76800       activation_389[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_396 (Conv2D)             (None, 16, 16, 96)   82944       activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_397 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_37[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_388 (BatchN (None, 16, 16, 64)   192         conv2d_391[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_390 (BatchN (None, 16, 16, 64)   192         conv2d_393[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_393 (BatchN (None, 16, 16, 96)   288         conv2d_396[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_394 (BatchN (None, 16, 16, 64)   192         conv2d_397[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_388 (Activation)     (None, 16, 16, 64)   0           batch_normalization_388[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_390 (Activation)     (None, 16, 16, 64)   0           batch_normalization_390[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, 16, 16, 96)   0           batch_normalization_393[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, 16, 16, 64)   0           batch_normalization_394[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_388[0][0]             \n",
            "                                                                 activation_390[0][0]             \n",
            "                                                                 activation_393[0][0]             \n",
            "                                                                 activation_394[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_401 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_398 (BatchN (None, 16, 16, 64)   192         conv2d_401[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_398 (Activation)     (None, 16, 16, 64)   0           batch_normalization_398[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_399 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_402 (Conv2D)             (None, 16, 16, 96)   55296       activation_398[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_396 (BatchN (None, 16, 16, 48)   144         conv2d_399[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_399 (BatchN (None, 16, 16, 96)   288         conv2d_402[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, 16, 16, 48)   0           batch_normalization_396[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_399 (Activation)     (None, 16, 16, 96)   0           batch_normalization_399[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_38 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_398 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_400 (Conv2D)             (None, 16, 16, 64)   76800       activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_403 (Conv2D)             (None, 16, 16, 96)   82944       activation_399[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_404 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_38[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_395 (BatchN (None, 16, 16, 64)   192         conv2d_398[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_397 (BatchN (None, 16, 16, 64)   192         conv2d_400[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_400 (BatchN (None, 16, 16, 96)   288         conv2d_403[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_401 (BatchN (None, 16, 16, 64)   192         conv2d_404[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, 16, 16, 64)   0           batch_normalization_395[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_397 (Activation)     (None, 16, 16, 64)   0           batch_normalization_397[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_400 (Activation)     (None, 16, 16, 96)   0           batch_normalization_400[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_401 (Activation)     (None, 16, 16, 64)   0           batch_normalization_401[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_395[0][0]             \n",
            "                                                                 activation_397[0][0]             \n",
            "                                                                 activation_400[0][0]             \n",
            "                                                                 activation_401[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_406 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_403 (BatchN (None, 16, 16, 64)   192         conv2d_406[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_403 (Activation)     (None, 16, 16, 64)   0           batch_normalization_403[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_407 (Conv2D)             (None, 16, 16, 96)   55296       activation_403[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_404 (BatchN (None, 16, 16, 96)   288         conv2d_407[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_404 (Activation)     (None, 16, 16, 96)   0           batch_normalization_404[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_405 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_408 (Conv2D)             (None, 7, 7, 96)     82944       activation_404[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_402 (BatchN (None, 7, 7, 384)    1152        conv2d_405[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_405 (BatchN (None, 7, 7, 96)     288         conv2d_408[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_402 (Activation)     (None, 7, 7, 384)    0           batch_normalization_402[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_405 (Activation)     (None, 7, 7, 96)     0           batch_normalization_405[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_402[0][0]             \n",
            "                                                                 activation_405[0][0]             \n",
            "                                                                 max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_413 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_410 (BatchN (None, 7, 7, 128)    384         conv2d_413[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_410 (Activation)     (None, 7, 7, 128)    0           batch_normalization_410[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_414 (Conv2D)             (None, 7, 7, 128)    114688      activation_410[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_411 (BatchN (None, 7, 7, 128)    384         conv2d_414[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_411 (Activation)     (None, 7, 7, 128)    0           batch_normalization_411[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_410 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_415 (Conv2D)             (None, 7, 7, 128)    114688      activation_411[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_407 (BatchN (None, 7, 7, 128)    384         conv2d_410[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_412 (BatchN (None, 7, 7, 128)    384         conv2d_415[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_407 (Activation)     (None, 7, 7, 128)    0           batch_normalization_407[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_412 (Activation)     (None, 7, 7, 128)    0           batch_normalization_412[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_411 (Conv2D)             (None, 7, 7, 128)    114688      activation_407[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_416 (Conv2D)             (None, 7, 7, 128)    114688      activation_412[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_408 (BatchN (None, 7, 7, 128)    384         conv2d_411[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_413 (BatchN (None, 7, 7, 128)    384         conv2d_416[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_408 (Activation)     (None, 7, 7, 128)    0           batch_normalization_408[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_413 (Activation)     (None, 7, 7, 128)    0           batch_normalization_413[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_39 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_409 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_412 (Conv2D)             (None, 7, 7, 192)    172032      activation_408[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_417 (Conv2D)             (None, 7, 7, 192)    172032      activation_413[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_418 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_39[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_406 (BatchN (None, 7, 7, 192)    576         conv2d_409[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_409 (BatchN (None, 7, 7, 192)    576         conv2d_412[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_414 (BatchN (None, 7, 7, 192)    576         conv2d_417[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_415 (BatchN (None, 7, 7, 192)    576         conv2d_418[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_406 (Activation)     (None, 7, 7, 192)    0           batch_normalization_406[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_409 (Activation)     (None, 7, 7, 192)    0           batch_normalization_409[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_414 (Activation)     (None, 7, 7, 192)    0           batch_normalization_414[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_415 (Activation)     (None, 7, 7, 192)    0           batch_normalization_415[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_406[0][0]             \n",
            "                                                                 activation_409[0][0]             \n",
            "                                                                 activation_414[0][0]             \n",
            "                                                                 activation_415[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_423 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_420 (BatchN (None, 7, 7, 160)    480         conv2d_423[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_420 (Activation)     (None, 7, 7, 160)    0           batch_normalization_420[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_424 (Conv2D)             (None, 7, 7, 160)    179200      activation_420[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_421 (BatchN (None, 7, 7, 160)    480         conv2d_424[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_421 (Activation)     (None, 7, 7, 160)    0           batch_normalization_421[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_420 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_425 (Conv2D)             (None, 7, 7, 160)    179200      activation_421[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_417 (BatchN (None, 7, 7, 160)    480         conv2d_420[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_422 (BatchN (None, 7, 7, 160)    480         conv2d_425[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_417 (Activation)     (None, 7, 7, 160)    0           batch_normalization_417[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_422 (Activation)     (None, 7, 7, 160)    0           batch_normalization_422[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_421 (Conv2D)             (None, 7, 7, 160)    179200      activation_417[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_426 (Conv2D)             (None, 7, 7, 160)    179200      activation_422[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_418 (BatchN (None, 7, 7, 160)    480         conv2d_421[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_423 (BatchN (None, 7, 7, 160)    480         conv2d_426[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_418 (Activation)     (None, 7, 7, 160)    0           batch_normalization_418[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_423 (Activation)     (None, 7, 7, 160)    0           batch_normalization_423[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_40 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_419 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_422 (Conv2D)             (None, 7, 7, 192)    215040      activation_418[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_427 (Conv2D)             (None, 7, 7, 192)    215040      activation_423[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_428 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_40[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_416 (BatchN (None, 7, 7, 192)    576         conv2d_419[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_419 (BatchN (None, 7, 7, 192)    576         conv2d_422[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_424 (BatchN (None, 7, 7, 192)    576         conv2d_427[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_425 (BatchN (None, 7, 7, 192)    576         conv2d_428[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_416 (Activation)     (None, 7, 7, 192)    0           batch_normalization_416[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_419 (Activation)     (None, 7, 7, 192)    0           batch_normalization_419[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_424 (Activation)     (None, 7, 7, 192)    0           batch_normalization_424[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_425 (Activation)     (None, 7, 7, 192)    0           batch_normalization_425[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_416[0][0]             \n",
            "                                                                 activation_419[0][0]             \n",
            "                                                                 activation_424[0][0]             \n",
            "                                                                 activation_425[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_433 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_430 (BatchN (None, 7, 7, 160)    480         conv2d_433[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_430 (Activation)     (None, 7, 7, 160)    0           batch_normalization_430[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_434 (Conv2D)             (None, 7, 7, 160)    179200      activation_430[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_431 (BatchN (None, 7, 7, 160)    480         conv2d_434[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_431 (Activation)     (None, 7, 7, 160)    0           batch_normalization_431[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_430 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_435 (Conv2D)             (None, 7, 7, 160)    179200      activation_431[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_427 (BatchN (None, 7, 7, 160)    480         conv2d_430[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_432 (BatchN (None, 7, 7, 160)    480         conv2d_435[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_427 (Activation)     (None, 7, 7, 160)    0           batch_normalization_427[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_432 (Activation)     (None, 7, 7, 160)    0           batch_normalization_432[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_431 (Conv2D)             (None, 7, 7, 160)    179200      activation_427[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_436 (Conv2D)             (None, 7, 7, 160)    179200      activation_432[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_428 (BatchN (None, 7, 7, 160)    480         conv2d_431[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_433 (BatchN (None, 7, 7, 160)    480         conv2d_436[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_428 (Activation)     (None, 7, 7, 160)    0           batch_normalization_428[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_433 (Activation)     (None, 7, 7, 160)    0           batch_normalization_433[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_41 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_429 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_432 (Conv2D)             (None, 7, 7, 192)    215040      activation_428[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_437 (Conv2D)             (None, 7, 7, 192)    215040      activation_433[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_438 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_41[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_426 (BatchN (None, 7, 7, 192)    576         conv2d_429[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_429 (BatchN (None, 7, 7, 192)    576         conv2d_432[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_434 (BatchN (None, 7, 7, 192)    576         conv2d_437[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_435 (BatchN (None, 7, 7, 192)    576         conv2d_438[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_426 (Activation)     (None, 7, 7, 192)    0           batch_normalization_426[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_429 (Activation)     (None, 7, 7, 192)    0           batch_normalization_429[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_434 (Activation)     (None, 7, 7, 192)    0           batch_normalization_434[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_435 (Activation)     (None, 7, 7, 192)    0           batch_normalization_435[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_426[0][0]             \n",
            "                                                                 activation_429[0][0]             \n",
            "                                                                 activation_434[0][0]             \n",
            "                                                                 activation_435[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_443 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_440 (BatchN (None, 7, 7, 192)    576         conv2d_443[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_440 (Activation)     (None, 7, 7, 192)    0           batch_normalization_440[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_444 (Conv2D)             (None, 7, 7, 192)    258048      activation_440[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_441 (BatchN (None, 7, 7, 192)    576         conv2d_444[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_441 (Activation)     (None, 7, 7, 192)    0           batch_normalization_441[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_440 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_445 (Conv2D)             (None, 7, 7, 192)    258048      activation_441[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_437 (BatchN (None, 7, 7, 192)    576         conv2d_440[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_442 (BatchN (None, 7, 7, 192)    576         conv2d_445[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_437 (Activation)     (None, 7, 7, 192)    0           batch_normalization_437[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_442 (Activation)     (None, 7, 7, 192)    0           batch_normalization_442[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_441 (Conv2D)             (None, 7, 7, 192)    258048      activation_437[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_446 (Conv2D)             (None, 7, 7, 192)    258048      activation_442[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_438 (BatchN (None, 7, 7, 192)    576         conv2d_441[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_443 (BatchN (None, 7, 7, 192)    576         conv2d_446[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_438 (Activation)     (None, 7, 7, 192)    0           batch_normalization_438[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_443 (Activation)     (None, 7, 7, 192)    0           batch_normalization_443[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_42 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_439 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_442 (Conv2D)             (None, 7, 7, 192)    258048      activation_438[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_447 (Conv2D)             (None, 7, 7, 192)    258048      activation_443[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_448 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_42[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_436 (BatchN (None, 7, 7, 192)    576         conv2d_439[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_439 (BatchN (None, 7, 7, 192)    576         conv2d_442[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_444 (BatchN (None, 7, 7, 192)    576         conv2d_447[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_445 (BatchN (None, 7, 7, 192)    576         conv2d_448[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_436 (Activation)     (None, 7, 7, 192)    0           batch_normalization_436[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_439 (Activation)     (None, 7, 7, 192)    0           batch_normalization_439[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_444 (Activation)     (None, 7, 7, 192)    0           batch_normalization_444[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_445 (Activation)     (None, 7, 7, 192)    0           batch_normalization_445[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_436[0][0]             \n",
            "                                                                 activation_439[0][0]             \n",
            "                                                                 activation_444[0][0]             \n",
            "                                                                 activation_445[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_473 (Conv2D)             (None, 5, 5, 256)    1769728     mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling2D) (None, 2, 2, 256)    0           conv2d_473[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2, 2, 1024)   263168      max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 4096)         0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 512)          2097664     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            513         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 13,106,337\n",
            "Trainable params: 4,131,073\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 80000 bytes but only got 0. Skipping tag 64640\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 65536 bytes but only got 0. Skipping tag 3\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 307363840 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 307888128 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 0. Skipping tag 3\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 328728576 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1385474 bytes but only got 5357. Skipping tag 513\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3846701056 bytes but only got 0. Skipping tag 2\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3300917248 bytes but only got 0. Skipping tag 7\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 5357. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/74\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.5291 - acc: 0.8010 - val_loss: 0.7946 - val_acc: 0.8689\n",
            "Epoch 2/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.2983 - acc: 0.8755 - val_loss: 0.2181 - val_acc: 0.9520\n",
            "Epoch 3/74\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 0.2855 - acc: 0.8830 - val_loss: 0.3981 - val_acc: 0.9552\n",
            "Epoch 4/74\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2739 - acc: 0.9020"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 80000 bytes but only got 0. Skipping tag 64640\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 65536 bytes but only got 0. Skipping tag 3\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 404094976 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 404619264 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 0. Skipping tag 3\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 425459712 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1385474 bytes but only got 6833. Skipping tag 513\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3846701056 bytes but only got 0. Skipping tag 2\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3300917248 bytes but only got 0. Skipping tag 7\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 6833. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 209715200 bytes but only got 0. Skipping tag 48\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 52428800 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6468665344 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1050744 bytes but only got 7027. Skipping tag 48\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 422313984 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 422838272 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3368026112 bytes but only got 0. Skipping tag 7\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 134479872 bytes but only got 0. Skipping tag 7\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 428867584 bytes but only got 0. Skipping tag 10\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 429391872 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2031616 bytes but only got 0. Skipping tag 3\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 429916160 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 21299200 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 24313856 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 453771264 bytes but only got 7032. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 7028. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 393216 bytes but only got 0. Skipping tag 3\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 416415744 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 416940032 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 524288 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 415825920 bytes but only got 7032. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 2. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 17s 172ms/step - loss: 0.2751 - acc: 0.9020 - val_loss: 0.1041 - val_acc: 0.9578\n",
            "Epoch 5/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.2518 - acc: 0.8945 - val_loss: 0.1310 - val_acc: 0.9712\n",
            "Epoch 6/74\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 0.2654 - acc: 0.9039"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 262146 bytes but only got 0. Skipping tag 2\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 262151 bytes but only got 0. Skipping tag 56\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 17s 171ms/step - loss: 0.2430 - acc: 0.9105 - val_loss: 0.4080 - val_acc: 0.9597\n",
            "Epoch 7/74\n",
            " 41/100 [===========>..................] - ETA: 4s - loss: 0.2423 - acc: 0.9073"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6553600 bytes but only got 0. Skipping tag 49\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1050744 bytes but only got 4951. Skipping tag 51\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 293339136 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 293863424 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 295698432 bytes but only got 0. Skipping tag 10\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 296222720 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 14745600 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 25624576 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 317718528 bytes but only got 4956. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 4952. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 287178752 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 287703040 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 286654464 bytes but only got 4956. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 76/100 [=====================>........] - ETA: 2s - loss: 0.2203 - acc: 0.9158"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18350080 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 6. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 17s 172ms/step - loss: 0.2272 - acc: 0.9130 - val_loss: 0.2585 - val_acc: 0.9751\n",
            "Epoch 8/74\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.2574 - acc: 0.9210 - val_loss: 0.6440 - val_acc: 0.9450\n",
            "Epoch 9/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.2360 - acc: 0.9100 - val_loss: 0.1590 - val_acc: 0.9680\n",
            "Epoch 10/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.2309 - acc: 0.9034 - val_loss: 0.6952 - val_acc: 0.9597\n",
            "Epoch 11/74\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 0.2230 - acc: 0.9236"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 17s 172ms/step - loss: 0.2305 - acc: 0.9165 - val_loss: 1.1312 - val_acc: 0.9054\n",
            "Epoch 12/74\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 0.2281 - acc: 0.9210 - val_loss: 2.0382 - val_acc: 0.8919\n",
            "Epoch 13/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1931 - acc: 0.9230 - val_loss: 1.2739 - val_acc: 0.9316\n",
            "Epoch 14/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1963 - acc: 0.9225 - val_loss: 0.2497 - val_acc: 0.9731\n",
            "Epoch 15/74\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.1746 - acc: 0.9386 - val_loss: 0.6347 - val_acc: 0.9712\n",
            "Epoch 16/74\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.2207 - acc: 0.9270 - val_loss: 0.4525 - val_acc: 0.9719\n",
            "Epoch 17/74\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.2034 - acc: 0.9220 - val_loss: 2.0049 - val_acc: 0.9322\n",
            "Epoch 18/74\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 0.1856 - acc: 0.9310 - val_loss: 1.8472 - val_acc: 0.9546\n",
            "Epoch 19/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.2212 - acc: 0.9265 - val_loss: 0.5440 - val_acc: 0.9642\n",
            "Epoch 20/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1875 - acc: 0.9315 - val_loss: 2.2496 - val_acc: 0.9457\n",
            "Epoch 21/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1890 - acc: 0.9340 - val_loss: 0.7695 - val_acc: 0.9642\n",
            "Epoch 22/74\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 0.1849 - acc: 0.9284"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 307363840 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 307888128 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 328728576 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1385474 bytes but only got 5357. Skipping tag 513\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 5357. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1965 - acc: 0.9315 - val_loss: 0.8763 - val_acc: 0.9648\n",
            "Epoch 23/74\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.1971 - acc: 0.9220 - val_loss: 1.4800 - val_acc: 0.9437\n",
            "Epoch 24/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1866 - acc: 0.9245 - val_loss: 0.5983 - val_acc: 0.9674\n",
            "Epoch 25/74\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.2063 - acc: 0.9235 - val_loss: 0.4507 - val_acc: 0.9687\n",
            "Epoch 26/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1556 - acc: 0.9440 - val_loss: 2.5822 - val_acc: 0.9380\n",
            "Epoch 27/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1940 - acc: 0.9410 - val_loss: 0.6657 - val_acc: 0.9680\n",
            "Epoch 28/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1852 - acc: 0.9326 - val_loss: 1.4034 - val_acc: 0.9597\n",
            "Epoch 29/74\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.1820 - acc: 0.9330 - val_loss: 1.0963 - val_acc: 0.9546\n",
            "Epoch 30/74\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.2002 - acc: 0.9350 - val_loss: 1.1548 - val_acc: 0.9482\n",
            "Epoch 31/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1853 - acc: 0.9405 - val_loss: 0.8386 - val_acc: 0.9719\n",
            "Epoch 32/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1839 - acc: 0.9340 - val_loss: 3.2963 - val_acc: 0.9290\n",
            "Epoch 33/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1817 - acc: 0.9355 - val_loss: 3.7205 - val_acc: 0.9399\n",
            "Epoch 34/74\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.1740 - acc: 0.9350 - val_loss: 1.8065 - val_acc: 0.9527\n",
            "Epoch 35/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1753 - acc: 0.9390 - val_loss: 4.3919 - val_acc: 0.9418\n",
            "Epoch 36/74\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1935 - acc: 0.9290 - val_loss: 2.1150 - val_acc: 0.9629\n",
            "Epoch 37/74\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.1950 - acc: 0.9405 - val_loss: 1.6218 - val_acc: 0.9584\n",
            "Epoch 38/74\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.1398 - acc: 0.9475 - val_loss: 2.5294 - val_acc: 0.9648\n",
            "Epoch 39/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1620 - acc: 0.9410 - val_loss: 1.8725 - val_acc: 0.9610\n",
            "Epoch 40/74\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.1690 - acc: 0.9445 - val_loss: 1.4958 - val_acc: 0.9597\n",
            "Epoch 41/74\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.1702 - acc: 0.9485 - val_loss: 3.8682 - val_acc: 0.9399\n",
            "Epoch 42/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1757 - acc: 0.9340 - val_loss: 2.8484 - val_acc: 0.9495\n",
            "Epoch 43/74\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.1775 - acc: 0.9430 - val_loss: 2.1638 - val_acc: 0.9520\n",
            "Epoch 44/74\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.1891 - acc: 0.9400 - val_loss: 1.8497 - val_acc: 0.9508\n",
            "Epoch 45/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1730 - acc: 0.9365 - val_loss: 1.2821 - val_acc: 0.9648\n",
            "Epoch 46/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1637 - acc: 0.9440 - val_loss: 1.6251 - val_acc: 0.9680\n",
            "Epoch 47/74\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.1814 - acc: 0.9355 - val_loss: 1.4026 - val_acc: 0.9687\n",
            "Epoch 48/74\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 0.1662 - acc: 0.9457 - val_loss: 4.9857 - val_acc: 0.9450\n",
            "Epoch 49/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1818 - acc: 0.9430 - val_loss: 5.4433 - val_acc: 0.9341\n",
            "Epoch 50/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1518 - acc: 0.9450 - val_loss: 5.0705 - val_acc: 0.9361\n",
            "Epoch 51/74\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.1938 - acc: 0.9416 - val_loss: 1.6566 - val_acc: 0.9642\n",
            "Epoch 52/74\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.1419 - acc: 0.9560 - val_loss: 1.6213 - val_acc: 0.9597\n",
            "Epoch 53/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1607 - acc: 0.9470 - val_loss: 2.3069 - val_acc: 0.9610\n",
            "Epoch 54/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1512 - acc: 0.9485 - val_loss: 1.3593 - val_acc: 0.9642\n",
            "Epoch 55/74\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.1453 - acc: 0.9470 - val_loss: 1.9099 - val_acc: 0.9680\n",
            "Epoch 56/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1814 - acc: 0.9445 - val_loss: 3.2588 - val_acc: 0.9604\n",
            "Epoch 57/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1747 - acc: 0.9570 - val_loss: 1.8500 - val_acc: 0.9565\n",
            "Epoch 58/74\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.1698 - acc: 0.9485 - val_loss: 1.1976 - val_acc: 0.9610\n",
            "Epoch 59/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1454 - acc: 0.9530 - val_loss: 1.2878 - val_acc: 0.9668\n",
            "Epoch 60/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1777 - acc: 0.9470 - val_loss: 0.7706 - val_acc: 0.9680\n",
            "Epoch 61/74\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1307 - acc: 0.9525 - val_loss: 2.0109 - val_acc: 0.9514\n",
            "Epoch 62/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1506 - acc: 0.9515 - val_loss: 1.8027 - val_acc: 0.9674\n",
            "Epoch 63/74\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.1171 - acc: 0.9565 - val_loss: 2.5037 - val_acc: 0.9578\n",
            "Epoch 64/74\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1453 - acc: 0.9460 - val_loss: 3.1374 - val_acc: 0.9552\n",
            "Epoch 65/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.2283 - acc: 0.9465 - val_loss: 3.3856 - val_acc: 0.9642\n",
            "Epoch 66/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1614 - acc: 0.9550 - val_loss: 2.6396 - val_acc: 0.9597\n",
            "Epoch 67/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1620 - acc: 0.9445 - val_loss: 1.9015 - val_acc: 0.9610\n",
            "Epoch 68/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1396 - acc: 0.9480 - val_loss: 4.1628 - val_acc: 0.9303\n",
            "Epoch 69/74\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.1832 - acc: 0.9405 - val_loss: 2.3535 - val_acc: 0.9610\n",
            "Epoch 70/74\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1312 - acc: 0.9540 - val_loss: 8.6260 - val_acc: 0.9092\n",
            "Epoch 71/74\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.1540 - acc: 0.9480 - val_loss: 3.6625 - val_acc: 0.9495\n",
            "Epoch 72/74\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.1336 - acc: 0.9615 - val_loss: 3.1704 - val_acc: 0.9559\n",
            "Epoch 73/74\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.1614 - acc: 0.9520 - val_loss: 1.6303 - val_acc: 0.9636\n",
            "Epoch 74/74\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.1317 - acc: 0.9600 - val_loss: 1.6878 - val_acc: 0.9565\n",
            "\n",
            "New model trained\n",
            "\n",
            "Saving model for later use...\n",
            "\n",
            "Model Successfully saved\n",
            "\n",
            "Plotting results...\n",
            "\n",
            "........................\n",
            "\n",
            "Training Complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcsAAAEICAYAAAAwft9dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAEICAYAAADV4BoxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvhRUj4qTfQ3",
        "colab_type": "text"
      },
      "source": [
        "## predict on test images from kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQctF7aQTpMK",
        "colab_type": "text"
      },
      "source": [
        "#### unzip test data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VmkGyxCAwnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### unzip test data\n",
        "test_dir = '/tmp/test'\n",
        "test_zip_dir = '/content/test1.zip'\n",
        "zipref = zipfile.ZipFile(test_zip_dir, 'r')\n",
        "zipref.extractall(test_dir)\n",
        "zipref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udVuXjpKTzGS",
        "colab_type": "text"
      },
      "source": [
        "#### load test data through generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJUH3I2ZPYII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "41a47974-d440-48d6-b296-d35570355a74"
      },
      "source": [
        "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_gen = test_data_gen.flow_from_directory(\n",
        "                    test_dir,\n",
        "                    target_size=((Nrows, Ncols)),\n",
        "                    class_mode='binary')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12500 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o4UYRdgPxjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.predict_generator(test_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btFOwyNDP-By",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "1e7bfb50-d71a-40d1-814e-91875f095cf8"
      },
      "source": [
        "print(result[1:10])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21ezM5kpUluK",
        "colab_type": "text"
      },
      "source": [
        "#### create test_list\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We_ySCZH-QBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b5fec07-25d1-4011-820b-501c5e72f24f"
      },
      "source": [
        "#### create test_list\n",
        "\n",
        "test_list = glob.glob(test_dir+'/test1/*.jpg')\n",
        "print(len(test_list))\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKUiSMaRsXxd",
        "colab_type": "text"
      },
      "source": [
        "Save the submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOOKHQZYsWcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "56fac57c-d91e-4d86-e20d-f7897af1e8a1"
      },
      "source": [
        "# save the submission file\n",
        "import numpy as np\n",
        "\n",
        "idx = []\n",
        "for i in test_list:\n",
        "    idx.append(i[18:-4])\n",
        "print(len(test_list))\n",
        "print(len(idx))\n",
        "print(result.shape)\n",
        "result = result.reshape(result.shape[0])\n",
        "submission = {\"id\": idx, \"label\": result}\n",
        "pd.DataFrame(submission).to_csv(\"/content/submission.csv\", index=False)\n",
        "\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500\n",
            "12500\n",
            "(12500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ovUoflEG0gVJ",
        "outputId": "7ee741da-885c-4e13-c06b-aa528cf50cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# predict for new uploaded images\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(Nrows, Ncols))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a dog\")\n",
        "  else:\n",
        "    print(fn + \" is a cat\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4bb6de4e-792e-41f7-a438-e1370150705b\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4bb6de4e-792e-41f7-a438-e1370150705b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-30d2a99ab6e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: google.colab._files is undefined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WD9GJDTV0gVR",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}