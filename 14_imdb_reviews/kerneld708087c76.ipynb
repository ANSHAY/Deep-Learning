{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['aclimdb']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"VOCAB_SIZE = 10000\nEPOCHS = 10\nPADDING = 'post'\nTRUNC = 'post'\nMAXLENGTH = 1024\nEMB_DIM = 16\nBATCH_SIZE = 1536","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Load Data"},{"metadata":{},"cell_type":"markdown","source":"### Define directories"},{"metadata":{"trusted":true},"cell_type":"code","source":"directory = \"../input/aclimdb/aclImdb/\"\n\ntrain_sent = []\ntest_sent = []\ntrain_labels = []\ntest_labels = []\n","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load from files"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(train_test, label_type):\n    path = os.path.join(directory, train_test, label_type)\n    label = 1 if (label_type=='pos') else 0\n    dir_list = os.listdir(path)\n    for file in dir_list:\n        f = open(os.path.join(path,file))\n        sentence = f.read()\n        if train_test == 'train':\n            train_sent.append(sentence)\n            train_labels.append(label)\n        if train_test == 'test':\n            test_sent.append(sentence)\n            test_labels.append(label)\n        f.close()\n\nload_data('train', 'pos')\nload_data('train', 'neg')\nload_data('test', 'pos')\nload_data('test', 'neg')\n\nprint (train_sent[0])\nprint (train_labels[0])\nprint (test_sent[0])\nprint (test_labels[0])","execution_count":7,"outputs":[{"output_type":"stream","text":"Though this movie has a first rate roster of fine actors, special effects that are excellent, and a story line that is full of surprises, it wasn't picked up for studio distribution and went directly to DVD. Perhaps it contains too much 'anti-police force' information, or perhaps it is juts one too many action flicks released during a glut, but whatever the reason the big screens missed the opportunity, fortunately the new concept of releasing direct to DVD allows us to enjoy it.<br /><br />The theme is old: rookie reporter uncovers an inner circle of cops that are corrupt - in this case the F.R.A.T. (First Response Assault and Tactical) team, a group of well trained policeman created to clean up the mythical city of Edison from its low point of crime, drugs, prostitution etc. Working undercover the temptation of pocketing the confiscated goods and money proves too much of an opportunity and now, 15 years after its formation, FRAT is responsible for murder, drug trafficking, terrorizing innocent people etc. The lead dog is Lazerov (Dylan McDermott, who makes a terrifyingly real gangster!) and his partner Rafe Deed (LL Cool J, even more buff than usual and proving he can be a sensitive actor). Reporter Pollack (Justin Timberlake) catches wind of a 'bad mistake' and reports his theory of fraud and corruption to his paper's boss Ashford (the always reliably fine Morgan Freeman). Gradually Polack convinces Ashford and subsequently Wallace (Kevin Spacey, also a consistently fine character actor) and they aid Pollack in this investigative reporting. The closer Pollack gets to the truth the more surprises and bad incidents happen and the story runs pall mall toward a series of unexpected results.<br /><br />Timberlake lacks the charisma to carry the lead, especially in the company of such seasoned actors. But LL Cool J, Freeman, Spacey, and McDermott keep the well-oiled machine of a movie rolling to the very end. No, it is not a great movie, but it is one that makes for an edge of the seat action flick with a message. Grady Harp\n1\nI am not a Faulkner fan (which is considered sacrilegious, especially since I grew up near the author's hometown); however, I think this is an excellent movie. On par with the quality of the movie \"To Kill a Mocking Bird\". If you haven't seen it, buy it anyway. It's well worth having in your permanent collection. TCM recently played the movie as a part of the Race on Film series. I wish they'd play it more often. Very moving.<br /><br />On a side note, the folks from Oxford, Mississippi, will also enjoy seeing the footage of the town square as it was back in the 1940's. The Courthouse, City Hall, etc.: They're all on screen. I never knew the movie was filmed there until I noticed the familiarity of the buildings. When I saw the arch in the front of City Hall, I began to get suspicious. Look closely at the pennants on Chick's wall: You'll see two for Ole Miss !\n1\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Tokenize the text data"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=VOCAB_SIZE)\ntokenizer.fit_on_texts(train_sent)\nword_index = tokenizer.word_index\n\nprint(len(word_index))","execution_count":8,"outputs":[{"output_type":"stream","text":"88582\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Sentences to Sequences"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_seq = tokenizer.texts_to_sequences(train_sent)\ntrain_seq = pad_sequences(train_seq, padding=PADDING, truncating=TRUNC, maxlen=MAXLENGTH)\n\ntest_seq = tokenizer.texts_to_sequences(test_sent)\ntest_seq = pad_sequences(test_seq, padding=PADDING, truncating=TRUNC, maxlen=MAXLENGTH)\n\ntrain_labels = np.array(train_labels)\ntest_labels = np.array(test_labels)\n\nprint(train_seq.shape)\nprint(test_seq.shape)\nprint(train_labels.shape)\nprint(test_labels.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"(25000, 1024)\n(25000, 1024)\n(25000,)\n(25000,)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Define Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(VOCAB_SIZE, EMB_DIM, input_length=MAXLENGTH),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(32, activation='tanh'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compile Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\nmodel.summary()","execution_count":11,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 1024, 16)          160000    \n_________________________________________________________________\nbidirectional (Bidirectional (None, 1024, 128)         41472     \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 64)                41216     \n_________________________________________________________________\ndense (Dense)                (None, 32)                2080      \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 244,801\nTrainable params: 244,801\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Train Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_seq,\n                    train_labels,\n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    validation_data=(test_seq, test_labels),\n                    verbose=1)","execution_count":12,"outputs":[{"output_type":"stream","text":"Train on 25000 samples, validate on 25000 samples\nEpoch 1/10\n25000/25000 [==============================] - 240s 10ms/sample - loss: 0.6899 - acc: 0.5349 - val_loss: 0.6557 - val_acc: 0.6704\nEpoch 2/10\n 2048/25000 [=>............................] - ETA: 2:39 - loss: 0.6384 - acc: 0.6919","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-a26d32556704>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     verbose=1)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":"## Plot Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(EPOCHS)\n\nplt.plot(epochs, acc, 'r')\nplt.plot(epochs, val_acc, 'b')\nplt.xlabel('EPOCHS')\nplt.ylabel('Accuracies')\nplt.legend('Train Acc', 'Val Acc')\nplt.figure()\n\nplt.plot(epochs, loss, 'r')\nplt.plot(epochs, val_loss, 'b')\nplt.xlabel('EPOCHS')\nplt.ylabel('Losses')\nplt.legend('Train Loss', 'Val Loss')\nplt.figure()","execution_count":13,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'history' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-154f232938e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}